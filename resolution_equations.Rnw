\chapter{Résolution d'équations à une variable}
\label{chap:resolution}

\begin{itemize}
\item Un investisseur est disposé à payer $k$~\$ aujourd'hui en retour
  d'une série de $n$ versements de 1~\$, le premier dans un an. Quel
  taux de rendement exige-t-il?

  On doit trouver la valeur de $i$ tel que $a_{\angl{n}\, i} = k$, soit
  \begin{displaymath}
    f(i) = \frac{1 - (1 + i)^{-n}}{i} -k = 0.
  \end{displaymath}

\item On a un échantillon aléatoire $X_1, \dots, X_n$ provenant d'une
  distribution binomiale négative avec fonction de masse de probabilité
  \begin{displaymath}
    \Pr[X = x] = \binom{x + r - 1}{r - 1} p^r (1 - p)^x, \quad x = 0,
    1, \dots,
  \end{displaymath}
  où $p$ est supposé connu. Trouver l'estimateur du maximum de
  vraisemblance du paramètre $r$.

  La fonction de vraisemblance est
  \begin{align*}
    L(r)
    &= \prod_{i = 1}^n \Pr[X = x_i] \\
    &= \prod_{i = 1}^n \binom{x_i + r - 1}{r - 1} p^r (1 - p)^{x_i} \\
  \end{align*}
  et la fonction de log-vraisemblance est
  \begin{align*}
    l(r)
    &= \sum_{i = 1}^n
    [\ln \Gamma(x_i + r) - \ln \Gamma(r) - \ln \Gamma(x_i - 2) \\
    &\quad\; + r \ln p + x_i \ln (1 - p)].
  \end{align*}
  Par conséquent, l'estimateur du maximum de vraisemblance $\hat{r}$
  est la solution de
  \begin{displaymath}
    \frac{d}{dr}\, l(r) = \underbrace{%
      \sum_{i = 1}^n (\Psi(x_i + r) - \Psi(r) + \ln p)}_{f(r)}
    = 0,
  \end{displaymath}
  où $\Psi(x) = \Gamma(x)^\prime/\Gamma(x)$ est la \emph{fonction
    digamma}.
\end{itemize}

Problème de base, mais fréquemment rencontré en analyse numérique:
trouver la racine d'une fonction $f(x)$, c'est-à-dire la solution de
$f(x) = 0$.


\section{Méthode de bissection}
\label{sec:resolution:bissection}

La méthode de bissection est la plus simple et intuitive de résolution
d'une équation à une variable, mais aussi la plus inefficace.

Soit $f$ une fonction continue sur $[a, b]$ et $f(a)$ et $f(b)$ sont
de signes opposés. Par le théorème de la valeur intermédiaire, il
existe un point $x^*$ tel que $f(x^*) = 0$.

Idée de la méthode de bissection: trouver le point $x^*$ en utilisant
le point milieu d'intervalles de plus en plus petits.

\SweaveOpts{height=4, width=6}
\begin{center}
<<echo=FALSE,fig=TRUE>>=
par(mar = c(4, 4, 1, 1))
f <- function(x) x^3 + x
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2, axes = FALSE)
x <- c(-0.5, 0.75, 0.125, -0.1875, 0)
#segments(x, -2.08, x, f(x), lty = 2)
points(x, f(x), pch = c(rep(21, 4), 19), bg = "gray")
axis(1, at = x,
     labels = c("a", "b", expression(x[1]), expression(x[2]),
     expression(x^"*")))
axis(2)
abline(h = 0)
box()
@
\end{center}

On peut utiliser différents critères pour arrêter la procédure:
\begin{enumerate}
\item $|f(x_n)| < \varepsilon$. Peut être satisfait même si $x_n \gg
  x^*$ ou $x_n \ll x^*$;
  \begin{center}
    \begin{minipage}[c]{0.4\linewidth}
<<echo=FALSE,fig=TRUE>>=
par(mar = c(1, 4, 1, 1))
f <- function(x) x^3 - x^2 - x - 10
curve(f(x), xlim = c(-10, 10), xlab = "", ylab = "f(x)",
      lwd = 2, axes = FALSE)
axis(2)
abline(h = 0)
box()
@
    \end{minipage}
    \begin{minipage}[c]{0.4\linewidth}
<<echo=FALSE,fig=TRUE>>=
par(mar = c(1, 4, 1, 1))
f <- function(x) x^3 - x^2 - x - 0.2
curve(f(x), xlim = c(-1, 2), xlab = "", ylab = "f(x)",
      lwd = 2, axes = FALSE)
axis(2)
abline(h = 0)
box()
@
    \end{minipage}
  \end{center}

\item $|x_n - x_{n - 1}| < \varepsilon$. Peut être satisfait même si
  $\{x_n\}$ diverge. Le choix de $\varepsilon$ est donc important;

\item $|x_n - x_{n - 1}|/|x_n| < \varepsilon$ pour $x_n \neq 0$. En
  général le meilleur choix.
\end{enumerate}

\begin{commentaire}
  Présentation de l'algorithme et des deux exemples au projecteur.
\end{commentaire}

%%% ALGORITHME DE BISSECTION À INSÉRER
\input{input_algorithme_bissection}

%%% DEUX EXEMPLES À INSÉRER
\input{input_exemple_bissection_1}
\input{input_exemple_bissection_2}



\section{Méthode du point fixe}
\label{sec:resolution:pointfixe}

<<echo=FALSE>>=
source("pointfixe.R")
@

La solution de l'équation
\begin{center}
  \begin{minipage}[c]{0.4\linewidth}
    \begin{displaymath}
      g(x) = x
    \end{displaymath}
\end{minipage}
  \begin{minipage}[c]{0.4\linewidth}
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
f <- function(x) x
g <- function(x) x - (x^3 + 4 * x^2 - 10)/(3 * x^2 + 8 * x)
x <- pointfixe(g, 1.5)$fixed.point
curve(g, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25), lwd = 2)
curve(f, add = TRUE)
points(x, x, pch = 19)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1), lty = 2, border = "blue")
@
  \end{minipage}
\end{center}
est un \emph{point fixe} de la fonction $g$.

Tout problème de recherche de racine peut être exprimé comme un
problème de point fixe:
\begin{displaymath}
  f(x) = 0 \quad\Leftrightarrow\quad \underbrace{x - f(x)}_{\D g(x)} = x.
\end{displaymath}

\begin{thm}
  \label{thm:resolution:pointfixe}
  Soit $g$ une fonction continue sur $[a, b]$.
  \begin{enumerate}
  \item Si $g(x) \in [a, b]$ pour tout $x \in [a, b]$, alors $g$ a un
    point fixe dans $[a, b]$.
  \item Si, de plus, $g^\prime(x)$ existe sur $(a, b)$ et qu'il existe
    une constante $k$ tel que
    \begin{displaymath}
      |g^\prime(x)| \leq k < 1
    \end{displaymath}
    pour tout $x \in (a, b)$, alors $g$ a un point fixe \emph{unique}
    dans $[a, b]$.
  \end{enumerate}
\end{thm}
\begin{proof}[Démonstration graphique]
  \mbox{}
  \begin{enumerate}
  \item
    \begin{minipage}[t]{0.5\linewidth}
      \mbox{} \\[-\baselineskip]
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
f <- function(x) x
g <- function(x) x - (x^3 + 4 * x^2 - 10)/(3 * x^2 + 8 * x)
k <- function(x) g(x - 0.5) + 0.3
h <- function(x) -2 * x^2 + 7 * x - 4.75
curve(g, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, axes = FALSE, xlab = "", ylab = "")
curve(h, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, lty = "dashed", col = "red1", add = TRUE)
curve(k, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, lty = "dotted", col = "orange1", add = TRUE)
curve(f, add = TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1), lty = 2, border = "blue")
axis(1, at = c(1, 2), labels = c("a", "b"))
axis(2, at = c(1, 2), labels = c("a", "b"))
text(rep(2.27, 3), c(g(2.25), h(2.25), k(2.25)), c("g", "h", "k"))
box()
@
    \end{minipage}
    \begin{minipage}[t]{0.5\linewidth}
      \begin{itemize}
      \item $g(x) \in [a, b]$ pour tout $x \in [a, b]$ $\Rightarrow$
        point fixe existe;
      \item $h(x) \not\in [a, b]$ pour tout $x \in [a, b]$ $\Rightarrow$
        pas nécessairement de point fixe;
      \item $k(x) \not\in [a, b]$ pour tout $x \in [a, b]$ $\Rightarrow$
         point fixe néanmoins possible.
      \end{itemize}
    \end{minipage}
  \item
    \begin{minipage}[t]{0.5\linewidth}
      \mbox{} \\[-\baselineskip]
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
f <- function(x) x
g <- function(x) x - (x^3 + 4 * x^2 - 10)/(3 * x^2 + 8 * x)

## Les points ci-dessous ont été obtenus avec la fonction drawPlot()
## du package Hmisc:
##
## drawPlot(Abline(0, 1), Abline(h = 1), Abline(h = 2),
##          Abline(v = 1), Abline(v = 2),
##          Curve('smooth', ask = TRUE),
##          xlim = c(0.75, 2.25), ylim = c(0.75, 2.25))
x <- c(
0.7840067, 0.8267755, 0.8668402, 0.9044605, 0.9402250, 0.9748105, 1.0088406,
1.0428095, 1.0770484, 1.1117217, 1.1468403, 1.1822866, 1.2178442, 1.2532294,
1.2881214, 1.3221886, 1.3551113, 1.3865996, 1.4164060, 1.4443339, 1.4702415,
1.4940425, 1.5157034, 1.5352392, 1.5527068, 1.5681983, 1.5818330, 1.5937504,
1.6041027, 1.6130488, 1.6207487, 1.6273589, 1.6330289, 1.6378987, 1.6420969,
1.6457396, 1.6489303, 1.6517600, 1.6543073, 1.6566399, 1.6588148, 1.6608796,
1.6628736, 1.6648288, 1.6667705, 1.6687184, 1.6706870, 1.6726867, 1.6747240,
1.6768025, 1.6789227, 1.6810837, 1.6832826, 1.6855164, 1.6877815, 1.6900755,
1.6923975, 1.6947488, 1.6971339, 1.6995611, 1.7020431, 1.7045971, 1.7072455,
1.7100156, 1.7129394, 1.7160532, 1.7193971, 1.7230142, 1.7269499, 1.7312507,
1.7359636, 1.7411355, 1.7468125, 1.7530396, 1.7598611, 1.7673205, 1.7754617,
1.7843296, 1.7939715, 1.8044381, 1.8157853, 1.8280743, 1.8413726, 1.8557528,
1.8712913, 1.8880650, 1.9061467, 1.9255983, 1.9464634, 1.9687572, 1.9924568,
2.0174906, 2.0437286, 2.0709745, 2.0989604, 2.1273455, 2.1557203, 2.1836199,
2.2105525, 2.2360593)
y <- c(
1.184281, 1.174952, 1.167810, 1.162311, 1.158103, 1.154966, 1.152779, 1.151487,
1.151073, 1.151545, 1.152918, 1.155205, 1.158409, 1.162524, 1.167523, 1.173368,
1.180005, 1.187368, 1.195383, 1.203970, 1.213046, 1.222532, 1.232351, 1.242432,
1.252714, 1.263146, 1.273686, 1.284303, 1.294978, 1.305699, 1.316463, 1.327275,
1.338145, 1.349088, 1.360123, 1.371268, 1.382545, 1.393974, 1.405574, 1.417363,
1.429356, 1.441564, 1.453996, 1.466657, 1.479547, 1.492662, 1.505995, 1.519534,
1.533262, 1.547157, 1.561196, 1.575350, 1.589585, 1.603868, 1.618160, 1.632420,
1.646607, 1.660678, 1.674589, 1.688297, 1.701760, 1.714935, 1.727783, 1.740267,
1.752351, 1.764005, 1.775200, 1.785911, 1.796119, 1.805806, 1.814961, 1.823575,
1.831645, 1.839169, 1.846153, 1.852601, 1.858524, 1.863933, 1.868844, 1.873273,
1.877238, 1.880758, 1.883856, 1.886556, 1.888882, 1.890862, 1.892529, 1.893916,
1.895063, 1.896012, 1.896807, 1.897496, 1.898117, 1.898702, 1.899259, 1.899759,
1.900124, 1.900207, 1.899779, 1.898530)

curve(g, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, axes = FALSE, xlab = "", ylab = "")
lines(x, y, lwd = 2, lty = "dashed", col = "red1")
curve(f, add = TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1), lty = 2, border = "blue")
axis(1, at = c(1, 2), labels = c("a", "b"))
axis(2, at = c(1, 2), labels = c("a", "b"))
text(rep(2.27, 2), c(g(2.25), tail(y, 1)), c("g", "h"))
box()
@
    \end{minipage}
    \begin{minipage}[t]{0.5\linewidth}
      \begin{itemize}
      \item $g^\prime(x) < 1$ pour tout $x \in (a, b)$, donc $g(x)$
        croise $y = x$ en un seul point $\Rightarrow$ point fixe
        unique;
      \item $h(x) \not\in [a, b]$ pour tout $x \in [a, b]$
        $\Rightarrow$, mais $h^\prime(x) > 1$ pour $x \in (a, b)$
        $\Rightarrow$ possibilité de plusieurs points fixes.
      \end{itemize}
    \end{minipage}
  \end{enumerate}
\end{proof}

Procédure pour trouver le point fixe: choisir une valeur de départ
$x_0$, puis rechercher le point $x^*$ tel que $g(x^*) = x^*$ par
essais successifs:

%% Premier graphique: fonction décroissante
\begin{center}
<<echo=FALSE, fig=TRUE>>=
f <- function(x) x
g <- function(x) -0.035 * x^2 +  10
lim <- c(7, 8.5)
curve(g, xlim = lim, ylim = lim,
      lwd = 2, axes = FALSE, xlab = "", ylab = "")
curve(f, add = TRUE)
x <- numeric(6)
x[1] <- 7.1
for (i in 2:length(x)) x[i] <- g(x[i - 1])
arrows(x[1], 0, x[1], x[2],
       lty = "dashed", col = "blue", length = 0.15)
arrows(x[-length(x)],
       x[-1],
       x[-1],
       x[-1], lty = "dashed", col = "blue", length = 0.15)
arrows(x[-length(x)][-1],
       x[-length(x)][-1],
       x[-length(x)][-1],
       x[-1][-1], lty = "dashed", col = "blue", length = 0.15)
axis(1, at = x,
     labels = parse(text = paste("x[", -1 + seq(along = x), "]", sep = "")))
axis(2, at = x[-1],
     labels = parse(text = paste("y[", -1 + seq(along = x[-1]), "]", sep = "")))
box()
@
\end{center}

%% Deuxième graphique: fonction croissante
\begin{center}
<<echo=FALSE, fig=TRUE>>=
f <- function(x) x
g <- function(x) -0.035 * (x - 15)^2 +  10
lim <- c(7.5, 8.8)
curve(g, xlim = lim, ylim = lim,
      lwd = 2, axes = FALSE, xlab = "", ylab = "")
curve(f, add = TRUE)
x <- numeric(5)
x[1] <- 7.8
for (i in 2:length(x)) x[i] <- g(x[i - 1])
arrows(x[1], 0, x[1], x[2],
       lty = "dashed", col = "blue", length = 0.15)
arrows(x[-length(x)],
       x[-1],
       x[-1],
       x[-1], lty = "dashed", col = "blue", length = 0.15)
arrows(x[-length(x)][-1],
       x[-length(x)][-1],
       x[-length(x)][-1],
       x[-1][-1], lty = "dashed", col = "blue", length = 0.15)
axis(1, at = x,
     labels = parse(text = paste("x[", -1 + seq(along = x), "]", sep = "")))
axis(2, at = x,
     labels = parse(text = paste("y[", -1 + seq(along = x), "]", sep = "")))
box()
@
\end{center}

La rapidité de la convergence est donc fonction de la $g^\prime(x)$:
plus la pente est \emph{faible}, plus la convergence est \emph{rapide}.

\begin{thm}
  Si les deux conditions du théorème \ref{thm:resolution:pointfixe}
  sont satisfaites, alors la série $\{x_n\}$ définie par
  \begin{displaymath}
    x_n = g(x_{n - 1})
  \end{displaymath}
  converge vers un point fixe unique dans $[a, b]$.
\end{thm}

\begin{commentaire}
  Présentation de l'algorithme et des deux exemples au projecteur.
\end{commentaire}

%%% ALGORITHME DU POINT FIXE À INSÉRER
\input{input_algorithme_pointfixe}

%%% DEUX EXEMPLES À INSÉRER
\input{input_exemple_pointfixe_1}
\input{input_exemple_pointfixe_2}



\section{Méthode de Newton--Raphson}
\label{sec:resolution:newtonraphson}

<<echo=FALSE>>=
source("nr.R")
@

Avec la méthode de Newton-Raphson, on revient au problème de trouver
la racine $x^*$ de la fonction $f(x)$, c'est-à-dire la solution de
\begin{displaymath}
  f(x) = 0.
\end{displaymath}

Soit $\tilde{x}$ un point «près» de $x^*$ tel que $f(\tilde{x}) \neq
0$. Alors la tengente de $f$ en $\tilde{x}$ croise l'abscisse près de
$x^*$. Graphiquement:

\begin{center}

<<echo=FALSE, fig=TRUE>>=
par(mar = c(3, 4, 1, 1))
f <- function(x) x^3 + x
fp <- function(x) 3 * x^2 + 1
tangente <- function(x) fp(0.5) * x + f(0.5) - 0.5 * fp(0.5)
curve(f(x), xlim = c(-1, 1), ylim = c(-1, 2),
      ylab = "f(x)", lwd = 2, axes = FALSE)
curve(tangente(x), xlim = c(-0.25, 1),
      lwd = 2, lty = "dashed", add = TRUE)
xh <- -(f(0.5) - 0.5 * fp(0.5))/fp(0.5)
points(c(0, xh, 0.5),
       c(0, 0, f(0.5)), pch = 19)
abline(h = 0)
axis(1, at = c(0, xh, 0.5),
     labels = c(expression(x^"*"), expression(hat(x)), expression(tilde(x))))
axis(2)
box()
@
\end{center}

Le point $\hat{x}$ est tel que
\begin{displaymath}
  \frac{f(\tilde{x}) - 0}{\tilde{x} - \hat{x}} = f^\prime(\tilde{x}),
\end{displaymath}
d'où
\begin{align*}
  x^*
  &\simeq \hat{x} \\
  &= \tilde{x} - \frac{f(\tilde{x})}{f^\prime(\tilde{x})}.
\end{align*}

On peut également justifier la formule précédente à l'aide du
développement de Taylor de $f(x)$ autour de $\tilde{x}$:
\begin{align*}
  f(x)
  &= f(\tilde{x}) + (x - \tilde{x}) f^\prime(\tilde{x})
  + \frac{(x - \tilde{x})^2}{2} f^{\prime\prime}(\tilde{x}) + \dots \\
  \intertext{et donc}
  f(x^*)
  &= 0 =
  f(\tilde{x}) + (x^* - \tilde{x}) f^\prime(\tilde{x})
  + \underbrace{%
    \frac{(x^* - \tilde{x})^2}{2} f^{\prime\prime}(\tilde{x}) +
    \dots}_{\D \text{négligeable}},
\end{align*}
d'où
\begin{displaymath}
  x^*
  \simeq \tilde{x} - \frac{f(\tilde{x})}{f^\prime(\tilde{x})}.
\end{displaymath}

Si le point $\hat{x}$ est trop éloigné de la racine $x^*$, on peut
répéter la procédure ci-dessus en utilisant $\hat{x}$ comme nouveau
point où l'on calcule la tengente, et ainsi de suite jusqu'à
l'obtention d'une «bonne» approximation.

Ainsi, soit $f$ une fonction différentiable sur $[a, b]$ et $x^* \in
[a, b]$. Alors $x^*$ peut être obtenu comme le point de convergence de
la série $\{x_n\}$ définie par
\begin{displaymath}
  x_n = x_{n - 1} - \frac{f(x_{n - 1})}{f^\prime(x_{n - 1})},
\end{displaymath}
avec $x_0$ une valeur de départ quelconque.

\begin{rems}
  \begin{enumerate}
  \item La méthode de Newton--Raphson constitue en fait une procédure
    de point fixe avec
    \begin{displaymath}
      g(x) = x - \frac{f(x)}{f^\prime(x)}.
    \end{displaymath}
  \item On peut démontrer que si $f$ est doublement différentiable sur
    $[a, b]$ et que $x^* \in [a, b]$ est tel que
    \begin{itemize}
    \item $f(x^*) = 0$
    \item $f^\prime(x^*) \neq 0$,
    \end{itemize}
    alors il existe un $\delta > 0$ tel que la série $\{x_n\}$
    converge vers $x^*$ pour tout $x_0 \in [x^* - \delta, x^* +
    \delta]$. Autrement dit:
    \begin{itemize}
    \item les hypothèses du théorème \ref{thm:resolution:pointfixe}
      sont satisfaites;
    \item la méthode de Newton--Raphson fonctionne toujours avec un
      «bon» choix de valeur de départ $x_0$.
    \end{itemize}
  \item Si $f^\prime(x)$ est difficile à calculer et/ou inefficace à
    calculer, on peut utiliser la \emph{méthode de la sécante}:
    \begin{displaymath}
      x_n = x_{n - 1} - \frac{f(x_{n - 1})(x_{n - 1} - x_{n - 2})}{%
        f(x_{n - 1}) - f(x_{n - 2})},
    \end{displaymath}
    avec $x_0$, $x_1$ des valeurs de départ.
    \begin{center}

<<echo=FALSE, fig=TRUE>>=
f <- function(x) exp(2 * x) - 20
curve(f, xlim = c(0, 2),
      ylab = "f(x)", lwd = 2, axes = FALSE)
abline(h = 0)
x <- numeric(7)
x[1] <- 0
x[2] <- 2
for (i in 3:length(x))
    x[i] <- x[i - 1] - (f(x[i - 1]) * (x[i - 1] - x[i - 2]))/
    (f(x[i - 1]) - f(x[i - 2]))
axis(1, at = x, label = parse(text = paste("x[", -1 + seq(along = x), "]", sep = "")))
axis(2)
box()
for (i in 1:(length(x) - 2))
{
    xx <- x[i:(i + 2)]
    fxx <- f(xx)
    segments(xx[1:2], fxx[1:2], xx[-1], c(fxx[2], 0),
             lwd = 1, col = "blue")
}
x <- x[-(1:2)]
segments(x, 0, x, f(x),
         lwd = 1, lty = "dashed", col = "gray")
@
    \end{center}
  \end{enumerate}
\end{rems}

\begin{commentaire}
  Présentation de l'algorithme et des trois exemples au projecteur.
\end{commentaire}

%%% ALGORITHME DE NEWTON-RAPHSON À INSÉRER
\input{input_algorithme_newtonraphson}

%%% TROIS EXEMPLES À INSÉRER
%% Les originaux de ces trois fichiers sont des fichiers .Rnw
\input{input_exemple_newtonraphson_1}
\input{input_exemple_newtonraphson_2}
\input{input_exemple_newtonraphson_3}



%%% SECTION À INSÉRER
\input{input_fonctions_optimisation}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "methodes_numeriques"
%%% End:
