%%% Copyright (C) 2018 Vincent Goulet
%%%
%%% Ce fichier fait partie du projet «Méthodes numériques en actuariat»
%%% http://github.com/vigou3/methodes-numeriques-en-actuariat
%%%
%%% Cette création est mise à disposition selon le contrat
%%% Attribution-Partage dans les mêmes conditions 4.0
%%% International de Creative Commons.
%%% http://creativecommons.org/licenses/by-sa/4.0/

\chapter{Valeurs propres, vecteurs propres et diagonalisation}
\label{chap:valeurspropres}

\begin{objectifs}
\item Énoncer les définitions de valeur et vecteur propre d'une
  matrice.
\item Calculer les valeurs propres d'une matrice et les
  vecteurs propres correspondants.
\item Déterminer si une matrice est diagonalisable ou non.
\item Diagonaliser une matrice carrée.
\end{objectifs}


Les valeurs et vecteurs propres sont des caractéristiques liées à une
matrice carrée. Ces notions admettent une grande variété
d'interprétations physiques différentes, chacune ancrée dans son
domaine d'application: géométrie, résolution d'équations
différentielles, mécanique quantique, finance, %
\capsule{http://youtu.be/VM4IRctyjOk}{moteurs de recherche}, %
etc.

Dans le cadre de ce cours, l'étude des valeurs et vecteurs propres
demeurera plutôt collée aux définitions de base. Nous ne verrons
qu'une seule application, celle que vous êtes la plus susceptible de
rencontrer dans vos études en actuariat, soit la diagonalisation d'une
matrice.


\section{Définitions}
\label{sec:valeurspropres:definitions}

En algèbre vectorielle, le produit par une matrice $\mat{A}$ peut être
vu comme un opérateur permettant d'appliquer une transformation à un
vecteur $\mat{x}$. Par exemple:
\begin{itemize}
\item La multiplication par un scalaire:
  \begin{equation*}
    \begin{bmatrix} 3 & 0 \\ 8 & -1 \end{bmatrix}
    \begin{bmatrix} 1 \\ 2 \end{bmatrix} =
    \begin{bmatrix} 3 \\ 6 \end{bmatrix} =
    3 \begin{bmatrix} 1 \\ 2 \end{bmatrix}.
  \end{equation*}
\item La rotation d'un angle $\theta$:
  \begin{equation*}
    \begin{bmatrix}
      \cos \theta & - \sin \theta \\ \sin \theta & \cos \theta
    \end{bmatrix}
    \begin{bmatrix} x \\ y \end{bmatrix} =
    \begin{bmatrix}
      x \cos \theta - y \sin \theta \\ x \sin \theta + y \cos
      \theta
    \end{bmatrix} =
    \begin{bmatrix} w \\ z \end{bmatrix}.
  \end{equation*}
\item La projection sur un autre vecteur:
  \begin{equation*}
    \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix}
    \begin{bmatrix} 2 \\ 1 \end{bmatrix} =
    \begin{bmatrix} 2 \\ 0 \end{bmatrix}.
  \end{equation*}
\end{itemize}
Voir la \autoref{fig:valeurspropres:transformations} pour des
illustrations des transformations ci-dessus.

\begin{figure}
  \begin{minipage}{0.33\linewidth}
    \centering
<<echo=FALSE, fig=TRUE>>=
par(mar = rep(1, 4))
x <- c(2, 1.75); y <- 1.75 * x
plot(NA, xlim = c(0, 4), ylim = c(0, 4),
     xlab = "", ylab = "", axes = FALSE)
arrows(0, 0, y[1], y[2], lwd = 4, col = "darkorange")
text((x[1] + y[1])/2 - 0.1, (x[2] + y[2])/2 + 0.1, labels = "Ax",
     pos = 3, font = 2, cex = 3, col = "darkorange")
arrows(0, 0, x[1], x[2], lwd = 4, col = "black")
text(x[1]/2, x[2]/2 + 0.1, labels = "x",
     pos = 3, font = 2, cex = 3, col = "black")
@
    \subcaption{produit par un scalaire}
  \end{minipage}
  \begin{minipage}{0.33\linewidth}
    \centering
<<echo=FALSE, fig=TRUE>>=
par(mar = rep(1, 4))
plot(NA, xlim = c(0, 4), ylim = c(0, 4),
     xlab = "", ylab = "", axes = FALSE)
R <- matrix(c(cos(pi/4), sin(pi/4), -sin(pi/4), cos(pi/4)), nrow = 2)
x <- c(3.25, 1)
w <- R %*% x
arrows(0, 0, x[1], x[2], lwd = 4)
arrows(0, 0, w[1], w[2], lwd = 4, col = "darkorange")
f <- function(x, r) sqrt(r^2 - x^2)
xx <- c(1.5, 1.5/x[1])
ww <- R %*% xx
r <- sqrt(sum(xx^2))
curve(f(x, r), xlim = c(ww[1], xx[1]), add = TRUE, lwd = 2)
text(1.3, 1.2, expression(theta), cex = 3)
text(x[1]/2 + 0.2, x[2]/2, labels = "x",
     pos = 1, font = 2, cex = 3)
text(x[1], x[2], labels = "(x, y)", pos = 4, cex = 3)
text(w[1]/2, w[2]/2 + 0.1, labels = "Ax",
     pos = 2, font = 2, cex = 3, col = "darkorange")
text(w[1], w[2], labels = "(w, z)", pos = 4, cex = 3, col = "darkorange")
@
    \subcaption{rotation}
  \end{minipage}
  \begin{minipage}{0.32\linewidth}
    \centering
<<echo=FALSE, fig=TRUE>>=
par(mar = rep(1, 4))
o <- c(0, 0.5)
x <- c(3.5, 3.25); y <- c(x[1], o[2])
plot(NA, xlim = c(0, 4), ylim = c(0, 4),
     xlab = "", ylab = "", axes = FALSE)
arrows(o[1], o[2] , x[1], x[2], lwd = 4, col = "black")
text(x[1]/2, (x[2] + o[2])/2 + 0.1, labels = "x",
     pos = 3, font = 2, cex = 3, col = "black")
arrows(o[1], o[2], y[1], y[2], lwd = 4, col = "darkorange")
text(y[1]/2, (y[2] + o[2])/2 - 0.1, labels = "Ax",
     pos = 1, font = 2, cex = 3, col = "darkorange")
len <- 0.25
segments(y[1], y[2], x[1], x[2], lty = 2)
segments(y[1] - len, y[2], y[1] - len, y[2] + len)
segments(y[1] - len, y[2] + len, y[1], y[2] + len)
@
    \subcaption{projection}
  \end{minipage}
  \caption{Illustrations de trois transformations d'un vecteur
    $\mat{x}$ que l'on peut représenter par un produit matriciel
    $\mat{A x}$.}
  \label{fig:valeurspropres:transformations}
\end{figure}

Les définitions de valeur propre et de vecteur propre procèdent de
cette interprétation du produit matriciel.

\begin{definition}
  \label{sec:valeurspropres:definition}
  Soit $\mat{A}$ une matrice $n \times n$. Alors le vecteur non nul
  $\mat{x} \in \R^n$ est un \emph{vecteur propre} de $\mat{A}$
  si
  \begin{displaymath}
    \mat{A} \mat{x} = \lambda \mat{x}
  \end{displaymath}
  pour une valeur de $\lambda$ appelée \emph{valeur propre} de
  $\mat{A}$. On dit que $\mat{x}$ est le vecteur propre
  \emph{correspondant} à $\lambda$.
\end{definition}

Ainsi, par définition, lorsqu'un vecteur propre $\mat{x}$ est
multiplié par la matrice $\mat{A}$, il est transformé en un multiple
de lui-même; voir la \autoref{fig:valeurspropres:illustration}.

\begin{figure}
  \begin{minipage}{0.22\linewidth}
<<echo=FALSE, fig=TRUE>>=
par(mar = rep(0, 4))
x <- c(1, 1)
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "", ylab = "", axes = FALSE)
arrows(0, 0, x[1], x[2], lwd = 8)
arrows(0, 0, x[1]/2, x[2]/2, lwd = 8, col = "darkorange")
points(0, 0, pch = 19, cex = 3)
@
    \subcaption{$0 \leq \lambda \leq 1$}
  \end{minipage}
  \hfill
  \begin{minipage}{0.22\linewidth}
<<echo=FALSE, fig=TRUE>>=
par(mar = rep(0, 4))
x <- c(1, 1)/2
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "", ylab = "", axes = FALSE)
arrows(0, 0, 2 * x[1], 2 * x[2], lwd = 8, col = "darkorange")
arrows(0, 0, x[1], x[2], lwd = 8)
points(0, 0, pch = 19, cex = 3)
@
    \subcaption{$\lambda \geq 1$}
  \end{minipage}
  \hfill
  \begin{minipage}{0.22\linewidth}
<<echo=FALSE, fig=TRUE>>=
par(mar = rep(0, 4))
x <- c(1, 1)
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "", ylab = "", axes = FALSE)
arrows(0.25, 0.25, x[1], x[2], lwd = 8)
arrows(0.25, 0.25, 0, 0, lwd = 8, col = "darkorange")
points(0.25, 0.25, pch = 19, cex = 3)
@
    \subcaption{$-1 \leq \lambda \leq 0$}
  \end{minipage}
  \hfill
  \begin{minipage}{0.22\linewidth}
<<echo=FALSE, fig=TRUE>>=
par(mar = rep(0, 4))
x <- c(1, 1)
plot(NA, xlim = c(0, 1), ylim = c(0, 1),
     xlab = "", ylab = "", axes = FALSE)
arrows(0.75, 0.75, x[1], x[2], lwd = 8)
arrows(0.75, 0.75, 0, 0, lwd = 8, col = "darkorange")
points(0.75, 0.75, pch = 19, cex = 3)
@
    \subcaption{$\lambda \leq -1$}
  \end{minipage}
  \caption{Un vecteur propre $\mat{x}$ d'une matrice $\mat{A}$ (en
    noir) est transformé en un multiple $\lambda$ de lui-même lorsque
    multiplié par $\mat{A}$ (en orange).}
  \label{fig:valeurspropres:illustration}
\end{figure}

\begin{exemple}
  Le vecteur $\mat{x} = (1, 2)$ est un vecteur propre de
  \begin{displaymath}
    \mat{A} = \begin{bmatrix} 3 & 0 \\ 8 & -1 \end{bmatrix}
  \end{displaymath}
  correspondant à la valeur propre $\lambda = 3$ car $\mat{Ax} = 3
  \mat{x}$. En effet,
  \begin{displaymath}
    \begin{bmatrix} 3 & 0 \\ 8 & -1 \end{bmatrix}
    \begin{bmatrix} 1 \\ 2 \end{bmatrix} =
    3 \begin{bmatrix} 1 \\ 2 \end{bmatrix}.
  \end{displaymath}
  \qed
\end{exemple}

\begin{rem}
  Le qualificatif «propre» doit être pris dans le sens de «qui
  caractérise». En anglais, les termes les plus souvent utilisés pour
  «valeur propre» et «vecteur propre» sont \emph{eigenvalue} et
  \emph{eigenvector}, dans l'ordre. Ils sont formés à partir du
  préfixe allemand \emph{eigen} plutôt qu'à partir de son équivalent
  anglais \emph{own}, probablement pour des raisons générales
  de viabilité phonétique.
\end{rem}



\section{Calcul des valeurs propres}
\label{sec:valeurspropres:valeurs}

Pour trouver les valeurs propres d'une matrice $\mat{A}$, on doit
résoudre
\begin{displaymath}
  \mat{A} \mat{x} = \lambda \mat{x}
\end{displaymath}
ou, de manière équivalente,
\begin{displaymath}
  (\lambda \mat{I} - \mat{A}) \mat{x} = \mat{0}.
\end{displaymath}
pour $\mat{x} \neq \mat{0}$. Par conséquent, $\lambda$ est une valeur
propre de $\mat{A}$ si, et seulement si, il existe une solution autre
que la solution triviale à ce système d'équations homogène.

Or, par le \autoref{thm:revision:unification}, il existe une
solution de $(\lambda \mat{I} - \mat{A}) \mat{x} = \mat{0}$ autre que
la solution triviale si, et seulement si, $\det(\lambda \mat{I} -
\mat{A}) = 0$. Par conséquent:
\begin{itemize}
\item les valeurs propres de $\mat{A}$ sont les solutions de
  \begin{displaymath}
    \det(\lambda \mat{I} - \mat{A}) = 0;
  \end{displaymath}
\item cette équation est l'\emph{équation caractéristique} de $\mat{A}$;
\item $\det(\lambda \mat{I} - \mat{A})$ est le \emph{polynôme
    caractéristique} (de degré $n$) de $\mat{A}$.
\end{itemize}

\begin{exemple}
  Soit
  \begin{displaymath}
    \mat{A} =
    \begin{bmatrix}
      0 &   1 & 0 \\
      0 &   0 & 1 \\
      4 & -17 & 8
    \end{bmatrix}.
  \end{displaymath}
  Le polynôme caractéristique de $\mat{A}$ est
  \begin{align*}
    \det(\lambda \mat{I} - \mat{A})
    &=
    \begin{vmatrix}
      \lambda &  -1 & 0 \\
      0 & \lambda & -1 \\
      -4 & 17 & \lambda - 8
    \end{vmatrix} \\
    &= \lambda [\lambda (\lambda - 8) + 17] - 4 \\
    &= \lambda^3 - 8 \lambda^2 + 17 \lambda - 4.
  \end{align*}
  Les valeurs propres sont les racines de ce polynôme, c'est-à-dire
  les solutions de
  \begin{displaymath}
    \lambda^3 - 8 \lambda^2 + 17 \lambda - 4 = 0.
  \end{displaymath}
  Or,
  \begin{displaymath}
    \lambda^3 - 8 \lambda^2 + 17 \lambda - 4 =
    (\lambda - 4)(\lambda^2 - 4 \lambda + 1),
  \end{displaymath}
  d'où les valeurs propres sont
  \begin{align*}
    \lambda_1 &= 4 \\
    \lambda_2 &= 2 + \sqrt{3} \\
    \lambda_3 &= 2 - \sqrt{3}.
  \end{align*}
  \qed
\end{exemple}


\begin{exemple}
  Soit la matrice triangulaire
  \begin{displaymath}
    \mat{A} =
    \begin{bmatrix}
      a_{11} & a_{12} & a_{13} \\
          0  & a_{22} & a_{23} \\
          0  &      0 & a_{33}
    \end{bmatrix}.
  \end{displaymath}
  On a
  \begin{align*}
    \det(\lambda \mat{I} - \mat{A})
    &=
    \begin{vmatrix}
      \lambda - a_{11} & -a_{12} & -a_{13} \\
          0  & \lambda - a_{22} & -a_{23} \\
          0  &      0 & \lambda - a_{33}
    \end{vmatrix} \\
    &= (\lambda - a_{11})(\lambda - a_{22})(\lambda - a_{33}),
  \end{align*}
  d'où $\lambda_1 = a_{11}$, $\lambda_2 = a_{22}$ et $\lambda_3 =
  a_{33}$. %
  \qed
\end{exemple}

Le résultat de l'exemple précédent justifie un théorème.

\begin{thm}
  \label{thm:valeurspropres:triangulaire}
  Si $\mat{A}_{n \times n}$ est une matrice triangulaire (supérieure
  ou inférieure) ou diagonale, alors ses valeurs propres sont les
  éléments de la diagonale.
\end{thm}

De ce théorème, on peut établir les faits suivants pour une matrice
triangulaire:
\begin{enumerate}
\item la trace est égale à la somme des valeurs propres;
\item le déterminant est égal au produit des valeurs propres.
\end{enumerate}
Le théorème suivant confirme que ces résultats tiennent pour toute
matrice carrée.

\begin{thm}
  \label{thm:valeurspropres:trace_et_determinant}
  Soit $\mat{A}_{n \times n}$ une matrice dont les valeurs propres
  sont $\lambda_1, \dots, \lambda_n$ (égalités et valeurs complexes
  comprises). Alors
  \begin{align*}
    \tr(\mat{A}) &= \sum_{i = 1}^n \lambda_i \\
    \det(\mat{A}) &= \prod_{i = 1}^n \lambda_i.
  \end{align*}
\end{thm}
\begin{proof}
  On peut démontrer que le polynôme caractéristique d'une matrice
  carrée $\mat{A}$ est toujours de la forme
  \begin{align*}
    \det(\lambda \mat{I} - \mat{A})
    &= \lambda^n - c_1 \lambda^{n - 1} + \dots + c_n \\
    &= (\lambda - \lambda_1) \cdots (\lambda - \lambda_n),
  \end{align*}
  où
  \begin{align*}
    c_1 &= \lambda_1 + \dots + \lambda_n \\
    c_n &= (-1)^n \lambda_1 \cdots \lambda_n.
  \end{align*}
  (Pensez au cas $n = 2$, soit un polynôme de second degré; vous savez
  que le coefficient du terme de degré un est la somme des racines et
  que le terme constant est le produit des racines.) Il faut
  maintenant établir que $c_1 = \tr(\mat{A})$ et que $c_n =
  (-1)^n \det(\mat{A})$ pour compléter la démonstration. Or, d'une part, on
  vérifie facilement que le coefficient de $\lambda^{n - 1}$ dans le
  polynôme caractéristique provient du produit
  \begin{displaymath}
    (\lambda - a_{11}) \cdots (\lambda - a_{nn}) =
    \lambda^n - (a_{11} + \dots + a_{nn}) \lambda^{n - 1} + \dots
  \end{displaymath}
  dans le calcul du déterminant de $\lambda \mat{I} - \mat{A}$. Par
  conséquent,
  \begin{align*}
    \tr(\mat{A})
    &= \sum_{i = 1}^n a_{ii} \\
    &= c_1 \\
    &= \sum_{i = 1}^n \lambda_i.
  \end{align*}

  D'autre part, en posant $\lambda = 0$ dans le polynôme
  caractéristique, on obtient
  \begin{align*}
    \det(-\mat{A})
    &= (-1)^n \det(\mat{A}) \\
    &= c_n \\
    &= (-1)^n \lambda_1 \cdots \lambda_n,
  \end{align*}
  d'où $\det(\mat{A}) = \prod_{i = 1}^n \lambda_i$.
\end{proof}

Du théorème précédent, il découle que si une valeur propre d'une
matrice est nulle, alors son déterminant est nul et la matrice est
singulière. Cette observation nous permet d'ajouter un énoncé au
\autoref{thm:revision:unification}.

\begin{thm}
  \label{thm:valeurspropres:unification}
  Soit $\mat{A}$ une matrice $n \times n$. Les énoncés suivants
  sont équivalents.
  \begin{enumerate}[widest=10]
  \item $\mat{A}$ est inversible.
  \item $\det(\mat{A}) \neq 0$
  \item $\mathrm{rang}(\mat{A}) = n$
  \item La seule solution de $\mat{Ax} = \mat{0}$ est la solution
    triviale.
  \item Le système d'équations $\mat{Ax} = \mat{b}$ a une solution
    pour tout vecteur $\mat{b}$ et celle-ci est unique.
  \item $\mat{A}$ peut être exprimée comme un produit de matrices
    élémentaires.
  \item Les vecteurs lignes de $\mat{A}$ sont linéairement
    indépendants.
  \item Les vecteurs colonnes de $\mat{A}$ sont linéairement
    indépendants.
  \item Les vecteurs lignes de $\mat{A}$ forment une base de $\R^n$.
  \item Les vecteurs colonnes de $\mat{A}$ forment une base de $R^n$.
  \item $\lambda = 0$ n'est pas une valeur propre de $\mat{A}$.
  \end{enumerate}
\end{thm}

Un dernier résultat: on observe que si $\lambda$ est une valeur propre
de $\mat{A}$ et $\mat{x}$ est un vecteur propre correspondant, alors
\begin{displaymath}
  \mat{A}^2 \mat{x} =
  \mat{A}(\mat{A} \mat{x}) =
  \mat{A}(\lambda \mat{x}) =
  \lambda (\mat{A} \mat{x}) =
  \lambda (\lambda \mat{x}) =
  \lambda^2 \mat{x},
\end{displaymath}
d'où $\lambda^2$ est une valeur propre de $\mat{A}^2$ et $\mat{x}$ est
un vecteur propre correspondant.

\begin{thm}
  Si $\lambda$ est une valeur propre de la matrice $\mat{A}$ et
  $\mat{x}$ est un vecteur propre correspondant, alors
  \begin{itemize}
  \item $\lambda^k$ est une valeur propre de $\mat{A}^k$, $k \in
    \symbb{N}$;
  \item $\mat{x}$ est un vecteur propre correspondant.
  \end{itemize}
\end{thm}
\begin{proof}
  Laissée en exercice.
\end{proof}

\begin{rem}
  On sait que pour une fonction $y = f(x)$ quelconque, $y = f(x - c)$
  correspond à une translation de la fonction de $c$ unités vers la
  gauche. Par analogie, l'équation caractéristique $\det(\lambda
  \mat{I} - \mat{A})$ fournit cette interprétation de la valeur
  propre: c'est le nombre de fois qu'il faut «déplacer» la matrice
  $\mat{A}$ de $\mat{I}$ jusqu'à ce qu'elle devienne singulière.
\end{rem}



\section{Calcul des vecteurs propres}
\label{sec:valeurspropres:vecteurs}

Les vecteurs propres de la matrice $\mat{A}$ correspondant à la valeur
propre $\lambda$ sont les vecteurs non nuls satisfaisant
\begin{displaymath}
  \mat{A} \mat{x} = \lambda \mat{x}
\end{displaymath}
ou, de manière équivalente,
\begin{displaymath}
  (\lambda \mat{I} - \mat{A}) \mat{x} = \mat{0}.
\end{displaymath}
Or, puisque $\det(\lambda \mat{I} - \mat{A}) = 0$:
\begin{itemize}
\item le rang de $\lambda \mat{I} - \mat{A}$ est inférieur à $n$;
\item il existe une solution $(\lambda \mat{I} - \mat{A}) \mat{x} =
  \mat{0}$ autre que la solution triviale;
\item le système d'équations homogène comporte une infinité de
  solutions.
\end{itemize}
Par conséquent, pour chaque valeur propre $\lambda$, on doit trouver
une base de $\R^k$, où
\begin{displaymath}
  k = n - \mathrm{rang}(\lambda \mat{I} - \mat{A}).
\end{displaymath}

\begin{exemple}
  \label{ex:valeurspropres:vecteurs}
  Soit
  \begin{displaymath}
    \mat{A} =
    \begin{bmatrix}
      0 & 0 & -2 \\
      1 & 2 &  1 \\
      1 & 0 &  3
    \end{bmatrix}.
  \end{displaymath}
  L'équation caractéristique de $\mat{A}$ est
  \begin{displaymath}
    (\lambda - 2)^2 (\lambda - 1) = 0,
  \end{displaymath}
  d'où les valeurs propres sont $\lambda_1 = 1$ et $\lambda_2 =
  \lambda_3 = 2$.

  \begin{enumerate}
  \item Cas $\lambda_1 = 1$. On doit trouver $\mat{x} = (x_1, x_2,
    x_3)$ tel que
    \begin{gather*}
      (\mat{I} - \mat{A}) \mat{x} = \mat{0} \\
      \intertext{soit}
      \begin{bmatrix}
         1 &  0 &  2 \\
        -1 & -1 & -1 \\
        -1 &  0 & -2
      \end{bmatrix}
      \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}
      \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix} \\
      \intertext{ou, de manière équivalente,}
      \begin{bmatrix}
        1 &  0 &  2 \\
        0 &  1 & -1 \\
        0 &  0 &  0
      \end{bmatrix}
      \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}
      \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}.
    \end{gather*}
    Par conséquent:
    \begin{itemize}
    \item la solution du système d'équations est $x_1 = -2 x_3$, $x_2
      = x_3$ et $x_3$ est une variable libre;
    \item $(-2s, s, s)$ est un vecteur propre correspondant à $\lambda
      = 1$;
    \item en fait, tout vecteur de la forme $(-2, 1, 1)$ est un
      vecteur propre correspondant à $\lambda = 1$.
    \end{itemize}
    Ainsi, $(-2, 1, 1)$ est une base de vecteurs propres correspondant
    à $\lambda = 1$.
  \item Cas $\lambda_2 = \lambda_3 = 2$. On a
    \begin{gather*}
      (2 \mat{I} - \mat{A}) \mat{x} = \mat{0} \\
      \intertext{soit}
      \begin{bmatrix}
         2 &  0 &  2 \\
        -1 &  0 & -1 \\
        -1 &  0 & -1
      \end{bmatrix}
      \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}
      \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix} \\
      \intertext{ou, de manière équivalente,}
      \begin{bmatrix}
        1 &  0 &  1 \\
        0 &  0 &  0 \\
        0 &  0 &  0
      \end{bmatrix}
      \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}
      \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}.
    \end{gather*}
    Par conséquent:
    \begin{itemize}
    \item la solution est $x_1 = -x_3$, $x_2$ et $x_3$ sont des
      variables libres;
    \item $(s, t, -s)$ est un vecteur propre correspondant à $\lambda
      = 2$;
    \item on a
      \begin{displaymath}
        \begin{bmatrix} s \\ t \\ -s  \end{bmatrix} =
        s \begin{bmatrix} 1 \\ 0 \\ -1  \end{bmatrix} +
        t \begin{bmatrix} 0 \\ 1 \\ 0  \end{bmatrix}.
      \end{displaymath}
    \end{itemize}
    Ainsi $(1, 0, -1)$ et $(0, 1, 0)$ forment une base de vecteurs
    propres correspondant à $\lambda = 2$.
  \end{enumerate}
  \qed
\end{exemple}

\begin{rem}
  Le nombre de vecteurs propres dans la base est \emph{au plus} la
  multiplicité de $\lambda$. Par conséquent, si toutes les valeurs
  propres sont différentes, alors on a $n$ vecteurs propres
  différents.
\end{rem}



\section{Diagonalisation}
\label{sec:valeurspropres:diagonalisation}

La diagonalisation d'une matrice est la principale application des
valeurs et vecteurs propres qu'un étudiant en actuariat est
susceptible de rencontrer dans ses études. Elle joue un rôle dans la
résolution de systèmes d'équations différentielles ordinaires, ainsi
que dans le calcul de l'exponentielle d'une matrice, tel qu'expliqué
dans l'exemple suivant.

\begin{exemple}
  L'exponentielle d'un nombre réel $x$ est définie comme
  \begin{align*}
    e^x &= 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \dots \\
    &= \sum_{n = 0}^\infty \frac{x^n}{n!}.
  \end{align*}
  Par analogie, on définit l'exponentielle d'une matrice $\mat{A}$ ainsi:
  \begin{align*}
    e^{\mat{A}} &= I + \mat{A} + \frac{\mat{A}^2}{2!} +
    \frac{\mat{A}^3}{3!} + \dots \\
    &= \sum_{n = 0}^\infty \frac{\mat{A}^n}{n!},
  \end{align*}
  avec $\mat{A}^0 = \mat{I}$ par convention.

  L'évaluation numérique de l'exponentielle d'une matrice de manière
  efficace, fiable et précise est chose difficile. Dans un article
  célèbre, \citet{Moler:dubious:1978} passent en revue pas moins de 19
  manières différentes de le faire, pour conclure{\dots} qu'aucune méthode
  n'est uniformément meilleure que les autres!

  Cela dit, le calcul de l'exponentielle d'une matrice demeure simple
  si celle-ci est diagonale. Pour les fins de la démonstration et sans
  perte de généralité, nous utiliserons une matrice diagonale
  $\mat{D}$ de dimension $2$:
  \begin{equation*}
    \mat{D} =
    \begin{bmatrix}
      d_1 & 0 \\ 0 & d_2
    \end{bmatrix}.
  \end{equation*}
  Ainsi
  \begin{equation*}
    \mat{D}^n =
    \begin{bmatrix}
      d_1^n & 0 \\ 0 & d_2^n
    \end{bmatrix}
  \end{equation*}
  et, par conséquent,
  \begin{align*}
    e^{\mat{D}} &= \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
    + \begin{bmatrix} d_1 & 0 \\ 0 & d_2 \end{bmatrix}
    + \frac{1}{2!} \begin{bmatrix} d_1^2 & 0 \\ 0 & d_2^2 \end{bmatrix}
    + \frac{1}{3!} \begin{bmatrix} d_1^3 & 0 \\ 0 & d_2^3 \end{bmatrix}
    + \dots \\
    &=
    \begin{bmatrix}
      1 + d_1 + \frac{d_1^2}{2!} + \frac{d_1^3}{3!} + \dots & 0 \\
      0 & 1 + d_2 + \frac{d_2^2}{2!} + \frac{d_2^3}{3!} + \dots
    \end{bmatrix} \\
    &=
    \begin{bmatrix}
      e^{d_1} & 0 \\
      0 & e^{d_2}
    \end{bmatrix}.
  \end{align*}
  Le calcul de l'exponentielle d'une matrice diagonale se résume donc
  à calculer l'exponentielle des éléments de la diagonale.

  Poussons l'idée une étape plus loin. Supposons que $\mat{A}$ est une
  matrice que l'on peut écrire sous la forme
  \begin{equation*}
    \mat{A} = \mat{P} \mat{D} \mat{P^{-1}},
  \end{equation*}
  où $\mat{D}$ est diagonale. Puisque
  \begin{align*}
    \mat{A}^2
    &= (\mat{P} \mat{D} \mat{P}^{-1})(\mat{P} \mat{D} \mat{P}^{-1}) \\
    &= \mat{P} \mat{D}^2 \mat{P}^{-1}, \\
    \mat{A}^3
    &= (\mat{P} \mat{D} \mat{P}^{-1})(\mat{P} \mat{D}^2 \mat{P}^{-1}) \\
    &= \mat{P} \mat{D}^3 \mat{P}^{-1} \\
    &\vdots \\
    \mat{A}^n &= \mat{P} \mat{D}^n \mat{P}^{-1},
  \end{align*}
  alors
  \begin{align*}
    e^{\mat{A}}
    &= \sum_{n = 0}^\infty \frac{\mat{P} \mat{D}^n \mat{P}^{-1}}{n!} \\
    &= \mat{P}
    \left(
      \sum_{n = 0}^\infty \frac{\mat{D}^n}{n!}
    \right)
    \mat{P}^{-1} \\
    &= \mat{P} e^{\mat{D}} \mat{P}^{-1}.
  \end{align*}
  Par conséquent, si l'on peut écrire une matrice $\mat{A}$ sous la forme $\mat{A} =
  \mat{P} \mat{D} \mat{P}^{-1}$ (ou, inversement, si $\mat{P}^{-1}
  \mat{A} \mat{P}$ est diagonale), alors le calcul de son exponentielle
  se résumera essentiellement au calcul de l'exponentielle de la
  matrice diagonale $\mat{D}$ qui est lui-même simple, comme on l'a vu.%
  \qed
\end{exemple}

\begin{definition}
  Une matrice carrée $\mat{A}$ est \emph{diagonalisable} s'il existe
  une matrice inversible $\mat{P}$ tel que
  \begin{displaymath}
    \mat{P}^{-1} \mat{A} \mat{P}
  \end{displaymath}
  est une matrice diagonale.
\end{definition}

Nous établirons qu'une matrice est diagonalisable si elle possède $n$
vecteurs propres linéairement indépendants.

\begin{exemple}
  À l'\autoref{ex:valeurspropres:vecteurs}, on a obtenu que les
  vecteurs propres de la matrice $\mat{A}$ sont
  \begin{align*}
    \mat{p}_1 &= \begin{bmatrix} -2 \\ 1 \\  1 \end{bmatrix} &
    \mat{p}_2 &= \begin{bmatrix}  1 \\ 0 \\ -1 \end{bmatrix} &
    \mat{p}_3 &= \begin{bmatrix}  0 \\ 1 \\  0 \end{bmatrix}.
  \end{align*}
  Ces vecteurs propres sont linéairement indépendants. Vérification
  rapide:
  \begin{displaymath}
    \begin{vmatrix}
      -2 &  1 & 0 \\
       1 &  0 & 1 \\
       1 & -1 & 0
    \end{vmatrix} = 1 \neq 0.
  \end{displaymath}
  \qed
\end{exemple}

Supposons qu'une matrice $\mat{A}_{3 \times 3}$ possède trois vecteurs
propres linéairement indépendants $\mat{p}_1, \dots, \mat{p}_3$ et
soit la matrice $\mat{P}$ formée de ces trois vecteurs dans les
colonnes:
\begin{align*}
  \mat{P}
  &= [\mat{p}_1\, \mat{p}_2\, \mat{p}_3] \\
  &=
  \begin{bmatrix}
    p_{11} & p_{12} & \dots & p_{1n} \\
    p_{21} & p_{22} & \dots & p_{2n} \\
    \vdots & \vdots &      & \vdots \\
    p_{n1} & p_{n2} & \dots & p_{nn}
  \end{bmatrix}.
\end{align*}
Alors,
\begin{align*}
  \mat{A} \mat{P}
  &= [\mat{A} \mat{p}_1\, \mat{A} \mat{p}_2\, \mat{A} \mat{p}_3] \\
  \intertext{et, par définition du vecteur propre,}
  \mat{A} \mat{P}
  &= [\lambda_1 \mat{p}_1\, \lambda_2 \mat{p}_2\, \lambda_3 \mat{p}_3] \\
  &= [\mat{p}_1\, \mat{p}_2\, \mat{p}_3]
  \begin{bmatrix}
    \lambda_1 & 0 & \dots & 0 \\
    0 & \lambda_2 & \dots & 0 \\
    \vdots & \vdots &     & \vdots \\
    0 & 0 & \dots & \lambda_n
  \end{bmatrix} \\
  &= \mat{P} \mat{D},
\end{align*}
où $\mat{D}$ est une matrice diagonale. Or, puisque les colonnes de
$\mat{P}$ sont linéairement indépendantes, $\mat{P}^{-1}$ existe et,
par conséquent,
\begin{displaymath}
  \mat{P}^{-1} \mat{A} \mat{P} = \mat{D} = \diag(\lambda_1, \dots, \lambda_n),
\end{displaymath}
d'où $\mat{A}$ est diagonalisable.

On pourrait faire le cheminement inverse, ce qui justifie le théorème
suivant.

\begin{thm}
  \label{thm:valeurspropres:diagonalisable}
  Soit $\mat{A}$ une matrice $n \times n$. Les énoncés suivants sont
  équivalents.
  \begin{enumerate}
  \item $\mat{A}$ est diagonalisable.
  \item $\mat{A}$ possède $n$ vecteurs propres linéairement
    indépendants.
  \end{enumerate}
  De plus, si $\mat{P}$ est la matrice qui diagonalise $\mat{A}$, alors
  \begin{displaymath}
    \mat{P}^{-1} \mat{A} \mat{P} =
    \begin{bmatrix}
      \lambda_1 & 0 & \dots & 0 \\
      0 & \lambda_2 & \dots & 0 \\
      \vdots & \vdots &     & \vdots \\
      0 & 0 & \dots & \lambda_n
    \end{bmatrix}.
  \end{displaymath}
\end{thm}

La remarque qui suit l'\autoref{ex:valeurspropres:vecteurs}
établissait que si toutes les valeurs propres sont distinctes
(multiplicité $1$), alors on a un total de $n$ vecteurs propres.
Or, on peut démontrer que si les valeurs propres sont distinctes,
alors les vecteurs propres sont linéairement indépendants. Il en
découle le théorème suivant.

\begin{thm}
  \label{thm:valeurspropres:diagonalisable2}
  Si la matrice $\mat{A}_{n \times n}$ possède $n$ valeurs propres
  distinctes, alors elle est diagonalisable.
\end{thm}

\begin{rem}
  La contraposée du théorème précédent indique que si une matrice
  n'est pas diagonalisable, alors ses valeurs propres ne sont pas
  distinctes. En revanche, la matrice peut être diagonalisable même si
  ses valeurs propres ne sont pas distinctes.
\end{rem}

\begin{exemple}
  Les valeurs propres de la matrice
  \begin{displaymath}
    \mat{A} =
    \begin{bmatrix}
      0 & 0 & -2 \\
      1 & 2 &  1 \\
      1 & 0 &  3
    \end{bmatrix}
  \end{displaymath}
  de l'\autoref{ex:valeurspropres:vecteurs} sont $\lambda_1 = 1$
  et $\lambda_2 = \lambda_3 = 2$. Néanmoins, les trois vecteurs
  propres forment une base de $\R^3$. Par conséquent,
  \begin{align*}
    \mat{P}^{-1} \mat{A} \mat{P}
    &=
    \begin{bmatrix}
      -1 & 0 & -1 \\
      -1 & 0 & -2 \\
       1 & 1 &  1
    \end{bmatrix}
    \begin{bmatrix}
      0 & 0 & -2 \\
      1 & 2 &  1 \\
      1 & 0 &  3
    \end{bmatrix}
    \begin{bmatrix}
      -2 &  1 & 0 \\
       1 &  0 & 1 \\
       1 & -1 & 0
    \end{bmatrix} \\
    &=
    \begin{bmatrix}
      1 & 0 & 0 \\
      0 & 2 & 0 \\
      0 & 0 & 2
    \end{bmatrix}.
  \end{align*}
  \qed
\end{exemple}

\begin{exemple}
  Soit
  \begin{displaymath}
    \mat{A} =
    \begin{bmatrix}
       1 & 0 & 0 \\
       1 & 2 & 0 \\
      -3 & 5 & 2
    \end{bmatrix}.
  \end{displaymath}
  Le polynôme caractéristique de $\mat{A}$ est
  \begin{displaymath}
    \det(\lambda \mat{I} - \mat{A}) = (\lambda - 1)(\lambda - 2)^2,
  \end{displaymath}
  d'où les valeurs propres sont $\lambda_1 = 1$ et $\lambda_2 =
  \lambda_3 = 2$. Il est laissé en exercice de vérifier que
  \begin{itemize}
  \item le vecteur propre correspondant à $\lambda = 1$ est $\mat{p}_1
    = (\frac{1}{8}, -\frac{1}{8}, 1)$;
  \item le vecteur propre correspondant à $\lambda = 2$ est $\mat{p}_2
    = (0, 0, 1)$.
  \end{itemize}
  Puisque l'on a seulement deux vecteurs propres linéairement
  indépendants, la matrice $\mat{A}$ n'est pas diagonalisable.
  \qed
\end{exemple}

\begin{exemple}
  Soit
  \begin{displaymath}
    \mat{A} =
    \begin{bmatrix}
      -1 & 2 & 4 &  0 \\
       0 & 3 & 1 &  7 \\
       0 & 0 & 5 &  8 \\
       0 & 0 & 0 & -2
    \end{bmatrix}
  \end{displaymath}
  On a:
  \begin{itemize}
  \item la matrice $\mat{A}$ est triangulaire;
  \item ses valeurs propres sont $\lambda_1 = -1$, $\lambda_2 = 3$,
    $\lambda_4 = 5$ et $\lambda_4 = -2$;
  \item les valeurs propres sont distinctes;
  \item la matrice est diagonalisable.
  \end{itemize}
  \qed
\end{exemple}

\gotorbox{La fonction \code{eigen} calcule les valeurs et vecteurs propres
  d'une matrice dans R. Voir le code informatique de la
  \autoref{sec:valeurspropres:code} pour les détails.}%


\section{Code informatique}
\label{sec:valeurspropres:code}

\def\scriptfilename{valeurs\string_propres.R}

\scriptfile{\scriptfilename}
\lstinputlisting[firstline=13]{\scriptfilename}


\section{Exercices}
\label{chap:valeurspropres:exercices}

\Opensolutionfile{reponses}[reponses-valeurs_propres]
\Opensolutionfile{solutions}[solutions-valeurs_propres]

\begin{Filesave}{reponses}
\bigskip
\section*{Réponses}

\end{Filesave}

\begin{Filesave}{solutions}
\section*{Chapitre \ref*{chap:valeurspropres}}
\addcontentsline{toc}{section}{Chapitre \ref*{chap:valeurspropres}}

\end{Filesave}

<<echo=FALSE>>=
options(width = 50)
@

\begin{exercice}
  \label{ex:valeurspropres:base}
  Trouver l'équation caractéristique, les valeurs propres et les bases
  de vecteurs propres des matrices suivantes.  Vérifier les réponses
  obtenues à l'aide de la fonction \texttt{eigen} de R.
  \begin{enumerate}
    \begin{multicols}{2}
    \item $\begin{bmatrix} 3 & 0 \\ 8 & -1 \end{bmatrix}$
    \item $\begin{bmatrix} 10 & -9 \\ 4 & -2 \end{bmatrix}$
    \end{multicols}
    \begin{multicols}{2}
    \item $\begin{bmatrix}
        4 & 0 & 1 \\
        -2 & 1 & 0 \\
        -2 & 0 & 1
      \end{bmatrix}$
    \item $\begin{bmatrix}
        5 &  6 &  2 \\
        0 & -1 & -8 \\
        1 &  0 & -2
      \end{bmatrix}$
    \end{multicols}
    \begin{multicols}{2}
    \item $\begin{bmatrix}
        0 & 0 &  2 & 0 \\
        1 & 0 &  1 & 0 \\
        0 & 1 & -2 & 0 \\
        0 & 0 &  0 & 1
      \end{bmatrix}$
    \end{multicols}
  \end{enumerate}
  \begin{sol}
    Dans tous les cas, la matrice mentionnée dans l'énoncé est notée
    $\mat{A}$.
    \begin{enumerate}
    \item On a
      \begin{align*}
        \det(\lambda \mat{I} - \mat{A})
        &=
        \begin{vmatrix}
          \lambda - 3 & 0 \\
          -8 & \lambda + 1
        \end{vmatrix} \\
        &= (\lambda - 3)(\lambda + 1).
      \end{align*}
      Les valeurs propres sont donc $\lambda_1 = 3$ et $\lambda_2 =
      -1$. D'une part, la forme échelonnée du système d'équations $(3
      \mat{I} - \mat{A}) \mat{x} = \mat{0}$ est
      \begin{displaymath}
        \begin{bmatrix} 0 & 0 \\ 1 & -\frac{1}{2} \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = s/2$ et $x_2 = s$. Une base de vecteurs propres
      correspondant à $\lambda = 3$ est donc $(\frac{1}{2}, 1)$.
      D'autre part, le système d'équations $(-\mat{I} - \mat{A})
      \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = 0$ et $x_2 = s$. Une base de vecteurs propres
      correspondant à $\lambda = -1$ est donc $(0, 1)$. Vérification:
<<echo=TRUE>>=
m <- matrix(c(3, 8, 0, -1), nrow = 2)
eigen(m)
@
      On remarque que les vecteurs propres obtenus avec \texttt{eigen}
      sont normalisés de sorte que leur norme soit toujours égale à 1.
    \item On a
      \begin{align*}
        \det(\lambda \mat{I} - \mat{A})
        &= \begin{vmatrix}
          \lambda - 10 & 9 \\
          -4 & \lambda + 2
        \end{vmatrix} \\
        &= (\lambda - 10)(\lambda + 2) + 36 \\
        &= (\lambda - 4)^2.
      \end{align*}
      On a donc une seule valeur propre: $\lambda = 4$.  Le système
      d'équations $(4 \mat{I} - \mat{A}) \mat{x} = \mat{0}$ se réduit
      à
      \begin{displaymath}
        \begin{bmatrix} 1 & -\frac{3}{2} \\ 0 & 0 \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = 3s/2$ et $x_2 = s$. Une base de vecteurs propres
      correspondant à $\lambda = 4$ est donc $(\frac{3}{2}, 1)$.
      Vérification:
<<echo=TRUE>>=
m <- matrix(c(10, 4, -9, -2), nrow = 2)
eigen(m)
@
    \item On a
      \begin{align*}
        \det(\lambda \mat{I} - \mat{A})
        &= \begin{vmatrix}
          \lambda - 4 & 0 & -1 \\
          2 & \lambda - 1 & 0 \\
          2 & 0 & \lambda - 1
        \end{vmatrix} \\
        &= (\lambda - 4)(\lambda - 1)^2 + 2(\lambda - 1) \\
        &= (\lambda - 1)(\lambda - 2)(\lambda - 3).
      \end{align*}
      Les valeurs propres sont donc $\lambda_1 = 1$, $\lambda_2 = 2$
      et $\lambda_3 = 3$.  En premier lieu, le système d'équations
      $(\mat{I} - \mat{A}) \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 & 0 \\
          0 & 0 & 1 \\
          0 & 0 & 0
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = x_3 = 0$ et $x_2 = s$. Une base de vecteurs propres
      correspondant à $\lambda = 1$ est donc $(0, 1, 0)$.
      Deuxièmement, le système d'équations $(2\mat{I} - \mat{A})
      \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 &  0 & \frac{1}{2} \\
          0 &  1 & -1 \\
          0 &  0 &  0
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = -s/2$, $x_2 = s$ et $x_3 = s$. Une base de vecteurs
      propres correspondant à $\lambda = 2$ est donc $(-\frac{1}{2},
      1, 1)$.  Finalement, le système d'équations $(3\mat{I} -
      \mat{A}) \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 &  0 &  1 \\
          0 &  1 & -1 \\
          0 &  0 &  0
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = -s$, $x_2 = s$ et $x_3 = s$. Une base de vecteurs
      propres correspondant à $\lambda = 2$ est donc $(-1, 1, 1)$.
      Vérification:
<<echo=TRUE>>=
m <- matrix(c(4, -2, -2, 0, 1, 0, 1, 0, 1),
            nrow = 3)
eigen(m)
@
    \item On a
      \begin{align*}
        \det(\lambda \mat{I} - \mat{A})
        &= \begin{vmatrix}
          \lambda - 5 &  -6 &  -2 \\
          0 & \lambda + 1 & 8 \\
          -1 &  0 & \lambda + 2
        \end{vmatrix} \\
        &= (\lambda - 5)(\lambda + 1)(\lambda + 2) - 2(\lambda + 1) + 48 \\
        &= \lambda^3 - 2 \lambda^2 - 15 \lambda + 36 \\
        &= (\lambda - 3)^2 (\lambda + 4).
      \end{align*}
      Les valeurs propres sont donc $\lambda_1 = 3$ et $\lambda_2 =
      \lambda_3 = -4$.  En premier lieu, le système d'équations
      $(3\mat{I} - \mat{A}) \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 & -5 \\
          0 & 1 &  2 \\
          0 & 0 &  0
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = 5 s$, $x_2 = -2s$ et $x_3 = s$. Une base de vecteurs
      propres correspondant à $\lambda = 3$ est donc $(5, -2, 1)$.
      Deuxièmement, le système d'équations $(-4\mat{I} - \mat{A})
      \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 & 2 \\
          0 & 1 & -\frac{8}{3} \\
          0 & 0 & 0
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = -2s$, $x_2 = 8s/3$ et $x_3 = s$. Une base de
      vecteurs propres correspondant à $\lambda = -4$ est donc $(-2,
      \frac{8}{3}, 1)$.  Vérification:
<<echo=TRUE>>=
m <- matrix(c(5, 0, 1, 6, -1, 0, 2, -8, -2),
            nrow = 3)
eigen(m)
@
    \item On a
      \begin{align*}
        \det(\lambda \mat{I} - \mat{A})
        &= \begin{vmatrix}
          \lambda & 0 &  -2 & 0 \\
          -1 & \lambda &  -1 & 0 \\
          0 & -1 & \lambda + 2 & 0 \\
          0 & 0 &  0 & \lambda - 1
        \end{vmatrix} \\
        &= (\lambda - 1)
        \begin{vmatrix}
          \lambda & 0 &  -2 \\
          -1 & \lambda &  -1 \\
          0 & -1 & \lambda + 2
        \end{vmatrix} \\
        &= (\lambda - 1)(\lambda^3 + 2 \lambda^2 - \lambda - 2) \\
        &= (\lambda - 1)^2 (\lambda + 1)(\lambda + 2).
      \end{align*}
      Les valeurs propres sont donc $\lambda_1 = \lambda_2 = 1$,
      $\lambda_3 = -1$ et $\lambda_4 = -2$.  En premier lieu, le
      système d'équations $(\mat{I} - \mat{A}) \mat{x} = \mat{0}$ se
      réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 & -2 & 0 \\
          0 & 1 & -3 & 0 \\
          0 & 0 &  0 & 0 \\
          0 & 0 &  0 & 0 \\
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = 2s$, $x_2 = 3s$, $x_3 = s$ et $x_4 = t$. Or, on a que $(2s,
      3s, s, t) = s(2, 3, 1, 0) + t (0, 0, 0, 1)$. Une base de
      vecteurs propres correspondant à $\lambda = 1$ est donc composée
      des vecteurs $(2, 3, 1, 0)$ et $(0, 0, 0, 1)$.  Deuxièmement, le
      système d'équations $(-\mat{I} - \mat{A}) \mat{x} = \mat{0}$ se
      réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 &  2 & 0 \\
          0 & 1 & -1 & 0 \\
          0 & 0 &  0 & 1 \\
          0 & 0 &  0 & 0 \\
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = -2s$, $x_2 = s$, $x_3 = s$ et $x_4 = 0$. Une base de
      vecteurs propres correspondant à $\lambda = -1$ est donc $(-2,
      1, 1, 0)$.  Finalement, le système d'équations $(-2\mat{I} -
      \mat{A}) \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 &  0 &  1 &  0 \\
          0 &  1 &  0 &  0 \\
          0 &  0 &  0 &  1 \\
          0 &  0 &  0 &  0 \\
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = -s$, $x_2 = 0$, $x_3 = s$ et $x_4 = 0$. Une base de
      vecteurs propres correspondant à $\lambda = -2$ est donc $(-1,
      0, 1, 0)$.  Vérification:
<<echo=TRUE>>=
m <- matrix(c(0, 1, 0, 0, 0, 0, 1, 0,
              2, 1, -2, 0, 0, 0, 0, 1),
            nrow = 4)
eigen(m)
@
    \end{enumerate}
  \end{sol}
  \begin{rep}
    \begin{enumerate}
    \item $\lambda =  3$ avec base $(\frac{1}{2}, 1)$,
          $\lambda = -1$ avec base $(0, 1)$
    \item $\lambda =  4$ avec base $(\frac{3}{2}, 1)$
    \item $\lambda =  1$ avec base $(0, 1, 0)$,
          $\lambda =  2$ avec base $(-\frac{1}{2}, 1, 1)$,
          $\lambda =  3$ avec base $(-1, 1, 1)$
    \item $\lambda = -4$ avec base $(-2, \frac{8}{3}, 1)$,
          $\lambda =  3$ avec base $(5, -2, 1)$
    \item $\lambda =  1$ avec base $(0, 0, 0, 1)$ et $(2, 3, 1, 0)$,
          $\lambda = -2$ avec base $(-1, 0, 1, 0)$,
          $\lambda = -1$ avec base $(-2, 1, 1, 0)$
    \end{enumerate}
  \end{rep}
\end{exercice}

\begin{exercice}
  \label{ex:valeurspropres:puissance}
  Démontrer que si $\lambda$ est une valeur propre de la matrice
  $\mat{A}$, alors $\lambda^k$ est une valeur propre de $\mat{A}^k$.
  \begin{sol}
    On procède par induction. Premièrement, l'énoncé est clairement
    vrai pour $k = 1$. On suppose par la suite qu'il est vrai pour $k
    = n$, soit que si $\mat{A} \mat{x} = \lambda \mat{x}$, alors
    $\mat{A}^n \mat{x} = \lambda^n \mat{x}$. Ainsi,
    \begin{displaymath}
      \mat{A}^{n + 1} \mat{x} =
      \mat{A}(\mat{A}^n \mat{x}) =
      \mat{A}(\lambda^n \mat{x}) =
      \lambda^n (\mat{A} \mat{x}) =
      \lambda^n (\lambda \mat{x}) =
      \lambda^{n + 1} \mat{x},
    \end{displaymath}
    d'où l'énoncé est vrai pour $k = n + 1$. Ceci complète la preuve.
  \end{sol}
\end{exercice}

\begin{exercice}
  Trouver les valeurs et vecteurs propres de $\mat{A}^{25}$ si
  \begin{displaymath}
    \mat{A} =
    \begin{bmatrix}
      -1 & -2 & -2 \\
       1 &  2 &  1 \\
      -1 & -1 &  0
    \end{bmatrix}.
  \end{displaymath}
  \begin{sol}
    On va utiliser les résultats de l'\autoref{ex:valeurspropres:puissance}. Tout d'abord,
    \begin{align*}
      \det(\lambda \mat{I} - \mat{A})
      &= \begin{vmatrix}
        \lambda + 1 & 2 & 2 \\
        -1 &  \lambda - 2 &  -1 \\
        1 & 1 & \lambda
      \end{vmatrix} \\
      &= (\lambda + 1)(\lambda - 1)^2,
    \end{align*}
    d'où les valeurs propres de $\mat{A}$ sont $\lambda_1 = \lambda_2
    = 1$ et $\lambda_3 = -1$. Par conséquent, les valeurs propres de
    $\mat{A}^{25}$ sont $\lambda_1 = \lambda_2 = 1^{25} = 1$ et
    $\lambda_3 = (-1)^{25} = -1$.  Toujours par le résultat de
    l'\autoref{ex:valeurspropres:puissance}, les vecteurs propres
    de $\mat{A}$ correspondant à $\lambda = 1$ et $\lambda = -1$ sont
    également des vecteurs propres de $\mat{A}^{25}$. Or, le système
    d'équations $(\mat{I} - \mat{A}) \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 &  1 & 1 \\
          0 &  0 & 0 \\
          0 &  0 & 0
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = -s - t$, $x_2 = s$ et $x_3 = t$. Puisque $(-s - t,
      s, t) = s(-1, 1, 0) + t(-1, 0, 1)$, une base de vecteurs propres
      correspondant à $\lambda = 1$ est composée de $(-1, 1, 0)$ et
      $(-1, 0, 1)$.  D'autre part, le système d'équations $(-\mat{I} -
      \mat{A}) \mat{x} = \mat{0}$ se réduit à
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 & -2 \\
          0 & 1 &  1 \\
          0 & 0 &  0
        \end{bmatrix}
        \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
        \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
      \end{displaymath}
      soit $x_1 = 2s$, $x_2 = -s$ et $x_3 = s$. Une base de vecteurs
      propres correspondant à $\lambda = -1$ est donc $(2, -1, 1)$.
  \end{sol}
  \begin{rep}
    $\lambda =  1$ avec base $(-1, 1, 0)$ et $(-1, 0, 1)$,
    $\lambda = -1$ avec base $(2, -1, 1)$
  \end{rep}
\end{exercice}

\begin{exercice}
  Soit
  \begin{displaymath}
    (x - x_1)(x - x_2) \cdots (x - x_n) = x^n + c_1 x^{n - 1} + \dots + c_n.
  \end{displaymath}
  Démontrer par induction les identités suivantes.
  \begin{enumerate}
  \item $c_1 = - \sum_{i=1}^n x_i$
  \item $c_n = (-1)^n \prod_{i=1}^n x_i$
  \end{enumerate}
  \begin{sol}
    On peut démontrer les deux résultats simultanément.  Tout d'abord,
    les résultats sont clairement vrais pour $n = 1$, c'est-à-dire
    $c_1 = c_n = - x_1$. On suppose ensuite que les résultats sont
    vrais pour $n = k$, soit
    \begin{displaymath}
      \prod_{i = 1}^k (x - x_i) =
      x^k + \left(- \sum_{i = 1}^k x_i \right) x^{k - 1} + \dots +
      \prod_{i = 1}^k x_i.
    \end{displaymath}
    Si $n = k + 1$, on a
    \begin{align*}
      \prod_{i = 1}^{k + 1} (x - x_i)
      &=
      \left[
        \prod_{i = 1}^k (x - x_i)
      \right]
      (x - x_{k + 1}) \\
      &=
      \left[
        x^k + \left(- \sum_{i = 1}^k x_i \right) x^{k - 1} + \dots +
        \prod_{i = 1}^k x_i
      \right]
      (x - x_{k + 1}) \\
      &= x^{k + 1} + \left( - \sum_{i = 1}^k x_i - x_{k + 1} \right)
      x^k + \dots + x_{k + 1} \prod_{i = 1}^k x_i \\
      &= x^{k + 1} + \left( - \sum_{i = 1}^{k + 1} x_i \right) x^k +
      \dots + \prod_{i = 1}^{k + 1} x_i.
    \end{align*}
    Les résultats sont donc vrais pour $n = k + 1$. Ceci complète la
    preuve.
  \end{sol}
\end{exercice}

\begin{exercice}
  Démontrer que l'équation caractéristique d'une matrice
  $\mat{A}_{2 \times 2}$ est
  \begin{displaymath}
    \lambda^2 - \tr(\mat{A}) \lambda + \det(\mat{A}) = 0.
  \end{displaymath}
  \begin{sol}
    Soit
    \begin{displaymath}
      \mat{A} =
      \begin{bmatrix}
        a_{11} & a_{12} \\ a_{21} & a_{22}
      \end{bmatrix}.
    \end{displaymath}
    Le polynôme caractéristique de cette matrice est
    \begin{align*}
      \det(\lambda \mat{I} - \mat{A})
      &=
      \begin{vmatrix}
        \lambda - a_{11} & -a_{12} \\ -a_{21} & \lambda - a_{22}
      \end{vmatrix} \\
      &= (\lambda - a_{11})(\lambda - a_{22}) - a_{12} a_{21} \\
      &= \lambda^2 - (a_{11} + a_{22}) \lambda +
      (a_{11} a_{22} - a_{12} a_{21}) \\
      &= \lambda^2 - \tr(\mat{A}) \lambda + \det(\mat{A}),
    \end{align*}
    d'où l'équation caractéristique est $\lambda^2 - \tr(\mat{A})
    \lambda + \det(\mat{A}) = 0$.
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:valeurspropres:inverse}
  Démontrer que si $\lambda$ est une valeur propre de la matrice
  inversible $\mat{A}$ et que $\mat{x}$ est un vecteur propre
  correspondant, alors $\lambda^{-1}$ est une valeur propre de
  $\mat{A}^{-1}$ et $\mat{x}$ est un vecteur propre correspondant.
  \begin{sol}
    On a $\mat{A} \mat{x} = \lambda \mat{x}$. En multipliant de part
    et d'autre (par la gauche) par $\mat{A}^{-1}$, on obtient $\mat{x}
    = \lambda \mat{A}^{-1} \mat{x}$, soit $\mat{A}^{-1} \mat{x} =
    \lambda^{-1} \mat{x}$. Par conséquent, $\lambda^{-1}$ est une
    valeur propre de $\mat{A}^{-1}$ et $\mat{x}$ est un vecteur propre
    correspondant.
  \end{sol}
\end{exercice}

\begin{exercice}
  Trouver les valeurs propres et les bases de vecteurs propres de
  $\mat{A}^{-1}$, où
  \begin{displaymath}
    \mat{A} =
    \begin{bmatrix}
      -2 & 2 & 3 \\
      -2 & 3 & 2 \\
      -4 & 2 & 5
    \end{bmatrix}
  \end{displaymath}
  \begin{sol}
    On utilise le résultat de l'\autoref{ex:valeurspropres:inverse} pour
    éviter de devoir calculer l'inverse de la matrice. Le polynôme
    caractéristique de la matrice $\mat{A}$ est
    \begin{align*}
      \det(\lambda \mat{I} - \mat{A})
      &= \begin{vmatrix}
        \lambda + 2 & -2 & -3 \\
        2 &  \lambda - 3 & -2 \\
        4 & -2 & \lambda - 5
      \end{vmatrix} \\
      &= \lambda^3 - 6 \lambda^2 + 11 \lambda - 6 \\
      &= (\lambda - 1)(\lambda - 2)(\lambda - 3),
    \end{align*}
    d'où les valeurs propres de $\mat{A}$ sont $\lambda_1 = 1$,
    $\lambda_2 = 2$ et $\lambda_3 = 3$. Par conséquent, les valeurs
    propres de $\mat{A}^{-1}$ sont $\lambda_1 = 1$, $\lambda_2 =
    \frac{1}{2}$ et $\lambda_3 = \frac{1}{3}$. Toujours par le
    résultat de l'\autoref{ex:valeurspropres:inverse}, les
    vecteurs propres de $\mat{A}$ correspondant à $\lambda = 1$,
    $\lambda = 2$ et $\lambda = 3$ sont également des vecteurs propres
    de $\mat{A}^{-1}$ correspondant à $\lambda_1 = 1$, $\lambda_2 =
    \frac{1}{2}$ et $\lambda_3 = \frac{1}{3}$. Or, le système
    d'équations $(\mat{I} - \mat{A}) \mat{x} = \mat{0}$ se réduit à
    \begin{displaymath}
      \begin{bmatrix}
        1 & 0 & -1 \\
        0 & 1 &  0 \\
        0 & 0 &  0
      \end{bmatrix}
      \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
      \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
    \end{displaymath}
    soit $x_1 = s$, $x_2 = 0$ et $x_3 = s$. Une base de vecteurs
    propres correspondant à $\lambda = 1$ est donc $(1, 0, 1)$.
    D'autre part, le système d'équations $(2\mat{I} - \mat{A}) \mat{x}
    = \mat{0}$ se réduit à
    \begin{displaymath}
      \begin{bmatrix}
        1 & -\frac{1}{2} & 0 \\
        0 &  0 & 1 \\
        0 &  0 & 0
      \end{bmatrix}
      \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
      \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
    \end{displaymath}
    soit $x_1 = s/2$, $x_2 = s$ et $x_3 = 0$. Une base de vecteurs
    propres correspondant à $\lambda = 2$ (ou $\lambda = \frac{1}{2}$)
    est donc $(\frac{1}{2}, 1, 0)$.  Finalement, le système
    d'équations $(3\mat{I} - \mat{A}) \mat{x} = \mat{0}$ se réduit à
    \begin{displaymath}
      \begin{bmatrix}
        1 &  0 & -1 \\
        0 &  1 & -1 \\
        0 &  0 &  0
      \end{bmatrix}
      \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} =
      \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix},
    \end{displaymath}
    soit $x_1 = s$, $x_2 = s$ et $x_3 = s$. Une base de vecteurs
    propres correspondant à $\lambda = 3$ (ou $\lambda = \frac{1}{3}$)
    est donc $(1, 1, 1)$.
  \end{sol}
  \begin{rep}
    $\lambda = 1$ avec base $(1, 0, 1)$,
    $\lambda = \frac{1}{2}$ avec base $(\frac{1}{2}, 1, 0)$,
    $\lambda = \frac{1}{3}$ avec base $(1, 1, 1)$
  \end{rep}
\end{exercice}

\begin{exercice}
  Démontrer que tout vecteur est un vecteur propre de la matrice
  identité correspondant à la valeur propre $\lambda = 1$.
  \begin{sol}
    Le résultat découle simplement du fait que l'équation $\mat{I}
    \mat{x} = \mat{x}$ est vraie pour tout vecteur $\mat{x}$.
  \end{sol}
\end{exercice}

\begin{exercice}
  Pour chacune des matrices $\mat{A}$ ci-dessous:
  \begin{enumerate}[i)]
  \item trouver les valeurs propres de la matrice;
  \item trouver le rang de la matrice $\lambda \mat{I} - \mat{A}$ pour
    chaque valeur propre $\lambda$;
  \item déterminer si la matrice est diagonalisable;
  \item si la matrice est diagonalisable, trouver la matrice $\mat{P}$
    qui diagonalise $\mat{A}$ et $\mat{P}^{-1} \mat{AP}$;
  \item vérifier les réponses en iv) avec la fonction \texttt{eigen}
    de R.
  \end{enumerate}
  \begin{enumerate}
    \begin{multicols}{2}
    \item $\begin{bmatrix} 2 & 0 \\ 1 & 2 \end{bmatrix}$
    \item $\begin{bmatrix}
        4 &  0 &  1 \\
        2 &  3 &  2 \\
        1 & 0 & 4
      \end{bmatrix}$
    \end{multicols}
    \begin{multicols}{2}
    \item $\begin{bmatrix}
        3 &  0 &  0 \\
        0 &  2 &  0 \\
        0 & 1 & 2
      \end{bmatrix}$
    \item $\begin{bmatrix}
        -1 &  4 & -2 \\
        -3 &  4 &  0 \\
        -3 & 1 & 3
      \end{bmatrix}$
    \end{multicols}
    \begin{multicols}{2}
    \item $\begin{bmatrix}
        -2 &  0 &  0 &  0 \\
        0 & -2 &  5 & -5 \\
        0 &  0 &  3 &  0 \\
        0 & 0 & 0 & 3
      \end{bmatrix}$
    \end{multicols}
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item Le polynôme caractéristique est $\lambda^2 - 4 \lambda + 4 =
      (\lambda - 2)^2$, donc les valeurs propres sont $\lambda_1 =
      \lambda_2 = 2$. On a donc
      \begin{displaymath}
        2 \mat{I} - \mat{A} =
        \begin{bmatrix}
          0 & 0 \\ -1 & 0
        \end{bmatrix},
      \end{displaymath}
      d'où $\mathrm{rang}(2 \mat{I} - \mat{A}) = 1$. Puisque la
      matrice $\mat{A}$ ne possède qu'un seul vecteur propre, elle
      n'est pas diagonalisable.  Vérification:
<<echo=TRUE>>=
m <- matrix(c(2, 1, 0, 2), nrow = 2)
eigen(m)
@
    \item Le polynôme caractéristique est $(\lambda - 3)(\lambda^2 - 8
      \lambda + 15) = (\lambda - 3)^2 (\lambda - 5)$, donc les valeurs
      propres sont $\lambda_1 = \lambda_2 = 3$ et $\lambda_3 = 5$.  La
      forme échelonnée de la matrice $3 \mat{I} - \mat{A}$ est
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 & 1 \\
          0 & 0 & 0 \\
          0 & 0 & 0
        \end{bmatrix},
      \end{displaymath}
      d'où $\mathrm{rang}(3 \mat{I} - \mat{A}) = 1$. La base de
      vecteurs propres correspondant à $\lambda = 3$ est composée des
      vecteurs $(-1, 0, 1)$ et $(0, 1, 0)$.  D'autre part, la forme
      échelonnée de la matrice $5 \mat{I} - \mat{A}$ est
      \begin{displaymath}
        \begin{bmatrix}
          1 &  0 & -1 \\
          0 &  1 & -2 \\
          0 &  0 &  0
        \end{bmatrix}
      \end{displaymath}
      d'où $\mathrm{rang}(5 \mat{I} - \mat{A}) = 2$. La base de
      vecteurs propres correspondant à $\lambda = 5$ est $(1, 2, 1)$.
      Bien que les valeurs propres de la matrice $\mat{A}$ ne sont pas
      toutes distinctes, les vecteurs propres $(1, 0, -1)$, $(0, 1,
      0)$ et $(1, 2, 1)$ sont linéairement indépendants. Par
      conséquent, la matrice
      \begin{align*}
        \mat{P}
        &=
        \begin{bmatrix}
          -1 & 0 & 1 \\ 0 & 1 & 2 \\ 1 & 0 & 1
        \end{bmatrix} \\
        \intertext{diagonalise $\mat{A}$ et}
        \mat{P}^{-1} \mat{AP}
        &=
        \begin{bmatrix}
          3 & 0 & 0 \\ 0 & 3 & 0 \\ 0 & 0 & 5
        \end{bmatrix}.
      \end{align*}
      Vérification:
<<echo=TRUE>>=
m <- matrix(c(4, 2, 1, 0, 3, 0, 1, 2, 4), nrow = 3)
eigen(m)
@
    \item La matrice étant triangulaire, on sait immédiatement que les
      valeurs propres sont $\lambda_1 = 3$ et $\lambda_2 = \lambda_3 =
      2$. La forme échelonnée de la matrice $3 \mat{I} - \mat{A}$ est
      \begin{displaymath}
        \begin{bmatrix}
          0 & 1 & 0 \\
          0 & 0 & 1 \\
          0 & 0 & 0
        \end{bmatrix},
      \end{displaymath}
      d'où $\mathrm{rang}(3 \mat{I} - \mat{A}) = 2$. La base de
      vecteurs propres correspondant à $\lambda = 3$ est $(1, 0, 0)$.
      D'autre part, la forme échelonnée de la matrice $2 \mat{I} -
      \mat{A}$ est
      \begin{displaymath}
        \begin{bmatrix}
          1 &  0 &  0 \\
          0 &  1 &  0 \\
          0 &  0 &  0
        \end{bmatrix}
      \end{displaymath}
      d'où $\mathrm{rang}(2 \mat{I} - \mat{A}) = 2$. La base de
      vecteurs propres correspondant à $\lambda = 2$ est $(0, 0, 1)$.
      Par conséquent, la matrice $\mat{A}$ n'a pas trois vecteurs
      linéairement indépendants, donc elle n'est pas diagonalisable.
      Vérification:
<<echo=TRUE>>=
m <- matrix(c(3, 0, 0, 0, 2, 1, 0, 0, 2), nrow = 3)
eigen(m)
@
    \item Le polynôme caractéristique est $\lambda^3 - 6 \lambda^2 +
      11 \lambda - 6 = (\lambda - 1)(\lambda - 2)(\lambda - 3)$, donc
      les valeurs propres sont $\lambda_1 = 1$, $\lambda_2 = 2$ et
      $\lambda_3 = 3$. Les valeurs propres étant distinctes, la
      matrice est diagonalisable. Or, la forme échelonnée de la
      matrice $\mat{I} - \mat{A}$ est
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 & -1 \\
          0 & 1 & -1 \\
          0 & 0 &  0
        \end{bmatrix},
      \end{displaymath}
      d'où $\mathrm{rang}(\mat{I} - \mat{A}) = 2$. La base de vecteurs
      propres correspondant à $\lambda = 1$ est $(1, 1, 1)$.
      Deuxièmement, la forme échelonnée de la matrice $2 \mat{I} -
      \mat{A}$ est
      \begin{displaymath}
        \begin{bmatrix}
          1 &  0 & -\frac{2}{3} \\
          0 &  1 &  -1 \\
          0 &  0 &  0
        \end{bmatrix}
      \end{displaymath}
      d'où $\mathrm{rang}(2 \mat{I} - \mat{A}) = 2$ et la base de
      vecteurs propres correspondant à $\lambda = 2$ est $(2, 3, 3)$.
      Enfin, la forme échelonnée de la matrice $3 \mat{I} - \mat{A}$
      est
      \begin{displaymath}
        \begin{bmatrix}
          1 &  0 & -\frac{1}{4} \\
          0 &  1 & -\frac{3}{4} \\
          0 &  0 & 0
        \end{bmatrix}
      \end{displaymath}
      d'où $\mathrm{rang}(3 \mat{I} - \mat{A}) = 2$ et la base de
      vecteurs propres correspondant à $\lambda = 3$ est $(1, 3, 4)$.
      Par conséquent,
      \begin{align*}
        \mat{P}
        &=
        \begin{bmatrix}
          1 & 2 & 1 \\ 1 & 3 & 3 \\ 1 & 3 & 4
        \end{bmatrix} \\
        \intertext{diagonalise $\mat{A}$ et}
        \mat{P}^{-1} \mat{AP}
        &=
        \begin{bmatrix}
          1 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 3 & 0
        \end{bmatrix}.
      \end{align*}
      Vérification:
<<echo=TRUE>>=
m <- matrix(c(-1, -3, -3, 4, 4, 1, -2, 0, 3),
            nrow = 3)
eigen(m)
@
    \item La matrice est triangulaire: les valeurs propres sont donc
      $\lambda_1 = \lambda_2 = -2$ et $\lambda_3 = \lambda_4 = 3$. La
      forme échelonnée de la matrice $-2 \mat{I} - \mat{A}$ est
      \begin{displaymath}
        \begin{bmatrix}
          0 & 0 & 1 & 0 \\
          0 & 0 & 0 & 1 \\
          0 & 0 & 0 & 0 \\
          0 & 0 & 0 & 0 \\
        \end{bmatrix},
      \end{displaymath}
      d'où $\mathrm{rang}(-2 \mat{I} - \mat{A}) = 2$ et la base de
      vecteurs propres correspondant à $\lambda = -2$ est composée des
      vecteurs $(1, 0, 0, 0)$ et $(0, 1, 0, 0)$.  D'autre part, la
      forme échelonnée de la matrice $3 \mat{I} - \mat{A}$ est
      \begin{displaymath}
        \begin{bmatrix}
          1 & 0 &  0 & 0 \\
          0 & 1 & -1 & 1 \\
          0 & 0 &  0 & 0 \\
          0 & 0 &  0 & 0 \\
        \end{bmatrix}
      \end{displaymath}
      d'où $\mathrm{rang}(2 \mat{I} - \mat{A}) = 2$ et la base de
      vecteurs propres correspondant à $\lambda = 3$ est composée des
      vecteurs $(0, 1, 1, 0)$ et $(0, -1, 0, 1)$.  Les valeurs propres
      de la matrice $\mat{A}$ ne sont pas toutes distinctes, mais les
      vecteurs propres $(1, 0, 0, 0)$, $(0, 1, 0, 0)$, $(0, 1, 1, 0)$
      et $(0, -1, 0, 1)$ sont linéairement indépendants. Par
      conséquent, la matrice
      \begin{align*}
        \mat{P}
        &=
        \begin{bmatrix}
          1 & 0 & 0 &  0 \\
          0 & 1 & 1 & -1 \\
          0 & 0 & 1 &  0 \\
          0 & 0 & 0 &  1 \\
        \end{bmatrix} \\
        \intertext{diagonalise $\mat{A}$ et}
        \mat{P}^{-1} \mat{AP}
        &=
        \begin{bmatrix}
          -2 &  0 & 0 & 0 \\
           0 & -2 & 0 & 0 \\
           0 &  0 & 3 & 0 \\
           0 &  0 & 0 & 3 \\
        \end{bmatrix}.
      \end{align*}
      Vérification:
<<echo=TRUE>>=
m <- matrix(c(-2, 0, 0, 0, 0, -2, 0, 0,
              0, 5, 3, 0, 0, -5, 0, 3),
            nrow = 4)
eigen(m)
@
    \end{enumerate}
  \end{sol}
  \begin{rep}
    \begin{enumerate}
    \item pas diagonalisable
    \item $\mat{P} =
      \begin{bmatrix}
         1 & 0 & 1 \\
         0 & 1 & 2 \\
        -1 & 0 & 1
      \end{bmatrix}$,
      $\mat{P}^{-1} \mat{AP} =
      \begin{bmatrix}
        3 & 0 & 0 \\
        0 & 3 & 0 \\
        0 & 0 & 5
      \end{bmatrix}$
    \item pas diagonalisable
    \item $\mat{P} =
      \begin{bmatrix}
        1 & 2 & 1 \\
        1 & 3 & 3 \\
        1 & 3 & 4
      \end{bmatrix}$,
      $\mat{P}^{-1} \mat{AP} =
      \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 2 & 0 \\
        0 & 0 & 3
      \end{bmatrix}$
    \item $\mat{P} =
      \begin{bmatrix}
          1 & 0 & 0 &  0 \\
          0 & 1 & 1 & -1 \\
          0 & 0 & 1 &  0 \\
          0 & 0 & 0 &  1 \\
      \end{bmatrix}$,
      $\mat{P}^{-1} \mat{AP} =
      \begin{bmatrix}
         -2 &  0 & 0 & 0 \\
          0 & -2 & 0 & 0 \\
          0 &  0 & 3 & 0 \\
          0 &  0 & 0 & 3
       \end{bmatrix}$
    \end{enumerate}
  \end{rep}
\end{exercice}

\Closesolutionfile{reponses}
\Closesolutionfile{solutions}

\input{reponses-valeurs_propres}

%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "methodes-numeriques-en-actuariat_algebre-lineaire.tex"
%%% coding: utf-8
%%% End:
