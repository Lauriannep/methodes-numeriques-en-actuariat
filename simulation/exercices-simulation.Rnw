\section{Exercices}
\label{sec:simulation:exercices}

%%%
%%% Fichers de solutions et de réponses
%%%

\Opensolutionfile{reponses}[reponses-simulation]
\Opensolutionfile{solutions}[solutions-simulation]

\begin{Filesave}{reponses}
\bigskip
\section*{Réponses}

\end{Filesave}

\begin{Filesave}{solutions}
\section*{Chapitre \ref*{chap:simulation}}
\addcontentsline{toc}{section}{Chapitre \ref*{chap:simulation}}

\end{Filesave}

%%%
%%% Début des exercices
%%%

Les étudiants jugent souvent que les exercices de ce chapitre sont
plus difficiles que ceux des autres chapitres. Les exercices font
beaucoup appel à des notions de transformations de variables
aléatoires qui ont pourtant déjà étudiées dans d'autres cours. Pour un
rappel des principaux résultats dans ce domaine, consulter
l'\autoref{chap:rappels_transformations}.

\begin{exercice}
  La transformation de Box--Muller est populaire pour simuler des
  nombres normaux à partir de nombres uniformes. Soit $U_1 \sim U(0,
  1)$ et $U_2 \sim U(0, 1)$ deux variables aléatoires indépendantes et
  \begin{align*}
    X_1 &= (-2 \log U_1)^{1/2} \cos (2\pi U_2) \\
    X_2 &= (-2 \log U_1)^{1/2} \sin (2\pi U_2).
  \end{align*}
  \begin{enumerate}
  \item Vérifier de manière heuristique que la transformation
    ci-dessus est bijective de $\{(u_1, u_2); 0 < u_1 < 1, 0 < u_2 <
    1\}$ à $\{(x_1, x_2); -\infty < x_1 < \infty, -\infty < x_2 <
    \infty\}$, c'est-à-dire qu'elle associe à un point $(u_1, u_2)$ un
    et un seul point $(x_1, x_2)$.
  \item Démontrer que la transformation inverse est
    \begin{align*}
      U_1 &= e^{-(X_1^2 + X_2^2)/2} \\
      U_2 &= \frac{1}{2 \pi} \arctan \frac{X_2}{X_1}.
    \end{align*}
  \item Démontrer que $X_1$ et $X_2$ sont deux variables aléatoires
    indépendantes chacune distribuée selon une $N(0, 1)$.
  \item Vérifier empiriquement la validité de ces formules à l'aide de
    Excel ou R. En R, on peut transformer les nombres uniformes
    obtenus avec la fonction \code{runif} en nombres normaux sans même
    utiliser de boucles grâce à la fonction \code{outer} et deux
    fonctions anonymes.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item Tout d'abord, on voit que
      \begin{align*}
        \cos (2\pi U_{2}) &\in (-1, 1) \\
        \sin (2\pi U_{2}) &\in (-1, 1) \\
        \intertext{et}
        (-2 \log U_1)^{1/2} &\in (0, \infty).
      \end{align*}
      Par conséquent, $X_1 \in (-\infty, \infty)$ et $X_2 \in
      (-\infty, \infty)$. On vérifie la bijectivité de façon
      heuristique avec quelques valeurs de $u_1$ et $u_2$.
    \item On a
      \begin{align*}
        X_1^2 &= (-2 \log U_1) \cos^2 (2\pi U_2) \\
        X_2^2 &= (-2 \log U_1) \sin^2 (2\pi U_2).
      \end{align*}
      Or, puisque $\sin^{2}(x) + \cos^{2}(x) = 1$, $X_1^2 + x_2^2 = -2
      \log U_1$, d'où $U_1 = e^{-(X_1^2 + X_2^2)/2}$. D'autre part,
      $\sin(x)/\cos(x) = \tan(x)$, donc $\tan (2\pi U_2) = X_2/X_1$
      ou, de manière équivalente, $U_2 = (2 \pi)^{-1} \arctan
      X_2/X_1$.
    \item Soit les fonctions
      \begin{align*}
        x_1(u_1, u_2)
        &= (-2\log u_1)^{1/2} \cos (2\pi u_2)  &
        u_1(x_1,x_2)
        &= e^{-(x_1^2 + x_2^2)/2}  \\
        x_2(u_1, u_2)
        &= (-2\log u_1)^{1/2} \sin (2\pi u_2) &
        u_2(x_1, x_2)
        &= \frac{1}{2\pi} \arctan \frac{x_2}{x_1}.
      \end{align*}
      Les variables aléatoires $U_1$ et $U_2$ sont indépendantes, donc
      leur fonction de densité de probabilité conjointe est le produit
      des densités marginales:
      \begin{displaymath}
        f_{U_1, U_2}(u_1, u_2) = 1, \quad 0 < u_1 < 1, 0 < u_2 < 1.
      \end{displaymath}
      La densité conjointe de $X_1$ et $X_2$ est, par définition d'une
      transformation,
      \begin{displaymath}
        f_{X_1,X_2}(x_1, x_2) =
        f_{U_1, U_2}(x_1(u_1, u_2), x_2(u_1,u_2)) |\det(J)|
      \end{displaymath}%
      où
      \begin{align*}
        J
        &=
        \begin{bmatrix}
          \frac{\partial u_1}{\partial x_1} &
          \frac{\partial u_1}{\partial x_2} \\
          \frac{\partial u_2}{\partial x_1} &
          \frac{\partial u_2}{\partial x_2}
        \end{bmatrix} \\
        &=
        \begin{bmatrix}
          -x_1 e^{- (x_1^2 + x_2^2)/2} &
          -x_2 e^{- (x_1^2 + x_2^2)/2} \\
          -\frac{1}{2\pi} \frac{x_2}{x_1^2 + x_2^2} &
          \frac{1}{2\pi} \frac{x_1}{x_1^2 + x_2^2}
        \end{bmatrix}
      \end{align*}
      Or,
      \begin{align*}
        |\det(J)|
        &= \frac{1}{2\pi} e^{-(x_1^2 + x_2^2)/2} \\
        &= \frac{1}{\sqrt{2\pi}} e^{-x_1^2/2} \cdot
        \frac{1}{\sqrt{2\pi}} e^{-x_2^2/2},
      \end{align*}
      d'où
      \begin{displaymath}
        f_{X_1,X_2}(x_1, x_2) = \frac{1}{\sqrt{2\pi}} e^{-x_1^2/2} \cdot
        \frac{1}{\sqrt{2\pi}} e^{-x_2^2/2}
      \end{displaymath}
      et, donc, $X_1$ et $X_2$ sont deux variables aléatoires $N(0, 1)$
      indépendantes.
    \item
<<echo=TRUE, eval=FALSE>>=
u1 <- runif(500)
u2 <- runif(500)
x1 <- outer(u1, u2, function(x, y)
            sqrt((-2 * log(x))) * cos(2 * pi * y))
x2 <- outer(u1, u2, function(x, y)
            sqrt((-2 * log(x))) * sin(2 * pi * y))
hist(x1, prob = TRUE)
curve(dnorm(x), add = TRUE)
@
    \end{enumerate}
    La \autoref{fig:simulation:boxmuller} illustre d'une autre façon que la
    transformation de Box--Muller fonctionne bel et bien. Dans le
    graphique de gauche, on a plusieurs couples de points $(u_1, u_2)$
    où chaque composante provient d'une distribution uniforme sur
    l'intervalle $(0, 1)$.

    Chacun de ces points a été transformé en un point $(x_1, x_2)$
    selon la transformation de Box--Muller, puis placé dans le
    graphique de droite. On a superposé le nuage de points ainsi
    obtenu aux lignes de niveau d'une distribution normale bivariée
    (avec paramètre $\rho = 0$). On observe que la répartition et la
    densité du nuage de points correspond effectivement aux lignes de
    niveau.
    \begin{figure}
      \centering
<<echo=FALSE, fig=TRUE, width=10, height=5>>=
u1 <- runif(1000)
u2 <- runif(1000)
x1 <- sqrt(-2 * log(u1)) * cos(2 * pi * u2)
x2 <- sqrt(-2 * log(u1)) * sin(2 * pi * u2)

col <- rgb(0.8, 0, 0, 0.25)
par(mfrow = c(1, 2))

plot(u1, u2, pch = 19, col = col)

f <- function(x, y) dnorm(x) * dnorm(y)
x <- seq(-3, 3, length = 100)
z <- outer(x, x, f)
contour(x, x, z, xlim = c(-3, 3), ylim = c(-3, 3),
        nlevels = 15, method = "edge", xlab = "x1", ylab = "x2")
points(x1, x2, pch = 19, col = col)
@
      \caption{Démonstration graphique du fonctionnement de la
        transformation de Box--Muller}
      \label{fig:simulation:boxmuller}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  La distribution de Laplace, ou double exponentielle, est définie
  comme la différence entre deux distributions exponentielles
  identiques et indépendantes. Sa fonction de densité de probabilité
  est
  \begin{displaymath}
    f(x) = \frac{\lambda}{2}\, e^{-\lambda |x|}, \quad
    -\infty < x < \infty.
  \end{displaymath}
  Proposer une ou plusieurs façons de simuler des nombres issus de
  cette distribution.
  \begin{sol}
    Deux suggestions:
    \begin{enumerate}[1.]
    \item Simuler deux nombres indépendants $x_1$ et $x_2$ d'une loi
      exponentielle de paramètre $\lambda$ et poser $y = x_1 - x_2$.
    \item La fonction de répartition de la distribution de Laplace est
      \begin{align*}
        F_{Y}(y)
        &=
        \begin{cases}
          \frac{1}{2}e^{\lambda x}, & x < 0 \\
          1-\frac{1}{2}e^{-\lambda x}, & x \geq 0,
        \end{cases} \\
        \intertext{d'où}
        F_{Y}^{-1}(u)
        &=
        \begin{cases}
          \frac{1}{\lambda} \ln (2u) & u < 0,5 \\
          \frac{-1}{\lambda} \ln (2(1-u) ) & u \geq 0,5.
        \end{cases}
      \end{align*}
      On peut donc utiliser la méthode inverse.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:gamma}
  Faire la mise en oeuvre informatique (dans le langage de votre
  choix) de l'algorithme de simulation suivant. Il s'agit d'un
  algorithme pour simuler des observations d'une loi Gamma$(\alpha,
  1)$, où $\alpha > 1$.
  \begin{enumerate}[1.]
  \item Générer $u_1$ et $u_2$ indépendemment d'une loi $U(0, 1)$ et
    poser
    \begin{displaymath}
      v = \frac{(\alpha - \frac{1}{6\alpha}) u_1}{(\alpha - 1) u_2}.
    \end{displaymath}
  \item Si
    \begin{displaymath}
      \frac{2 (u_2 - 1)}{\alpha - 1} + v + \frac{1}{v} \leq 2,
    \end{displaymath}
    alors retourner le nombre $x = (\alpha - 1) v$. Sinon, si
    \begin{displaymath}
      \frac{2 \log u_2}{\alpha - 1} - \log v + v \leq 1,
    \end{displaymath}
    alors retourner le nombre $x = (\alpha - 1) v$.
  \item Répéter au besoin la procédure depuis l'étape 1.
  \end{enumerate}
  Faire les vérifications empiriques usuelles de la validité de
  l'algorithme.
  \begin{sol}
    Voir la fonction R de la \autoref{fig:simulation:gamma}. On vérifie
    graphiquement la validité de l'algorithme:
<<echo=TRUE, eval=FALSE>>=
hist(rgamma2(1000, 5), prob = TRUE)
curve(dgamma(x, 5, 1), add = TRUE)
@
    \begin{figure}
      \centering
      \begin{framed}
\begin{Scode}
rgamma2 <- function(nsim, alpha)
{
    x <- numeric(nsim)
    i <- 0
    while (i < nsim)
    {
        u <- runif(2)
        v <- (alpha - 1/(6 * alpha)) * u[1] /
               ((alpha - 1) * u[2])

        if ((2 * (u[2] - 1)/(alpha - 1) +
               v + 1/v <= 2) |
            (2 * log(u[2])/(alpha - 1) -
               log(v) + v <= 1))
            x[i <- i + 1] <- (alpha - 1) * v
    }
    x
}
\end{Scode}
      \end{framed}
      \caption{Fonction de simulation d'une distribution
        Gamma$(\alpha, 1)$, $\alpha > 1$}
      \label{fig:simulation:gamma}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  En utilisant le résultat de l'exercice précédent, quelle procédure
  pourrait-on suivre pour simuler des nombres d'une loi Gamma$(\alpha,
  \lambda)$ où $\alpha > 1$?
  \begin{sol}
    Deux suggestions.
    \begin{enumerate}[1.]
    \item Si $X \sim \text{Gamma}(\alpha, 1)$, alors $Y = X/\lambda
      \sim \text{Gamma}(\alpha, \lambda)$. On peut donc générer un
      nombre $x$ d'une loi Gamma$(\alpha, 1)$ avec l'algorithme de
      l'\autoref{ex:simulation:gamma}, puis poser $y =
      x/\lambda$.
    \item Si $\alpha$ est entier, on peut générer $\alpha$ nombres
      (indépendants) $x_1, \dots, x_\alpha$ d'une distribution
      Exponentielle$(\lambda)$ et poser $y = \sum_{i=1}^\alpha x_i$.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \begin{enumerate}
  \item Démontrer que si $X|\Theta \sim \text{Exponentielle}(\Theta)$
    et $\Theta \sim \text{Gamma}(\alpha, \lambda)$, alors $X \sim
    \text{Pareto}(\alpha, \lambda)$. La fonction de densité de
    probabilité d'une loi de Pareto est
    \begin{displaymath}
      f(x) = \frac{\alpha \lambda^\alpha}{(x + \lambda)^{\alpha + 1}},
      \quad x > 0.
    \end{displaymath}
  \item Utiliser le résultat ci-dessus pour proposer un algorithme de
    simulation de nombres issus d'une loi de Pareto. Faire la mise en
    oeuvre informatique de cet algorithme et les vérifications d'usage
    de sa validité.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item On a $X|\Theta \sim \text{Exponentielle}(\Theta)$ et $\Theta
      \sim \text{Gamma}(\alpha, \lambda)$. Par la loi des probabilités
      totales,
      \begin{align*}
        f_{X}(x)
        &= \int_0^\infty f(x|\theta) u(\theta)\, d\theta  \\
        &= \frac{\lambda^\alpha}{\Gamma(\alpha)} \int_0^\infty
        \theta^{\alpha + 1 - 1} e^{-(\lambda + x) \theta}\, d\theta  \\
        &= \frac{\lambda^\alpha}{\Gamma(\alpha)}
        \frac{\Gamma(\alpha + 1)}{(\lambda + x)^{\alpha +1}} \\
        &= \frac{\alpha \lambda^\alpha}{(\lambda + x)^{\alpha +1}}.
      \end{align*}
    \item Pour générer un nombre d'une distribution de Pareto de
      paramètres $\alpha$ et $\lambda$ avec le résultat en a), on
      génère d'abord un nombre $\theta$ d'une distribution gamma de
      mêmes paramètres, puis on génère un nombre $x$ d'une
      distribution exponentielle de paramètre $\theta$. En R:
<<echo=TRUE, eval=FALSE>>=
rexp(1, rgamma(1, alpha, lambda))
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  La fonction de densité de probabilité de la loi de
  Pareto translatée est
  \begin{displaymath}
    f(x) = \frac{\alpha \lambda^\alpha}{x^{\alpha + 1}}, \quad x > \lambda.
  \end{displaymath}
  Simuler trois valeurs d'une telle distribution avec $\alpha = 2$ et
  $\lambda = \nombre{1000}$ à l'aide de la méthode de l'inverse et du
  générateur congruentiel linéaire suivant:
  \begin{displaymath}
    x_n = (65 x_{n-1} + 1) \bmod \nombre{2048}.
  \end{displaymath}
  Utiliser une amorce de $12$.
  \begin{rep}
    $\nombre{\Sexpr{round(1000/sqrt(1 - 0.3813))}}$,
    $\nombre{\Sexpr{round(1000/sqrt(1 - 0.7881))}}$,
    $\nombre{\Sexpr{round(1000/sqrt(1 - 0.2261))}}$
  \end{rep}
  \begin{sol}
    La fonction de répartition de la Pareto translatée$(\alpha,
    \lambda)$ est
    \begin{align*}
      F(x)
      &= \int_\lambda^x
      \frac{\alpha \lambda^\alpha}{y^{\alpha + 1}}\, dy \\
      &=
      \begin{cases}
        0, & x \leq \lambda \\
        1 - \left( \frac{\lambda}{x} \right)^\alpha, & x > \lambda
      \end{cases} \\
      \intertext{et son inverse est}
      F^{-1}(y)
      &=
      \begin{cases}
        \lambda, & y = 0 \\
        \frac{\lambda}{(1 - y)^{1/\alpha}}, & 0 < y < 1.
      \end{cases}
    \end{align*}
    Par conséquent, si $U \sim U(0, 1)$, alors
    \begin{displaymath}
      X = \frac{\lambda}{(1 - U)^{1/\alpha}} \sim
      \text{Pareto translatée}(\alpha, \lambda).
    \end{displaymath}
    Les trois premières valeurs retournées par le générateur
    \begin{displaymath}
      x_n = (65 x_{n-1} + 1) \bmod \nombre{2048}
    \end{displaymath}
    avec une amorce de $12$ sont $781$, $\nombre{1614}$ et $463$. En divisant
    ces nombres par $\nombre{2048}$, on obtient des nombres dans
    l'intervalle $(0, 1)$:
    \begin{displaymath}
      0,3813 \quad 0,7881 \quad 0,2261.
    \end{displaymath}
    Finalement, les observations de la Pareto$(2, \nombre{1000})$ sont
<<echo=TRUE>>=
1000/sqrt(1 - c(0.3813, 0.7881, 0.2261))
@
    \emph{Remarque:} puisque $1 - U \sim U(0, 1)$ si $U \sim U(0, 1)$,
    les nombres issus de la transformation $\lambda (1 -
    U)^{-1/\alpha}$ seraient tout aussi distribués selon une Pareto
    translatée. Les réponses seraient toutefois différentes.
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:cercle}
  Soit $U_1$ et $U_2$ deux variables aléatoires indépendantes
  uniformément distribuées sur l'intervalle $(0, 1)$ et soit la
  transformation
  \begin{align*}
    X_1 &= \sqrt{U_1} \cos(2 \pi U_2) \\
    X_2 &= \sqrt{U_1} \sin(2 \pi U_2).
  \end{align*}
  Démontrer que la distribution conjointe de $X_1$ et $X_2$ est
  uniforme sur le disque de rayon de $1$ centré en $(x_1, x_2) = (0,
  0)$. À quoi ce résultat peut-il servir?
  \begin{sol}
    On a la transformation
    \begin{displaymath}
      \begin{split}
        X_1 &= \sqrt{U_1} \cos(2 \pi U_2) \\
        X_2 &= \sqrt{U_1} \sin(2 \pi U_2)
      \end{split}
      \quad \Leftrightarrow \quad
      \begin{split}
        U_1 &= X_1^2 + X_2^2 \\
        U_2 &= \frac{1}{2\pi} \arctan \frac{X_2}{X_1}.
      \end{split}
    \end{displaymath}
    Cette transformation associe les points de l'espace $\{(u_1, u_2):
    0 < u_1 < 1, 0 < u_2 < 1\}$ à ceux de l'espace $\{(x_1, x_2):
    x_1^2 + x_2^2 < 1 \backslash (0, 0)\}$. Cela se vérifie aisément
    en examinant les limites de l'espace de départ:
    \begin{align*}
      u_1 &> 0 &\Rightarrow&& x_1^2 + x_2^2 &> 0 \\
      u_1 &< 1 &\Rightarrow&& x_1^2 + x_2^2 &< 1 \\
      u_2 &> 0 &\Rightarrow&& \frac{x_2}{x_1} &> 0 \\
      u_2 &< 1 &\Rightarrow&& \frac{x_2}{x_1} &< 0.
    \end{align*}
    Les troisième et quatrième inégalités définissent les quadrants I
    et III, puis II et IV de $\R^2$, respectivement. On remarque
    également que le point $(0, 0)$, qui a probabilité zéro, ne se
    trouve pas dans l'espace image.

    Le Jacobien de la transformation est
    \begin{align*}
      J
      &=
      \begin{vmatrix}
        \dfrac{\partial u_1}{\partial x_1} &
        \dfrac{\partial u_1}{\partial x_2} \\[8pt]
        \dfrac{\partial u_2}{\partial x_1} &
        \dfrac{\partial u_2}{\partial x_2}
      \end{vmatrix} \\
      &=
      \begin{vmatrix}
        2 x_1 &
        2 x_2 \\[6pt]
        -\dfrac{1}{2\pi} \dfrac{x_2}{x_1^2 + x_2^2} &
        \dfrac{1}{2\pi} \dfrac{x_1}{x_1^2 + x_2^2},
      \end{vmatrix} \\
      &=
      \frac{1}{\pi}.
    \end{align*}
    La fonction de densité de probabilité conjointe de $X_1$ et $X_2$
    est donc
    \begin{align*}
      f_{X_1,X_2}(x_1, x_2)
      &= f_{U_1, U_2}(u_1, u_2) |J| \\
      &= \frac{1}{\pi}, \quad -1 < x_1 < 1, -\sqrt{1 - x_1^2} < x_2 <
      \sqrt{1 - x_1^2},
    \end{align*}
    soit une distribution uniforme sur le disque unité.

    Le résultat peut évidemment servir à simuler des points
    uniformément répartis sur un disque de rayon $1$ centré en $(0,
    0)$. La \autoref{fig:simulation:cercle} illustre d'ailleurs cette
    transformation. Les points $(u_1, u_2)$ dans le graphique de gauche
    sont tirés aléatoirement sur le carré $(0, 1) \times (0, 1)$. Le
    graphique de droite montre que suite à la tranformation ci-dessus,
    on obtient des points $(x_1, x_2)$ distribués uniformément sur un
    disque de rayon $1$ centré en $(0, 0)$.
    \begin{figure}
      \centering
<<echo=FALSE, fig=TRUE, width=10, height=5>>=
col <- rgb(0.8, 0, 0, 0.25)
par(mfrow = c(1, 2))
u1 <- runif(1000)
u2 <- runif(1000)
x1 <- sqrt(u1) * cos(2 * pi * u2)
x2 <- sqrt(u1) * sin(2 * pi * u2)
plot(u1, u2, pch = 19, col = col)
plot(x1, x2, pch = 19, col = col)
@
      \caption{Démonstration graphique du fonctionnement de la
        transformation de l'\autoref{ex:simulation:cercle}}
      \label{fig:simulation:cercle}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:gamma-beta}
  \begin{enumerate}
  \item Soit $Y_1 \sim \text{Gamma}(\alpha, 1)$ et $Y_2 \sim
    \text{Gamma}(\beta, 1)$ deux variables aléatoires
    indépendantes. Démontrer que
    \begin{displaymath}
      X = \frac{Y_1}{Y_1 + Y_2} \sim \text{Bêta}(\alpha, \lambda).
    \end{displaymath}
  \item Utiliser le résultat en a) pour proposer un algorithme de
    simulation d'observations d'une loi Bêta$(\alpha, \lambda)$.
  \item Faire la mise en oeuvre informatique de l'algorithme en b)
    ainsi que les vérifications d'usage.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item On a
      \begin{align*}
        f_{Y_1}(y_1)
        &= \frac{1}{\Gamma(\alpha)}\, y_1^{\alpha - 1} e^{-y_1}, \quad
        y_1 > 0, \\
        f_{Y_2}(y_2)
        &= \frac{1}{\Gamma(\beta)}\, y_2^{\beta - 1} e^{-y_2}, \quad
        y_2 > 0 \\
        \intertext{et}
        f_{Y_1, Y_2}(y_1, y_2)
        &= \frac{1}{\Gamma(\alpha) \Gamma(\beta)}\,
        y_1^{\alpha - 1} y_2^{\beta - 1} e^{-(y_1 + y_2)}, \quad
        y_1 > 0, y_2 > 0.
      \end{align*}
      Soit $X_1 = Y_1/(Y_1 + Y_2)$ et $X_2 = Y_1 + Y_2$ (le choix de
      $X_2$ étant justifié par l'exposant de la distribution conjointe
      de $Y_1$ et $Y_2$). On cherche la distribution conjointe de
      $X_1$ et $X_2$, $f_{X_1, X_2}(x_1, x_2)$. On a la transformation
      \begin{displaymath}
        \begin{split}
          x_1 &= \frac{y_1}{y_1 + y_2} \\
          x_2 &= y_1 + y_2
        \end{split}
        \quad \Leftrightarrow \quad
        \begin{split}
          y_1 &= x_1 x_2 \\
          y_2 &= x_2 - x_1 x_2.
        \end{split}
      \end{displaymath}
      Cette transformation associe de manière évidente les points de
      l'espace $\{(y_1, y_2): y_1 > 0, y_2 > 0\}$ à ceux de l'espace
      $\{(x_1, x_2): 0 < x_1 < 1, x_2 > 0\}$.

      Le Jacobien de la transformation est
      \begin{align*}
        J
        &=
        \begin{vmatrix}
          \dfrac{\partial y_1}{\partial x_1} &
          \dfrac{\partial y_1}{\partial x_2} \\[8pt]
          \dfrac{\partial y_2}{\partial x_1} &
          \dfrac{\partial y_2}{\partial x_2}
        \end{vmatrix} \\
        &=
        \begin{vmatrix}
          x_2 & x_1 \\
          -x_2 & 1 - x_1
        \end{vmatrix} \\
        &=
        x_2.
      \end{align*}
      La fonction de densité de probabilité conjointe de $X_1$ et $X_2$
      est donc
      \begin{align*}
        f_{X_1,X_2}(x_1, x_2)
        &= f_{Y_1, Y_2}(y_1, y_2) |J| \\
        &= \frac{1}{\Gamma(\alpha) \Gamma(\beta)}\,
        x_1^{\alpha - 1} (1 - x_1)^{\beta - 1}
        x_2^{\alpha + \beta - 1} e^{-x_2} \\
        &=
        \left[
          \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)}\,
          x_1^{\alpha - 1} (1 - x_1)^{\beta - 1}
        \right]
        \left[
          \frac{1}{\Gamma(\alpha + \beta)}\,
          x_2^{\alpha + \beta - 1} e^{-x_2}
        \right],
      \end{align*}
      pour $0 < x_1 < 1$, $x_2 > 0$, d'où $X_1$ et $X_2$ sont
      indépendantes, $X_1 \sim \text{Bêta}(\alpha, \beta)$ et $X_2
      \sim \text{Gamma}(\alpha + \beta)$ (un résultat connu).
    \item La conversion du résultat en un algorithme est très simple:
      \begin{quote}
        \begin{enumerate}[1.]
        \item Générer $y_1$ d'une distribution Gamma$(\alpha, 1)$.
        \item Générer $y_2$ d'une distribution Gamma$(\beta, 1)$.
        \item Poser $x = y_1/(y_1 + y_2)$.
        \end{enumerate}
      \end{quote}
      Cet algorithme suppose évidemment qu'une source de nombres
      provenant d'une loi gamma est disponible.

      La \autoref{fig:simulation:gamma-beta} illustre le fonctionnement de
      cette transformation. Dans le graphique de gauche, on a un nuage
      de points $(y_1, y_2)$ tirés indépendemment de deux
      distributions gamma de paramètre d'échelle égal à 1. On a
      superposé ce nuage de points aux courbes de niveaux de la
      distribution conjointe des deux lois gamma.

      Dans le graphique de droite, on a placé en abscisse les points
      $x = y_1/(y_1 + y_2)$ résultant de la transformation. On voit
      que la répartition et la densité de ces points correspond à la
      densité de la loi bêta également représentée sur le graphique.
      \begin{figure}
        \centering
<<echo=FALSE, fig=TRUE, width=10, height=5>>=
col <- rgb(0.8, 0, 0, 0.25)
par(mfrow = c(1, 2))
f <- function(x, y) dgamma(x, 2) * dgamma(y, 3)
y <- seq(0, 8, length = 100)
z <- outer(y, y, f)
contour(y, y, z, xlim = c(0, 8), ylim = c(0, 8),
        nlevels = 15, method = "edge",
        xlab = expression(y[1]), ylab = expression(y[2]))

y1 <- rgamma(100, 2)
y2 <- rgamma(100, 3)
points(y1, y2, pch = 19, col = col)

curve(dbeta(x, 2, 3), xlim = c(0, 1), lwd = 2)
points(y1/(y1 + y2), rep(0, length(y1)), pch = 19, col = col)
@
        \caption{Démonstration graphique du fonctionnement de la
          transformation de l'\autoref{ex:simulation:gamma-beta}}
        \label{fig:simulation:gamma-beta}
      \end{figure}
    \item En R:
<<echo=TRUE,eval=FALSE>>=
(y <- rgamma(1, alpha, 1))/(y + rgamma(1, beta, 1))
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \begin{enumerate}
  \item Dans la méthode d'acceptation-rejet, un nombre $y$ tiré d'une
    variable aléatoire $Y$ avec fonction de densité de probabilité
    $g_Y(\cdot)$ est accepté comme réalisation d'une variable
    aléatoire $X$ avec fonction de densité de probabilité $f_X(\cdot)$ si
    \begin{displaymath}
      U \leq \frac{f_X(y)}{c g_Y(y)},
    \end{displaymath}
    où $U \sim U(0, 1)$. Calculer la probabilité d'accepter une valeur
    lors de toute itération de la méthode d'acceptation-rejet,
    c'est-à-dire
    \begin{displaymath}
      \Pr \left[ U \leq \frac{f_X(Y)}{c g_Y(Y)} \right].
    \end{displaymath}
    \emph{Astuce}: utiliser la loi des probabilités totales en
    conditionnant sur $Y = y$.
  \item Déterminer la distribution du nombre d'essais avant d'accepter
    un nombre $y$ dans la méthode d'acceptation-rejet.
  \item Déterminer le nombre moyen d'essais avant d'accepter un nombre
    $y$ dans la méthode d'acceptation-rejet.
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
    \item $1/c$
    \item Géométrique$(1/c)$ commençant à $1$
    \item $c$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On a
      \begin{align*}
        \Pr \left[ U \leq \frac{f_X(Y)}{c g_Y(Y)} \right]
        &= \int_{-\infty}^\infty
        \Pr \left[ U \leq \frac{f_X(Y)}{c g_Y(Y)}|Y = y \right] %|
        g_Y(y)\, dy \\
        &= \int_{-\infty}^\infty
        \frac{f_X(Y)}{c g_Y(Y)}\, g_Y(y)\, dy \displaybreak[0] \\
        &= \frac{1}{c} \int_{-\infty}^\infty f_X(y)\, dy \\
        &= \frac{1}{c}.
      \end{align*}
    \item Les essais étant indépendants, la distribution du nombre
      d'essais avant d'avoir un succès (accepter un nombre $y$) est
      géométrique de paramètre $1/c$, c'est-à-dire
      \begin{displaymath}
        \Pr[Z = z] =
        \left( \frac{1}{c} \right)
        \left( 1 - \frac{1}{c} \right)^z, \quad z = 1, 2, \dots,
      \end{displaymath}
      où $Z$ représente le nombre d'essais avant d'accepter un nombre.
    \item On a $\esp{Z} = 1/(1/c) = c$.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:mode}
  Soit $X$ une variable aléatoire continue définie sur l'intervalle
  $(a, b)$, où $a$ et $b$ sont des nombres réels. Pour simuler des
  observations de cette variable aléatoire par la méthode
  d'acceptation-rejet, on peut toujours inscrire la fonction de
  densité de probabilité de $X$ dans un rectangle de hauteur $M$, ou
  $M$ est la valeur de la densité au mode de $X$.
  \begin{enumerate}
  \item Énoncer l'algorithme d'acceptation-rejet découlant d'une telle
    procédure.
  \item Calculer l'\emph{efficacité} de l'algorithme en a), soit la
    probabilité d'accepter une valeur lors d'une itération de
    l'algorithme.
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
      \stepcounter{enumi}
    \item $1/(M (b - a))$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On pose
      \begin{displaymath}
        c g_Y(x) = M, \quad a < x < b,
      \end{displaymath}
      soit $Y \sim U(a, b)$ et $c = M (b - a)$. L'algorithme
      d'acceptation-rejet est donc le suivant:
      \begin{enumerate}[1.]
      \item Simuler deux nombres indépendants $u_1$ et $u_2$ d'une
        loi $U(0, 1)$.
      \item Poser $y = a + (b - a) u_1$.
      \item Si $u_2 \leq f_X(y)/M$, poser $x = y$. Sinon, retourner
        à l'étape 1.
      \end{enumerate}
    \item L'efficacité est
      \begin{displaymath}
        \frac{1}{c} = \frac{1}{M (b - a)}.
      \end{displaymath}
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:beta}
  Considérer le problème de simulation d'observations d'une loi
  Bêta$(3, 2)$ à l'aide de la méthode d'acceptation-rejet.
  \begin{enumerate}
  \item Calculer l'efficacité de l'algorithme développé à
    l'\autoref{ex:simulation:mode} et à
    l'\autoref{exemple:simulation:beta:1} pour le cas présent.
  \item Calculer l'efficacité de l'algorithme développé dans
    l'\autoref{exemple:simulation:beta:2}, où l'on a déterminé que
    \begin{displaymath}
      f_{X}(x) \leq
      \begin{cases}
        3x, & 0 < x < 0,8 \\
        12 - 12 x, & 0,8 \leq x < 1.
      \end{cases}
    \end{displaymath}
  \item Faire la mise en oeuvre informatique de l'algorithme le plus
    efficace entre celui de la partie a) et celui de la partie b).
    Vérifier la fonction en superposant l'histogramme d'un grand
    échantillon obtenu avec cette fonction et la vraie fonction de
    densité de la loi bêta.
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
    \item $9/16$
    \item $4/5$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On démontre facilement que le mode $M$ d'une distribution
      bêta de paramètres $\alpha$ et $\beta$ se trouve en
      \begin{displaymath}
        x = \frac{\alpha - 1}{\alpha + \beta - 2}.
      \end{displaymath}
      Par conséquent, l'efficacité de l'algorithme d'acceptation-rejet
      décrit à l'\autoref{ex:simulation:mode} et consistant à
      borner la densité par un rectangle de hauteur $M$ est
      \begin{align*}
        \frac{1}{M}
        &= \frac{1}{f((\alpha - 1)/(\alpha + \beta - 2))} \\
        &= \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)}
        \left(
          \frac{\alpha - 1}{\alpha + \beta - 2}
        \right)^{1 - \alpha}
        \left(
          \frac{\beta - 1}{\alpha + \beta - 2}
        \right)^{1 - \beta}.
      \end{align*}
      Avec $\alpha = 3$ et $\beta = 2$, on obtient une efficacité de
      $9/16$.
    \item On a trouvé $c = 1,2$ dans
      l'\autoref{exemple:simulation:beta:2}, d'où une efficacité de
      $1/c = 5/6$. Cet algorithme est évidemment plus efficace puisque
      la surface de l'enveloppe de la densité bêta est nettement plus
      petite.
    \item On utilise l'algorithme développé à
      l'\autoref{exemple:simulation:beta:2}. Une première mise en
      {\oe}uvre de l'algorithme en R est fournie dans le code
      informatique de la \autoref{sec:simulation:code}. La
      \autoref{fig:simulation:rbeta.ar2} en propose une autre. On
      propose aussi une mise en {\oe}uvre VBA à la \autoref{fig:simulation:betasim}.
      \begin{figure}[t]
        \centering
        \begin{framed}
\begin{Scode}
rbeta.ar2 <- function(n)
{
    g <- function(x)
        ifelse(x < 0.8, 2.5 * x, 10 - 10 * x)
    Ginv <- function(y)
        ifelse(y < 0.8, sqrt(0.8 * y),
               1 - sqrt(0.2 - 0.2 * y))
    x <- numeric(n)
    i <- 0
    while(i < n)
    {
        y <- Ginv(runif(1))
        if(1.2 * g(y) * runif(1) <=
           dbeta(y, shape1 = 3, shape2 = 2))
            x[i <- i + 1] <- y
    }
    x
}
\end{Scode}
        \end{framed}
        \caption{Code R de la fonction \code{rbeta.ar2}}
        \label{fig:simulation:rbeta.ar2}
      \end{figure}
      \begin{figure}
        \centering
        \begin{framed}
\begin{Scode}
Private Function sqrt(x)
    sqrt = x ^ 0.5
End Function

Private Function g(x As Double)
    DensiteTriangle = IIf(x < 0.8, 2.5 * x,
                          10 - 10 * x)
End Function

Private Function Ginv(u As Double)
    InverseTriangle = IIf(u < 0.8, sqrt(0.8 * u),
                          1 - sqrt(0.2 - 0.2 * u))
End Function

Private Function dbeta(x As Double, shape1 As Double,
                       shape2 As Double)
    Dim cte As Double
    With WorksheetFunction
        cte = Exp(.GammaLn(shape1 + shape2) -
                  .GammaLn(shape1) -
                  .GammaLn(shape2))
        dbeta = cte * x ^ (shape1 - 1) *
                (1 - x) ^ (shape2 - 1)
    End With
End Function

Function betasim()
    Dim u1 As Double, u2 As Double, y As Double

    Do
        u1 = Rnd
        u2 = Rnd
        y = Ginv(u1)
    Loop Until u2 <= dbeta(y, 3, 2) / (1.2 * g(y))

    SimuleBeta = y
End Function
\end{Scode}
        \end{framed}
        \caption{Code VBA de la fonction \code{betasim}}
        \label{fig:simulation:betasim}
      \end{figure}
      On peut vérifier l'exactitude la fonction \code{rbeta.ar2} avec
<<echo=TRUE, eval=FALSE>>=
x <- rbeta.ar2(10000)
hist(x, prob = TRUE)
curve(dbeta(x, 3, 2), add = TRUE)
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:rejet}
  La fonction R de la \autoref{fig:simulation:fonction} permet de
  simuler des observations de la distribution Bêta$(\alpha, \beta)$.
    \begin{figure}[t]
      \begin{framed}
\begin{Scode}
simul <- function(n, alpha, beta)
{
    xmax <- (alpha - 1)/(alpha + beta - 2)
    M <- dbeta(xmax, alpha, beta)
    x <- numeric(n)
    i <- 0
    repeat
    {
        u <- runif(1)
        if (M * runif(1) <= dbeta(u, alpha, beta))
            x[i <- i + 1] <- u
        if (i == n)
            break
    }
    x
}
\end{Scode}
      \end{framed}
      \caption{Fonction de simulation d'une loi Bêta$(\alpha, \beta)$
        pour l'\autoref{ex:simulation:rejet}}
      \label{fig:simulation:fonction}
    \end{figure}
  \begin{enumerate}
  \item Identifier le type d'algorithme utilisé dans cette fonction.
  \item On vous donne également les valeurs suivantes, obtenues dans
    R:
<<echo=FALSE>>=
op <- options(width = 50, digits = 2)
simul <- function(n, alpha, beta)
{
    ymax <- dbeta((alpha-1)/(alpha + beta - 2), alpha, beta)
    x <- numeric(n)
    i <- 1
    repeat
    {
        u <- runif(1)
        if (ymax * runif(1) <= dbeta(u, alpha, beta))
        {
            x[i] <- u
            i <- i + 1
        }
        if (i > n)
            break
    }
    x
}
@
<<echo=TRUE>>=
set.seed(12345)
runif(10)
@
    Évaluer le résultat des expressions suivantes:
<<echo=TRUE, eval=FALSE>>=
set.seed(12345)
simul(2, alpha = 2, beta = 3)
@
  \end{enumerate}
  \begin{rep}
    \begin{enumerate}[a)]
      \stepcounter{enumi}
    \item
<<echo=FALSE>>=
set.seed(12345)
round(simul(2, alpha = 2, beta = 3), 2)
options(op)
@
    \end{enumerate}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On reconnaît l'algorithme d'acceptation-rejet de
      l'\autoref{ex:simulation:mode}.
    \item On doit simuler deux observations d'une loi Bêta$(2, 3)$
      dont la fonction de densité de probabilité est
      \begin{displaymath}
        f(x) = 12 x (1 - x)^2, \quad 0 < x < 1.
      \end{displaymath}
      Le mode de cette densité se trouve en $x = 1/3$ (voir la
      solution de l'\autoref{ex:simulation:beta}) et la valeur de
      ce mode est $M = f(1/3) = 16/9$. Pour obtenir le résultat de
      l'appel de la fonction \code{simul}, il faut s'assurer
      d'utiliser les nombres uniformes dans le bon ordre. Quatre
      itérations de la boucle \code{repeat} seront nécessaires;
      voici leurs résultas.
      \begin{enumerate}[1.]
      \item On a $u = 0,72$, puis $(16/9) (0,88) > f(0,72)$, donc $u$
        est rejeté.
      \item On a $u = 0,76$, puis $(16/9) (0,89) > f(0,76)$, donc $u$
        est rejeté.
      \item On a $u = 0,46$, puis $(16/9) (0,17) > f(0,46)$, donc $u$
        est accepté: $x_1 = 0,46$.
      \item On a $u = 0,33$, puis $(16/9) (0,51) > f(0,33)$, donc $u$
        est accepté: $x_2 = 0,33$.
      \end{enumerate}
      Le résultat est donc le vecteur $\mat{x} = (0,46, 0,33)$.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \begin{enumerate}
  \item Démontrer que, si $0 < \alpha < 1$,
    \begin{displaymath}
      x^{\alpha - 1} e^{-x} \leq
      \begin{cases}
        x^{\alpha - 1}, & 0 \leq x \leq 1 \\
        e^{-x},        & x > 1.
      \end{cases}
    \end{displaymath}
  \item Développer un algorithme d'acceptation-rejet pour simuler des
    observations d'une loi Gamma$(\alpha, 1)$, $0 < \alpha < 1$ à
    partir du résultat en a).
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item Si $0 \leq x \leq 1$, $e^{-1} < e^{-x} < 1$, d'où $x^{\alpha
        - 1} e^{-x} \leq x^{\alpha - 1}$. De même, puisque $0 < \alpha
      < 1$, $x^{\alpha - 1} < 1$ pour $x > 1$, d'où  $x^{\alpha - 1}
      e^{-x} \leq e^{-x}$ pour $x > 1$.
    \item On veut borner la densité $f_X(x) = x^{\alpha - 1}
      e^{-x}/\Gamma(\alpha)$, $x > 0$ et $0 < \alpha < 1$. Du résultat
      en a), on a
      \begin{displaymath}
        f_X(x) \leq
        \begin{cases}
          x^{\alpha - 1}/\Gamma(\alpha), & 0 \leq x \leq 1 \\
          e^{-x}/\Gamma(\alpha),        & x > 1.
        \end{cases}
      \end{displaymath}
      Posons
      \begin{displaymath}
        c g_Y(x) =
        \begin{cases}
          x^{\alpha - 1}/\Gamma(\alpha), & 0 \leq x \leq 1 \\
          e^{-x}/\Gamma(\alpha),        & x > 1.
        \end{cases}
      \end{displaymath}
      L'aire totale sous la fonction $c g_Y(x)$ est
      \begin{displaymath}
        \int_0^1 \frac{x^{\alpha - 1}}{\Gamma(\alpha)}\, dx +
        \int_1^\infty \frac{e^{-x}}{\Gamma(\alpha)}\, dx =
        \frac{1}{\Gamma(\alpha)}
        \left(
          \frac{1}{\alpha} + \frac{1}{e}
        \right),
      \end{displaymath}
      d'où
      \begin{align*}
        g_Y(x)
        &=
        \begin{cases}
          \dfrac{x^{\alpha - 1}}{(1/\alpha) + (1/e)}, & 0 \leq x \leq 1 \\
          \dfrac{e^{-x}}{(1/\alpha) + (1/e)}, & x > 1,
        \end{cases} \\
        G_Y(x)
        &=
        \begin{cases}
          \dfrac{e}{\alpha + e}\, x^\alpha, & 0 \leq x \leq 1 \\
          1 - \dfrac{e^{-x}}{(1/\alpha) + (1/e)}, & x > 1,
        \end{cases} \\
        \intertext{et}
        G_Y^{-1}(x)
        &=
        \begin{cases}
          \left( \dfrac{\alpha + e}{e}\, x \right)^{1/\alpha},
          & 0 \leq x \leq e/(\alpha + e) \\
          - \ln [((1/\alpha) + (1/e))(1 - x)],
          & e/(\alpha + e) < x \leq 1.
        \end{cases}
      \end{align*}
      On remarque que
      \begin{displaymath}
        \frac{f_X(x)}{c g_Y(x)} =
        \begin{cases}
          e^{-x},        & 0 \leq x \leq 1 \\
          x^{\alpha - 1}, & x > 1.
        \end{cases}
      \end{displaymath}
      On a donc l'algorithme de simulation suivant:
      \begin{enumerate}[1.]
      \item Simuler deux nombres $u_1$ et $u_2$ d'une $U(0, 1)$.
      \item Poser $y = G_Y^{-1}(u_1)$.
      \item Si
        \begin{displaymath}
          u_2 \leq
          \begin{cases}
            e^{-y},        & 0 \leq y \leq 1 \\
            y^{\alpha - 1}, & y > 1,
          \end{cases}
        \end{displaymath}
        alors poser $x = y$. Sinon, retourner à l'étape 1.
      \end{enumerate}
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  On vous donne l'inégalité suivante, valide pour $\alpha \geq 1$:
  \begin{displaymath}
    x^{\alpha - 1} e^{-x}
    \leq \alpha^{\alpha - 1} e^{-x/\alpha + 1 -  \alpha}, \quad x > 0.
  \end{displaymath}
  Utiliser cette inégalité pour justifier l'algorithme
  d'acceptation-rejet suivant pour simuler des observations d'une loi
  Gamma$(\alpha, 1)$ avec $\alpha \geq 1$:
  \begin{enumerate}[1.]
  \item Simuler deux observations indépendantes $v_1$ et $v_2$ d'une
    loi exponentielle de moyenne $1$.
  \item Si $v_2 < (\alpha - 1)(v_1 - \ln v_1 - 1)$, poser $x =
    \alpha v_1$. Sinon, retourner à l'étape 1.
  \end{enumerate}
  \begin{sol}
    On veut simuler des observations de la fonction de densité de
    probabilité $f_X(x) = x^{\alpha - 1} e^{-x}/\Gamma(\alpha)$ avec
    $\alpha \geq 1$. Or, on nous donne
    \begin{displaymath}
      f_X(x) \leq \frac{\alpha^\alpha}{\Gamma(\alpha)}\,
      e^{1 - \alpha}\,
      \frac{1}{\alpha}\, e^{-x/\alpha}, \quad x > 0,
    \end{displaymath}
    d'où $f_X(x) \leq c g_Y(x)$ avec
    \begin{align*}
      c
      &= \frac{\alpha^\alpha}{\Gamma(\alpha)}\, e^{1 - \alpha} \\
      \intertext{et}
      g_Y(x)
      &= \frac{1}{\alpha}\, e^{-x/\alpha}.
    \end{align*}
    Ainsi, $Y \sim \text{Exponentielle}(1/\alpha)$. Soit $y$ une
    observation de la variable aléatoire $Y$ et $u$ une observation
    d'une loi $U(0, 1)$. Selon l'algorithme d'acceptation-rejet, on
    accepte la valeur $y$ comme observation d'une loi Gamma$(\alpha,
    1)$ avec $\alpha \geq 1$ si
    \begin{gather*}
      u \leq \frac{f_X(y)}{c g_Y(y)} =
      y^{\alpha - 1}\, \frac{e^{-y (1 - 1/\alpha)}}{\alpha^{\alpha -
          1} e^{-(\alpha - 1)}} \\
      \Updownarrow \\
      u^{1/(\alpha - 1)} \leq \left( \frac{y}{\alpha} \right)
      \frac{e^{-y/\alpha}}{e^{-1}} \\
      \Updownarrow \\
      \ln u \leq (\alpha - 1)
      \left[
        \ln \left( \frac{y}{\alpha} \right) - \frac{y}{\alpha} + 1
      \right] \\
      \Updownarrow \\
      - \ln u > (\alpha - 1)
      \left[
        \frac{y}{\alpha} - \ln \left( \frac{y}{\alpha} \right) - 1
      \right].
    \end{gather*}
    Or, tant la distribution de $-\ln U$ que celle de $Y/\alpha$ est
    une exponentielle de moyenne $1$, d'où l'algorithme donné dans
    l'énoncé.
  \end{sol}
\end{exercice}

\Closesolutionfile{reponses}
\Closesolutionfile{solutions}

%%%
%%% Insérer les réponses
%%%
\input{reponses-simulation}

%%% Local Variables:
%%% TeX-master: methodes_numeriques-partie_2
%%% coding: utf-8
%%% End:
