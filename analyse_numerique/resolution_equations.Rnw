\chapter{Résolution d'équations à une variable}
\label{chap:resolution}

\begin{objectifs}
\item Résoudre une équation à une variable à l'aide des méthodes de la
  bissection, du point fixe et de Newton-Raphson.
\item Faire un choix parmi l'une des méthodes ci-dessus pour résoudre
  un problème donné.
\item Déterminer si une fonction admet un point fixe dans un
  intervalle donné.
\item Utiliser les fonctions de résolution d'équations et
  d'optimisation de Excel et R.
\end{objectifs}

<<echo=FALSE>>=
options(width = 60)
source("bissection.R")
source("pointfixe.R")
source("nr.R")
@


\begin{prob-enonce}
  Les fonctions décrivant les heures de lever et de coucher du soleil
  à Québec pour le mois de janvier 2016 sont représentées par $L(x)$
  et $C(x)$, respectivement:
  \begin{align*}
    L(x) &= e^{-0.001431 x + 2,016340} \\
    C(x) &= e^{0,001312 x + 2,778538},
  \end{align*}
  où $x$ est le jour du mois (un entier). La fonction du nombre
  d'heures d'ensoleillement pour une journée est donc
  $H(x) = C(x) - L(x)$.

  Pendant quel jour du mois les Québécois bénéficient-ils de
  9~heures d'ensoleillement, à une minute près?
\end{prob-enonce}


\section{Mise en contexte}
\label{sec:resolution:contexte}

Ce chapitre passe en revue les méthodes les plus populaires pour
résoudre numériquement une équation à une variable. Ce problème,
simple seulement en apparence, survient dans une foule de domaines.
Débutons par deux exemples, tirés des mathématiques financières et de
l'inférence statistique.

\begin{exemple}
  Un investisseur est disposé à payer $k$~\$ aujourd'hui en retour
  d'une série de $n$ versements de $1$~\$, le premier dans un an. Pour
  déterminer le taux de rendement qu'il exige, on doit trouver la
  valeur de $i$ tel que $a_{\angl{n}\, i} = k$ ou, énoncé autrement,
  la valeur de $i$ tel que
  \begin{equation*}
    f(i) = \frac{1 - (1 + i)^{-n}}{i} -k = 0.
  \end{equation*}
  \qed
\end{exemple}

\begin{exemple}
  On a un échantillon aléatoire $X_1, \dots, X_n$ provenant d'une
  distribution binomiale négative avec fonction de masse de
  probabilité
  \begin{displaymath}
    \Pr[X = x] = \binom{x + r - 1}{r - 1} p^r (1 - p)^x, \quad x = 0,
    1, \dots,
  \end{displaymath}
  où $p$ est supposé connu. On souhaite trouver l'estimateur du
  maximum de vraisemblance du paramètre $r$.

  La fonction de vraisemblance est
  \begin{align*}
    L(r)
    &= \prod_{i = 1}^n \Pr[X = x_i] \\
    &= \prod_{i = 1}^n \binom{x_i + r - 1}{r - 1} p^r (1 - p)^{x_i}
  \end{align*}
  et la fonction de log-vraisemblance est
  \begin{align*}
    l(r)
    &= \sum_{i = 1}^n
    [\ln \Gamma(x_i + r) - \ln \Gamma(r) - \ln \Gamma(x_i + 1) \\
    &\quad\; + r \ln p + x_i \ln (1 - p)].
  \end{align*}
  Par conséquent, l'estimateur du maximum de vraisemblance $\hat{r}$
  est la solution de
  \begin{displaymath}
    f(r) = \frac{d}{dr}\, l(r) =
    \sum_{i = 1}^n (\Psi(x_i + r) - \Psi(r) + \ln p) = 0,
  \end{displaymath}
  où $\Psi(x) = \Gamma^\prime(x)/\Gamma(x)$ est la \emph{fonction
    digamma}. %
  \qed
\end{exemple}

Le problème sur lequel nous allons nous pencher consiste donc à
trouver la racine d'une fonction $f(x)$, c'est-à-dire la solution de
$f(x) = 0$.

\begin{prob-astuce}
  Nous cherchons à déterminer pour quelle valeur de
  $x \in \{1, 2, \dots, 31\}$ la fonction $H(x)$ vaut $9$ ou, de
  manière équivalente, la racine de l'équation $H(x) - 9 = 0$.

  Une technique d'essai-erreur intuitive suivrait probablement
  à peu près les étapes suivantes:
  \begin{enumerate}
  \item vérifier qu'il existe bel une racine dans l'intervalle
    $[1, 31]$ en évaluant le nombre d'heures d'ensoleillement aux
    bornes de l'intervalle, puis déterminer si la fonction est
    croissante ou décroissante sur l'intervalle (elle est croissante
    dans le cas présent);
  \item essayer une première valeur pour $x$ et calculer la valeur de
    $H(x)$;
  \item si le nombre d'heures d'ensoleillement est trop élevé,
    diminuer la valeur de $x$ et si, à l'inverse, le nombre d'heures
    d'ensoleillement est trop faible, augmenter la valeur de $x$;
  \item répéter les deux étapes précédentes jusqu'à trouver la bonne
    valeur de $x$ au un degré de précision désiré.
  \end{enumerate}

  Voici une mise en {\oe}uvre simple en R. Définissons d'abord une
  fonction pour calculer le nombre d'heures d'ensoleillement $H(x)$.
<<echo=TRUE>>=
H <- function(x)
{
    exp(0.001312 * x + 2.778538) -
        exp(-0.001431 * x + 2.016340)
}
@
  Calculons les valeurs au début et à la fin de l'intervalle
<<echo=TRUE>>=
H(1)
H(31)
@
  Selon les valeurs à $x = 1$ et $x = 31$, le jour où l'ensoleillement
  total vaut $9$ semble se situer environ à la mi-mois. Essayons donc
  $x = 15$.
<<echo=TRUE>>=
H(15)
@
  La valeur est supérieure à $9$. Le jour recherché se trouve donc
  entre $1$ et $15$. Essayons $x = 10$.
<<echo=TRUE>>=
H(10)
@
  La valeur est inférieure à $9$. Le jour recherché se trouve donc
  entre $10$ et $15$. Essayons $x = 13$.
<<echo=TRUE>>=
H(13)
@
  Nous avons trouvé la bonne valeur à une minute près.
\end{prob-astuce}


\section{Méthode de bissection}
\label{sec:resolution:bissection}

Toutes les méthodes numériques de résolution d'une équation qui seront
étudiées dans ce chapitre reposent sur une procédure systématique
d'essais et d'erreurs. La procédure --- ou algorithme --- utilisée
déterminera l'efficacité de la méthode. À ce chapitre, la méthode de
bissection est la plus simple et la plus intuitive méthode de
résolution, mais aussi la moins efficace.

Soit $f$ une fonction continue sur un intervalle $[a, b]$ choisi de
telle sorte que $f(a)$ et $f(b)$ sont de signes opposés. Par le
théorème de la valeur intermédiaire, il existe un point $x^*$ tel que
$f(x^*) = 0$. En d'autres mots, si une fonction continue est d'un côté
de l'axe des abscisses au début d'un intervalle et de l'autre coté à
l'autre extrémité de l'intervalle, alors elle a forcément croisé l'axe
quelque part dans l'intervalle.

L'idée de la méthode de bissection consiste à trouver la solution
$x^*$ par essais successifs en utilisant le point milieu d'intervalles
de plus en plus petits, mais que l'on sait toujours contenir le point
cherché. L'\autoref{algo:resolution:bissection} systématise
cette idée et la \autoref{fig:resolution:bissection} l'illustre
pour quelques itérations de l'algorithme.

\begin{algorithme}[Méthode de la bissection]
  \label{algo:resolution:bissection}
  Soit $f$ une fonction continue sur l'intervalle $[a, b]$ où $f(a)$
  et $f(b)$ sont de signes opposés. On cherche $x^*$ tel que $f(x^*) =
  0$ en un maximum de $N_{\mathrm{max}}$ itérations.
  \begin{enumerate}
  \item Poser $n = 1$.
  \item Répéter les étapes suivantes.
    \begin{enumerate}
      \pointedenum
    \item Poser $x_n = (a + b)/2$.
    \item \label{algo:resolution:bissection:signe} Si $f(a) f(x_n) >
      0$, poser $a = x_n$, sinon poser $b = x_n$.
    \item \label{algo:resolution:bissection:test} Si $|x_n - x_{n -
        1}|/|x_n| < \varepsilon$, poser $x^* = x_n$ et terminer.
    \item Si $n \geq N_{\mathrm{max}}$, terminer sans convergence.
    \item Poser $n = n + 1$.
    \end{enumerate}
  \end{enumerate}
\end{algorithme}

\begin{figure}[t]
  \centering
<<echo=FALSE, fig=TRUE>>=
par(mfrow = c(2, 2))
f <- function(x) x^3 + x

x <- c(-0.5, 0.75, 0.125)
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2,
      main = "Première itération")
abline(h = 0)
segments(x, -2.08, x, f(x), lty = c(1, 1, 2), col = "darkgray")
points(x, f(x), pch = c(19, 19, 21), bg = "red3")

x <- c(-0.5, 0.125, -0.1875)
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2,
      main = "Seconde itération")
abline(h = 0)
segments(x, -2.08, x, f(x), lty = c(1, 1, 2), col = "darkgray")
points(x, f(x), pch = c(19, 19, 21), bg = "red3")

x <- c(-0.1875, 0.125, -0.03125)
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2,
      main = "Troisième itération")
abline(h = 0)
segments(x, -2.08, x, f(x), lty = c(1, 1, 2), col = "darkgray")
points(x, f(x), pch = c(19, 19, 21), bg = "red3")

x <- c(-0.03125, 0.125, 0.046875)
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2,
      main = "Quatrième itération")
abline(h = 0)
segments(x, -2.08, x, f(x), lty = c(1, 1, 2), col = "darkgray")
points(x, f(x), pch = c(19, 19, 21), bg = "red3")
@
  \caption{Illustration de la méthode de bissection. À chaque
    itération, les points noirs reliés par des segments verticaux en
    ligne pleine identifient les bornes de l'intervalle dans lequel on
    sait que se trouve la solution de l'équation $f(x) = 0$. Le point
    rouge relié par un segment en pointillé est l'essai de
    l'itération, c'est-à-dire le point milieu de l'intervalle. On
    remarquera comment ce point devient la borne inférieure ou
    supérieure de l'intervalle à l'itération suivante.}
  \label{fig:resolution:bissection}
\end{figure}

L'application de l'\autoref{algo:resolution:bissection} génère
une suite $\{x_n\}$, $n = 1, 2, \dots$ qui, si tout se passe bien,
converge vers la valeur $x^*$.

\begin{rems}
  \begin{enumerate}
  \item À l'étape~\ref*{algo:resolution:bissection:signe} de
    l'algorithme, le produit $f(a)
    f(x_n)$ permet de déterminer si l'on se trouve du même côté de
    l'axe des abscisses aux points $a$ et $x_n$ (produit de deux
    valeurs négatives ou de deux valeurs positives) ou de part et d'autre
    de l'axe (produit de valeurs de signes opposés).
  \item L'étape~\ref*{algo:resolution:bissection:test} permet de
    valider si l'algorithme a convergé vers une réponse. La valeur de
    $\varepsilon$ sera donc en général «petite».
  \item Nous avons utilisé l'erreur relative comme critère d'arrêt à
    l'étape~\ref*{algo:resolution:bissection:test}. Il s'agit en
    général du meilleur choix. En effet, un critère tel que $|f(x_n)|
    < \varepsilon$ peut être satisfait même si $x_n \gg x^*$ ou $x_n
    \ll x^*$ (voir la \autoref{fig:resolution:critere} pour deux
    exemples). Quant à l'erreur absolue $|x_n - x_{n - 1}| <
    \varepsilon$, l'inégalité peut être satisfaite même si la suite
    $\{x_n\}$ diverge.
  \end{enumerate}
\end{rems}

\begin{figure}
  \centering
<<echo=FALSE, fig=TRUE, height=4, width=8>>=
par(mfrow = c(1, 2))
f <- function(x) x^3 - x^2 - x - 10
curve(f(x), xlim = c(-10, 10), xlab = "x", ylab = "f(x)", lwd = 2)
points(Re(polyroot(c(-10, -1, -1, 1))[3]), 0, pch = 19)
abline(h = 0)

f <- function(x) x^3 - x^2 - x - 0.2
curve(f(x), xlim = c(-1, 2), xlab = "x", ylab = "f(x)", lwd = 2)
points(Re(polyroot(c(-0.2, -1, -1, 1))[3]), 0, pch = 19)
abline(h = 0)
@
  \caption{Deux exemples de fonctions pour lesquelles on pourrait
    avoir $|f(x_n)| < \varepsilon$ même si $x_n \gg x^*$ ou $x_n \ll
    x^*$. Le point identifie la véritable racine dans chaque
    graphique.}
  \label{fig:resolution:critere}
\end{figure}

\begin{exemple}
  \label{ex:resolution:bissection_1}
  On cherche la racine de $f(x) = x^3 + 4 x^2 - 10$ dans l'intervalle
  $[1, 2]$. On peut vérifier que la fonction $f$ n'a qu'une seule
  racine dans cet l'intervalle et que, de plus, $f(1) = -5$ et $f(2) =
  14$. Ainsi, $a = 1$ et $b = 2$ constituent des valeurs de départ
  adéquates.

  Le code R de la \autoref{sec:resolution:code} définit une
  fonction \code{bissection} dont les arguments sont:
  \begin{enumerate}
  \item la fonction $f(x)$;
  \item la valeur de $a$;
  \item la valeur de $b$;
  \item la valeur de $\varepsilon$ ($10^{-6}$ par défaut);
  \item le nombre maximal d'itérations $N_{\mathrm{max}}$ ($100$ par
    défaut);
  \item une valeur booléenne indiquant si les calculs intermédiaires
    doivent ou non être affichés à l'écran: si l'argument est
    \code{TRUE}, les valeurs de $a$, $b$, $x_n$ et $f(x_n)$ sont
    affichées à chaque itération.
  \end{enumerate}
  La fonction retourne une liste dont l'élément \code{\$root} contient
  la réponse et l'élément \code{\$nb.iter} le nombre d'itérations
  nécessaire pour obtenir cette réponse.

  \begin{gotoR}
    Exécuter le code informatique de la
    \autoref{sec:resolution:code} pour définir la fonction
    \code{bissection} puis résoudre cet exemple.
  \end{gotoR}

<<echo=FALSE>>=
source("bissection.R")
f <- function(x) x^3 + 4*x^2 - 10
res <- bissection(f, 1, 2, TOL=1E-5)
@

  Après \Sexpr{res$nb.iter} %$
  itérations de la fonction \code{bissection}, la réponse obtenue est,
  à neuf décimales, %
  $\nombre{\Sexpr{format(res$root, digits = 10, decimal.mark = ",")}}$. %$
  L'erreur d'approximation est au maximum de
  \begin{displaymath}
    |x^* - x_{17}| < |b_{18} - a_{18}| =
    |1,365234 - 1,365227| = 0,000007
  \end{displaymath}
  et, puisque $|a_{18}| < |x^*|$,
  \begin{displaymath}
    \frac{|x^* - x_{17}|}{|x^*|} < \frac{|b_{18} - a_{18}|}{|a_{18}|} =
    5,13 \times 10^{-6}.
  \end{displaymath}
  La réponse est donc exacte à au moins cinq décimales près. %
  \qed
\end{exemple}

\begin{exemple}
  \label{ex:resolution:bissection_2}
  La valeur présente d'une série de dix paiements de fin d'année est
  $8,2218$. Pour déterminer le taux d'intérêt (ou taux de rendement,
  selon le point de vue), on cherche $i$ tel que $f(i) =
  a_{\angl{10}\, i} - 8,2218 = 0$.

  \begin{gotoR}
    Exécuter le code informatique de la
    \autoref{sec:resolution:code} correspondant à cet exemple pour
    la solution.
  \end{gotoR}
  \qed
\end{exemple}


\begin{prob-astuce}
  La méthode de bissection est en fait une systématisation de la
  technique d'essai-erreur intuitive présentée précédemment.

  On utilise l'\autoref{algo:resolution:bissection} avec
  $f(x) = H(x) - 9$, $a = 1$ et $b = 31$.
\end{prob-astuce}


\section{Méthode du point fixe}
\label{sec:resolution:pointfixe}

La solution de l'équation
\begin{equation*}
  g(x) = x
\end{equation*}
est un \emph{point fixe} de la fonction $g$. Il s'agit du point où les
fonctions $g(x)$ et $y = x$ sont égales, c'est-à-dire là où la fonction
$g$ croise la droite à 45{\textdegree} dans le plan.

Tout problème de recherche de racine peut être exprimé comme un
problème de point fixe. Par exemple, en définissant
\begin{equation*}
  g(x) = x - f(x),
\end{equation*}
les problèmes de trouver $x$ tel que $g(x) = x$ ou tel que $f(x) = 0$ sont
équivalents.

La méthode du point fixe repose sur le théorème du même nom. Celui-ci
fournit les conditions garantissant, d'une part, l'existence d'un
point fixe pour une fonction $g$ dans un intervalle donné et, d'autre
part, l'unicité de ce point fixe. Un point fixe unique peut néanmoins
exister sans que ces conditions ne soient remplies.

\begin{thm}[Théorème du point fixe]
  \label{thm:resolution:pointfixe}
  Soit $g$ une fonction continue sur un intervalle $[a, b]$.
  \begin{enumerate}
  \item Si $g(x) \in [a, b]$ pour tout $x \in [a, b]$, alors $g$ a un
    point fixe dans $[a, b]$.
  \item Si, de plus, $g^\prime(x)$ existe sur $(a, b)$ et qu'il existe
    une constante $k$ tel que
    \begin{displaymath}
      |g^\prime(x)| \leq k < 1
    \end{displaymath}
    pour tout $x \in (a, b)$, alors $g$ a un point fixe \emph{unique}
    dans $[a, b]$.
  \end{enumerate}
\end{thm}

\begin{proof}
  Le théorème compte deux volets. Nous en faisons une démonstration
  simplifiée ne reposant que sur des arguments graphiques.

  \begin{enumerate}
  \item Le premier volet garantit l'existence d'un point fixe sur $[a,
    b]$ si l'image de la fonction $g$ se trouve aussi dans un
    intervalle $[a, b]$. Cette paire d'intervalles engendre le carré
    en pointillé que l'on retrouve dans les graphiques de la
    \autoref{fig:resolution:demo}.

    En définitive, le premier volet du théorème établit que si la
    fonction continue $g$ entre dans l'intervalle $[a, b]$ par la
    gauche du carré ($g(x) \in [a, b]$) et en ressort par la droite
    (idem), alors elle doit forcément croiser la droite $y = x$.
    Observons le graphique (a) de la \autoref{fig:resolution:demo}:
    \begin{itemize}
    \item $g(x) \in [a, b]$ pour tout $x \in [a, b]$, donc un point
      fixe existe nécessairement;
    \item $h(x) \notin [a, b]$ pour tout $x \in [a, b]$, donc la
      fonction n'a pas nécessairement de point fixe dans $[a, b]$;
    \item $k(x) \notin [a, b]$ pour tout $x \in [a, b]$, mais un point
      fixe demeure néanmoins possible.
    \end{itemize}
  \item Le second volet garantit l'unicité du point fixe si la pente
    de la fonction sur $(a, b)$ n'excède jamais $1$. Cette condition
    empêche la fonction de croiser la droite $y = x$ une première fois
    et de la croiser de nouveau suite à une forte augmentation.
    Comparons les deux fonctions du graphique (b) de la
    \autoref{fig:resolution:demo}:
    \begin{itemize}
    \item $g^\prime(x) < 1$ pour tout $x \in (a, b)$, donc $g(x)$
      croise $y = x$ en un seul point et le point fixe est unique;
    \item $h(x) \in [a, b]$ pour tout $x \in [a, b]$, mais
      $h^\prime(x) > 1$ pour $x \in (a, b)$, ce qui ouvre la porte à
      des points fixes multiples, tel qu'illustré.
    \end{itemize}
  \end{enumerate}

  \begin{figure}
    \setkeys{Gin}{width=\textwidth}
    \begin{minipage}{0.45\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
par(mar = c(2, 2, 1, 1))
f <- function(x) x
g <- function(x) x - (x^3 + 4 * x^2 - 10)/(3 * x^2 + 8 * x)
k <- function(x) g(x - 0.5) + 0.3
h <- function(x) -2 * x^2 + 7 * x - 4.75
curve(g, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, axes = FALSE, xlab = "", ylab = "")
curve(h, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, col = "red3", add = TRUE)
curve(k, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, col = "orange1", add = TRUE)
curve(f, add = TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1), lty = 2, border = "blue")
axis(1, at = c(1, 2), labels = c("a", "b"))
axis(2, at = c(1, 2), labels = c("a", "b"))
text(rep(2.2, 3), c(g(2.2), h(2.2), k(2.2)) + c(0.05, 0.09, 0.05),
     c("g", "h", "k"))
box()
@
      \subcaption{existence du point fixe}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
par(mar = c(2, 2, 1, 1))
f <- function(x) x
g <- function(x) x - (x^3 + 4 * x^2 - 10)/(3 * x^2 + 8 * x)

## Les points ci-dessous ont été obtenus avec la fonction drawPlot()
## du package Hmisc:
##
## drawPlot(Abline(0, 1), Abline(h = 1), Abline(h = 2),
##          Abline(v = 1), Abline(v = 2),
##          Curve('smooth', ask = TRUE),
##          xlim = c(0.75, 2.25), ylim = c(0.75, 2.25))
x <- c(
0.7840067, 0.8267755, 0.8668402, 0.9044605, 0.9402250, 0.9748105, 1.0088406,
1.0428095, 1.0770484, 1.1117217, 1.1468403, 1.1822866, 1.2178442, 1.2532294,
1.2881214, 1.3221886, 1.3551113, 1.3865996, 1.4164060, 1.4443339, 1.4702415,
1.4940425, 1.5157034, 1.5352392, 1.5527068, 1.5681983, 1.5818330, 1.5937504,
1.6041027, 1.6130488, 1.6207487, 1.6273589, 1.6330289, 1.6378987, 1.6420969,
1.6457396, 1.6489303, 1.6517600, 1.6543073, 1.6566399, 1.6588148, 1.6608796,
1.6628736, 1.6648288, 1.6667705, 1.6687184, 1.6706870, 1.6726867, 1.6747240,
1.6768025, 1.6789227, 1.6810837, 1.6832826, 1.6855164, 1.6877815, 1.6900755,
1.6923975, 1.6947488, 1.6971339, 1.6995611, 1.7020431, 1.7045971, 1.7072455,
1.7100156, 1.7129394, 1.7160532, 1.7193971, 1.7230142, 1.7269499, 1.7312507,
1.7359636, 1.7411355, 1.7468125, 1.7530396, 1.7598611, 1.7673205, 1.7754617,
1.7843296, 1.7939715, 1.8044381, 1.8157853, 1.8280743, 1.8413726, 1.8557528,
1.8712913, 1.8880650, 1.9061467, 1.9255983, 1.9464634, 1.9687572, 1.9924568,
2.0174906, 2.0437286, 2.0709745, 2.0989604, 2.1273455, 2.1557203, 2.1836199,
2.2105525, 2.2360593)
y <- c(
1.184281, 1.174952, 1.167810, 1.162311, 1.158103, 1.154966, 1.152779, 1.151487,
1.151073, 1.151545, 1.152918, 1.155205, 1.158409, 1.162524, 1.167523, 1.173368,
1.180005, 1.187368, 1.195383, 1.203970, 1.213046, 1.222532, 1.232351, 1.242432,
1.252714, 1.263146, 1.273686, 1.284303, 1.294978, 1.305699, 1.316463, 1.327275,
1.338145, 1.349088, 1.360123, 1.371268, 1.382545, 1.393974, 1.405574, 1.417363,
1.429356, 1.441564, 1.453996, 1.466657, 1.479547, 1.492662, 1.505995, 1.519534,
1.533262, 1.547157, 1.561196, 1.575350, 1.589585, 1.603868, 1.618160, 1.632420,
1.646607, 1.660678, 1.674589, 1.688297, 1.701760, 1.714935, 1.727783, 1.740267,
1.752351, 1.764005, 1.775200, 1.785911, 1.796119, 1.805806, 1.814961, 1.823575,
1.831645, 1.839169, 1.846153, 1.852601, 1.858524, 1.863933, 1.868844, 1.873273,
1.877238, 1.880758, 1.883856, 1.886556, 1.888882, 1.890862, 1.892529, 1.893916,
1.895063, 1.896012, 1.896807, 1.897496, 1.898117, 1.898702, 1.899259, 1.899759,
1.900124, 1.900207, 1.899779, 1.898530)

curve(g, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, axes = FALSE, xlab = "", ylab = "")
lines(x, y, lwd = 2, col = "red3")
curve(f, add = TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1), lty = 2, border = "blue")
axis(1, at = c(1, 2), labels = c("a", "b"))
axis(2, at = c(1, 2), labels = c("a", "b"))
text(rep(2.2, 2), c(g(2.2), y[96]) + 0.05, c("g", "h"))
box()
@
      \subcaption{unicité du point fixe}
    \end{minipage}
    \caption{Exemples de graphiques permettant de faire la
      démonstration du théorème du point fixe}
    \label{fig:resolution:demo}
    \setkeys{Gin}{width=0.8\textwidth}
  \end{figure}
\end{proof}

Le théorème suivant, donné sans preuve, établit véritablement la
procédure qui sera utilisée par la méthode numérique pour trouver le
point fixe d'une fonction.

\begin{thm}
  \label{thm:resolution:pointfixe:2}
  Si les deux conditions du \autoref{thm:resolution:pointfixe}
  sont satisfaites, alors la série $\{x_n = g(x_{n - 1})\}$ converge
  vers un point fixe unique dans $[a, b]$.
\end{thm}

Tel que mentionné au début de la
\autoref{sec:resolution:bissection}, toutes les méthodes
numériques --- et la méthode du point fixe ne fait pas exception ---
procèdent par essais et erreurs, mais de manière systématique. Le
\autoref{thm:resolution:pointfixe:2} nous dit que pour trouver un
point fixe, le meilleur essai $x_n$ à faire est la valeur de la
fonction $g$ à l'essai précédent, $g(x_{n - 1})$. La
\autoref{fig:resolution:pointfixe} illustre comment la suite des
essais successifs peut converger vers le point fixe.

\begin{figure}
  \centering
  \setkeys{Gin}{width=\textwidth}
<<echo=FALSE, fig=TRUE, height=4, width=8>>=
par(mfrow = c(1, 2))
f <- function(x) x

## Fonction décroissante
g <- function(x) -0.035 * x^2 +  10

lim <- c(7, 8.5)
curve(g, xlim = lim, ylim = lim, lwd = 2)
curve(f, add = TRUE)

x <- numeric(6)
x[1] <- 7.1
for (i in 2:length(x)) x[i] <- g(x[i - 1])

segments(x[1], 6.95, x[1], x[2], lty = 2, col = "darkgray")
segments(x[-1], x[-1], x[-1], g(x[-1]), lty = 2, col = "darkgray")
arrows(head(x, -1), x[-1], x[-1], x[-1],
       col = "blue", length = 0.07)
points(x, g(x), pch = 21, bg = "red3")

## Fonction croissante
g <- function(x) -0.035 * (x - 15)^2 +  10
lim <- c(7.5, 8.8)
curve(g, xlim = lim, ylim = lim, lwd = 2)
curve(f, add = TRUE)
x <- numeric(5)
x[1] <- 7.7
for (i in 2:length(x)) x[i] <- g(x[i - 1])

segments(x[1], 6.95, x[1], x[2], lty = 2, col = "darkgray")
segments(x[-1], x[-1], x[-1], g(x[-1]), lty = 2, col = "darkgray")
arrows(head(x, -1), x[-1], x[-1], x[-1],
       col = "blue", length = 0.07)
points(x, g(x), pch = 21, bg = "red3")
@
  \caption{Illustrations de la méthode du point fixe pour une fonction
    décroissante et pour une fonction croissante. Les points rouges
    identifient les essais successifs, le premier étant, ici, le point
    le plus à gauche dans les graphiques. Les flèches illustrent
    comment est déterminé l'essai suivant. La relation $x_n = g(x_{n -
      1})$ implique que l'abscisse d'un essai correspond à la
    projection de l'ordonnée de l'essai précédent sur la droite $y =
    x$.}
  \label{fig:resolution:pointfixe}
  \setkeys{Gin}{width=0.8\textwidth}
\end{figure}

Nous pouvons dès lors composer un algorithme de résolution par la
méthode du point fixe.

\begin{algorithme}[Méthode du point fixe]
  \label{algo:resolution:pointfixe}
  Soit $g$ une fonction et $x_0$ une valeur de départ. On cherche
  $x^*$ tel que $g(x^*) = x^*$ en un maximum de $N_{\mathrm{max}}$
  itérations.
  \begin{enumerate}
  \item Poser $n = 1$.
  \item Répéter les étapes suivantes.
    \begin{enumerate}
    \item Poser $x_n = g(x_{n - 1})$.
    \item Si $|x_n - x_{n - 1}|/|x_n| < \varepsilon$, alors poser $x^*
      = x_n$ et terminer.
    \item Si $n \geq N_{\mathrm{max}}$, terminer sans convergence.
    \item Poser $n = n + 1$.
    \end{enumerate}
  \end{enumerate}
\end{algorithme}

\begin{rem}
  Comme on peut le déduire des illustrations de la
  \autoref{fig:resolution:pointfixe}, la rapidité de la convergence
  est fonction de $g^\prime(x)$: plus la pente est \emph{faible}, plus
  la convergence est \emph{rapide}, et vice versa.
\end{rem}

\begin{exemple}
  \label{ex:resolution:pointfixe_1}
  On répète l'\autoref{ex:resolution:bissection_2} à l'aide de la
  méthode du point fixe, soit trouver le taux d'intérêt $i$ tel que
  $a_{\angl{10}\,i} = 8,2218$. On a déjà déterminé à
  l'\autoref{ex:resolution:bissection_2} que le taux d'intérêt se
  trouve dans l'intervalle $[0,035, 0,040]$. On peut exprimer le
  problème sous forme de point fixe ainsi: trouver la valeur de $i$
  tel que
  \begin{displaymath}
    g(i) = \frac{1 - (1 + i)^{-10}}{8,2218} = i.
  \end{displaymath}

  Le code R de la \autoref{sec:resolution:code} définit une
  fonction \code{pointfixe} similaire à la fonction \code{bissection}
  présentée à la \autoref{sec:resolution:bissection}. Ses
  arguments sont d'ailleurs les mêmes, à l'exception que les points
  $a$ et $b$ sont remplacés par une valeur de départ $x_0$.

  \begin{gotoR}
    Exécuter le code informatique de la
    \autoref{sec:resolution:code} correspondant à ce bloc de
    matière pour définir la fonction \code{pointfixe} puis résoudre
    cet exemple.
  \end{gotoR}

<<echo=FALSE>>=
g <- function(i) (1 - (1 + i)^(-10))/8.2218
res.pf <- pointfixe(g, start = 0.0375)
@
  Il faut \Sexpr{res.pf$nb.iter} %$
  itérations pour obtenir la convergence avec un critère identique à
  celui utilisé avec la bissection. Pour ce type de problème, la
  méthode du point fixe n'est pas la plus efficace.
  \qed
\end{exemple}

\begin{exemple}
  \label{ex:resolution:pointfixe_2}
  On répète l'\autoref{ex:resolution:bissection_1} à l'aide de la
  méthode du point fixe, à savoir: trouver la racine de $f(x) = x^3 +
  4 x^2 - 10 = 0$ dans l'intervalle $[1, 2]$.

  Il y a plusieurs façons d'exprimer le problème de recherche de
  racine en termes de point fixe. On examine cinq différentes
  fonctions toutes algébriquement équivalentes:
  \begin{align*}
    g_1(x) &= x - x^3 - 4 x^2 + 10  \\
    g_2(x) &= \left( \frac{10}{x} - 4x \right)^{1/2} \\
    g_3(x) &= \frac{1}{2} (10 - x^3)^{1/2} \\
    g_4(x) &= \left( \frac{10}{4 + x} \right)^{1/2} \\
    g_5(x) &= x - \frac{x^3 + 4 x^2 - 10}{3x^2 + 8x}.
  \end{align*}
  Il est laissé en exercice de vérifier que, dans chacun des cas, la
  racine de $f(x)$ est le point fixe de $g_i(x)$, $i = 1, \dots, 5$.

  Les graphiques des cinq fonctions ci-dessus se trouvent à la
  \autoref{fig:resolution:pointfixe_2}. L'examen de ces graphiques
  permet de déterminer, avant de faire tout calcul, pour quelles
  fonctions la procédure itérative du point fixe convergera ainsi que
  les taux de convergence relatif, le cas échéant.
  \begin{figure}
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
f <- function(x) x
lim <- c(0.95, 2.05)
g1 <- function(x) x - x^3 - 4 * x^2 + 10
curve(g1, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[1](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_1(x)$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
g2 <- function(x) sqrt(10/x - 4*x)
curve(g2, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[2](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_2(x)$}
    \end{minipage}
    \newline
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
g3 <- function(x) sqrt(10 - x^3)/2
curve(g3, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[3](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_3(x)$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
g4 <- function(x) sqrt(10/(4 + x))
curve(g4, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[4](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_4(x)$}
    \end{minipage}
    \newline
    \centering
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
g5 <- function(x) x - (x^3 + 4*x^2 - 10)/(3*x^2 + 8*x)
curve(g5, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[5](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_5(x)$}
    \end{minipage}
    \caption{Graphiques des cinq fonctions de
      l'\autoref{ex:resolution:pointfixe_2}}
    \label{fig:resolution:pointfixe_2}
  \end{figure}

  \begin{gotoR}
    Compléter cet exemple en exécutant le code informatique
    correspondant à la \autoref{sec:resolution:code}.
  \end{gotoR}
  \qed
\end{exemple}

\begin{prob-astuce}
  Pour utiliser l'algorithme du point fixe
  \ref{algo:resolution:pointfixe}, il faut exprimer notre problème de
  recherche du jour du mois où l'ensoleillement est de $9$ heures sous
  la forme $g(x) = x$.

  Nous pourrions simplement réécrire l'équation de départ $H(x) = 9$
  sous la forme $H(x) - 9 + x = x$. Seulement, la pente de cette
  fonction est très près de $1$ et la méthode du point fixe serait
  donc très lente.

  Isolons donc plutôt une valeur de $x$ dans l'équation de départ
  \begin{equation*}
    e^{0,001312 x + 2,778538} - e^{-0,001431 x + 2,016340} = 9.
  \end{equation*}
  En isolant le $x$ dans la première exponentielle, cette équation se
  réécrit
  \begin{equation*}
    x = \frac{\ln (9 + e^{-0,001431 x + 2,016340}) - 2,778538}{0,001312}.
  \end{equation*}
  Nous pourrions donc utiliser l'algorithme du point fixe avec la
  fonction
  \begin{equation*}
    \label{eq:resolution:pf-app}
    g(x) = \frac{\ln (9 + e^{-0,001431 x + 2,016340}) - 2,778538}{0,001312}.
  \end{equation*}
  On peut vérifier graphiquement que la pente de cette fonction est
  beaucoup plus faible que celle de $H(x) - 9 + x$.
\end{prob-astuce}


\section{Méthode de Newton--Raphson}
\label{sec:resolution:newtonraphson}

La méthode de Newton--Raphson est l'une des plus populaires et
puissantes méthodes numériques de résolution d'équations à une
variable. Les algorithmes plus élaborés qui existent aujourd'hui sont
d'ailleurs souvent basés sur cet algorithme.

L'étude de la méthode de Newton--Raphson nous ramène au problème de
recherche de la racine $x^*$ d'une fonction $f(x)$, c'est-à-dire la
solution de $f(x) = 0$. Il y a plusieurs manières d'introduire cette
méthode de résolution. Nous privilégierons une approche graphique.

Dans la méthode de Newton--Raphson, les essais successifs sont
déterminés en utilisant les points où la tangente de la fonction $f$ à
l'essai précédent croise l'axe des abscisses; voir la
\autoref{fig:resolution:newtonraphson} pour une illustration.

\begin{figure}[t]
  \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) (x - 0.2)^3 + x - 0.2
fp <- function(x) 3 * (x - 0.2)^2 + 1
tangente <- function(x, a) fp(a) * (x - a) + f(a)
curve(f(x), xlim = c(-0.8, 1.2), ylim = c(-0.5, 1.5), lwd = 2)
abline(h = 0)
x <- c(0.98, 0, 0)
for (i in 2:3)
    x[i] <- -(f(x[i - 1]) - x[i - 1] * fp(x[i - 1]))/fp(x[i - 1])

segments(x, c(-1.1, 0, 0), x, f(x), lty = 2, col = "darkgray")
arrows(1.2, tangente(1.2, x[1]), x[2], 0, col = "blue", length = 0.1)
arrows(0.95, tangente(0.95, x[2]), x[3], 0, col = "blue", length = 0.1)

points(x, f(x), pch = 21, bg = "red3")
@
  \caption{Illustration de la méthode de Newton--Raphson. Les points
    rouges identifient les essais successifs, le premier étant, ici,
    le point le plus à droite dans le graphique. Les flèches
    illustrent comment est déterminé l'essai suivant. On trace la
    tangente en un point; le prochain essai est la valeur en abscisse
    où cette tangente croise l'axe.}
  \label{fig:resolution:newtonraphson}
\end{figure}

Une première justification mathématique de la méthode va comme suit.
Soit $\tilde{x}$ un point «près» de la racine $x^*$ et tel que
$f(\tilde{x}) \neq 0$. Comme on peut le voir à la
\autoref{fig:resolution:newtonraphson}, la tangente de $f$ en
$\tilde{x}$ croise l'abscisse en un point $\hat{x}$ «près» de $x^*$.
Ainsi, le point $\hat{x}$ est tel que
\begin{displaymath}
  \frac{f(\tilde{x}) - 0}{\tilde{x} - \hat{x}} = f^\prime(\tilde{x}),
\end{displaymath}
d'où
\begin{align*}
  x^*
  &\simeq \hat{x} \\
  &= \tilde{x} - \frac{f(\tilde{x})}{f^\prime(\tilde{x})}.
\end{align*}

On peut également justifier la formule précédente à l'aide du
développement de Taylor de $f(x)$ autour de $\tilde{x}$:
\begin{equation*}
  f(x)
  = f(\tilde{x}) + (x - \tilde{x}) f^\prime(\tilde{x})
  + \frac{(x - \tilde{x})^2}{2} f^{\prime\prime}(\tilde{x}) + \dots
\end{equation*}
Toujours en supposant que $\tilde{x}$ est près de $x^*$, on a
\begin{equation*}
  f(x^*) = 0 = f(\tilde{x}) + (x^* - \tilde{x}) f^\prime(\tilde{x}) +
  \frac{(x^* - \tilde{x})^2}{2} f^{\prime\prime}(\tilde{x}) + \dots,
\end{equation*}
où l'on peut considérer les termes de puissance $2$ et plus dans le
développement comme négligeables. On obtient alors l'approximation
\begin{equation*}
  x^* \simeq \tilde{x} - \frac{f(\tilde{x})}{f^\prime(\tilde{x})}.
\end{equation*}

Tel qu'illustré à la \autoref{fig:resolution:newtonraphson}, on
peut répéter la procédure ci-dessus si le point $\hat{x}$ est trop
éloigné de la racine $x^*$. On utilise alors $\hat{x}$ comme nouveau
point où l'on calcule la tengente, et ainsi de suite jusqu'à
l'obtention d'une «bonne» approximation.

Formellement, soit $f$ une fonction différentiable sur $[a, b]$ et
$x^* \in [a, b]$. Alors $x^*$ peut être obtenu comme le point de
convergence de la série $\{x_n\}$ définie par
\begin{displaymath}
  x_n = x_{n - 1} - \frac{f(x_{n - 1})}{f^\prime(x_{n - 1})},
\end{displaymath}
avec $x_0$ une valeur de départ quelconque.
L'\autoref{algo:resolution:newtonraphson} systématise cette
procédure.

\begin{algorithme}[Méthode de Newton--Raphson]
  \label{algo:resolution:newtonraphson}
  Soit $f$ une fonction continue et différentiable sur l'intervalle
  $[a, b]$. On cherche $x^*$ tel que $f(x^*) = 0$ en un maximum de
  $N_{\mathrm{max}}$ itérations avec une valeur de départ $x_0$.
  \begin{enumerate}
  \item Poser $n = 1$.
  \item Répéter les étapes suivantes.
    \begin{enumerate}
    \item Poser $x_n = x_{n-1} - f(x_{n-1})/f^\prime(x_{n-1})$.
    \item Si $|x_n - x_{n - 1}|/|x_n| < \varepsilon$, alors poser $x^*
      = x_n$ et terminer.
    \item Si $n \geq N_{\mathrm{max}}$, terminer sans convergence.
    \item Poser $n = n + 1$.
    \end{enumerate}
  \end{enumerate}
\end{algorithme}

\begin{rems}
  \begin{enumerate}
  \item \label{algo:resolution:rem} L'examen attentif de la méthode de
    Newton--Raphson revèle qu'il s'agit en fait d'une procédure de
    point fixe avec
    \begin{displaymath}
      g(x) = x - \frac{f(x)}{f^\prime(x)}.
    \end{displaymath}
    La méthode de Newton--Raphson nous fournit donc la «bonne»
    fonction $g$ à utiliser dans la méthode du point fixe pour trouver
    la racine de la fonction $f$.
  \item On peut démontrer que si $f$ est doublement différentiable sur
    $[a, b]$ et que $x^* \in [a, b]$ est tel que $f(x^*) = 0$ et
    $f^\prime(x^*) \neq 0$, alors il existe un $\delta > 0$ tel que la
    série $\{x_n\}$ converge vers $x^*$ pour tout $x_0 \in [x^* -
    \delta, x^* + \delta]$. Autrement dit:
    \begin{itemize}
    \item les hypothèses du \autoref{thm:resolution:pointfixe}
      sont satisfaites;
    \item la méthode de Newton--Raphson fonctionne toujours avec un
      «bon» choix de valeur de départ $x_0$.
    \end{itemize}
  \end{enumerate}
\end{rems}

\begin{exemple}
  \label{ex:resolution:newtonraphson_1}
  On reprend l'\autoref{ex:resolution:pointfixe_1} de calcul d'un taux
  de rendement, cette fois à l'aide de la méthode de Newton--Raphson.
  Vous savez peut-être de votre cours de mathématiques financières que
  la méthode de Newton--Raphson est la plus efficace pour résoudre ce
  genre de problème. La \autoref{fig:resolution:newtonraphson_1}
  montre pourquoi elle est plus efficace que la méthode du point fixe:
  la fonction
  \begin{equation*}
    g(i) =  i - \frac{f(i)}{f^\prime(i)}
  \end{equation*}
  avec $f(i) = a_{\angl{n}\, i} - k$ est beaucoup plus plate que la
  fonction
  \begin{equation*}
    g(i) = \frac{1 - v^n}{k}
  \end{equation*}
  utilisée à l'\autoref{ex:resolution:pointfixe_1}.
  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) x
an <- function(i, n) (1 - (1 + i)^(-n))/i
anp <- function(i, n) (n * i * (1 + i)^(-n - 1) + (1 + i)^(-n) - 1)/i^2
g <- function(x) x - (an(x, 10) - 8.2218)/anp(x, 10)
lim <- c(0.0345, 0.0405)
curve(g, xlim = lim, ylim = lim,
      lwd = 2, xlab = "i", ylab = "g(i)")
curve(f, add = TRUE)
polygon(c(0.035, 0.035, 0.04, 0.04), c(0.035, 0.04, 0.04, 0.035),
        lty = "dashed", border = "blue")
@
    \caption{Fonction $g(i) = i - f(i)/f^\prime(i)$ où $f(i) = (1 - (1 +
      i)^{-10})/i - 8,2218$ pour $0,035 \leq i \leq 0,040$ (ligne épaisse)
      et la droite $y = i$ (ligne mince)}
    \label{fig:resolution:newtonraphson_1}
  \end{figure}

  On a défini en R une fonction \code{nr} similaire à la fonction
  \code{pointfixe} mentionnée à la \autoref{sec:resolution:pointfixe},
  sauf qu'on y a ajouté un argument pour la dérivée de la fonction
  $f(x)$.

  \begin{gotoR}
    Exécuter le code informatique de la \autoref{sec:resolution:code}
    correspondant à ce bloc de matière pour définir la fonction
    \code{nr} puis résoudre cet exemple. Prendre note comment l'on
    peut également utiliser la fonction \code{pointfixe} pour obtenir
    le taux de rendement.
  \end{gotoR}

<<echo=FALSE>>=
f <- function(i) (1 - (1 + i)^(-10))/i - 8.2218
fp <- function(i) (10 * i * (1 + i)^(-11) + (1 + i)^(-10) - 1)/i^2
res.nr <- nr(f, fp, 0.0375)
@
  La méthode de Newton--Raphson ne requiert donc que
  \Sexpr{res.nr$nb.iter} %$
  itérations pour obtenir un résultat équivalent à celui obtenu par la
  méthode du point fixe avec la fonction $g$ de
  l'\autoref{ex:resolution:pointfixe_1} en
  \Sexpr{res.pf$nb.iter} %$
  itérations. %
  \qed
\end{exemple}

\begin{exemple}
  \label{ex:resolution:newtonraphson_2}
  Revisitons l'\autoref{ex:resolution:bissection_1} où l'on
  cherche la racine de la fonction $f(x) = x^3 + 4 x^2 - 10$ dans
  l'intervalle $[1, 2]$. On a $f^\prime(x) = 3x^2 + 8 x$, d'où
  $f^\prime(x) \neq 0$ pour tout $x \in [1, 2]$. La méthode de
  Newton--Raphson dicte en définitive de rechercher le point fixe de
  la fonction
  \begin{align*}
    g(x) &= x - \frac{f(x)}{f^\prime(x)} \\
    &= x - \frac{x^3 + 4 x^2 - 10}{3 x^2 + 8 x}.
  \end{align*}
  Celle-ci est présentée à la
  \autoref{fig:resolution:newtonraphson_2}. On constate que la
  procédure itérative de Newton--Raphson convergera rapidement vers
  une racine unique dans l'intervalle $[1, 2]$. En effet:
<<echo=TRUE>>=
f <- function(x) x^3 + 4*x^ 2 - 10
fp <- function(x) 3*x^2 + 8 * x
nr(f, fp, start = 1.5)
@
  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
f0 <- function(x) x
lim <- c(0.95, 2.05)
f <- function(x) x^3 + 4*x^ 2 - 10
fp <- function(x) 3*x^2 + 8 * x
g <- function(x) x - f(x)/fp(x)
curve(g, xlim = lim, ylim = lim, lwd = 2)
curve(f0, add = TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
    \caption{Fonction $g(x) = x - f(x)/f^\prime(x)$, où $f(x) = x^3 +
      4 x^2 - 10$}
    \label{fig:resolution:newtonraphson_2}
  \end{figure}

  Le lecteur attentif aura remarqué que la fonction $g$ utilisée ici
  était la fonction $g_5$ dans
  l'\autoref{ex:resolution:pointfixe_2}, celle pour laquelle la
  convergence de la méthode du point fixe était la plus rapide. Mettre
  cette constatation en relation avec la première des remarques
  suivant l'\autoref{algo:resolution:newtonraphson}, à la
  \autopageref{algo:resolution:rem}. %
  \qed
\end{exemple}

\begin{exemple}
  \label{ex:resolution:newtonraphson_3}
  Cet exemple illustre l'importance d'utiliser, pour certaines
  fonctions, une valeur de départ près de la racine. La fonction $f(x)
  = (4x - 7)/(x - 2)$ a une racine en $x = 1,75$ et une asymptote en
  $x = 2$, ce qui cause quelques soucis. (Voir la
  \autoref{fig:resolution:newtonraphson_3-1} pour un graphique de
  cette fonction.)
  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) ifelse(x == 2, NA, (4 * x - 7)/(x - 2))
curve(f, xlim = c(0, 5), lwd = 2)
abline(8, -4, lty = "dashed", col = "blue")
abline(h = 0)
abline(v = 2, lwd = 2, lty = "dotted", col = "darkgray")
curve(f, xlim = c(0, 5), lwd = 2, add = TRUE)
@
  \caption{Fonction $f(x) = (4x - 7)/(x - 2)$ (ligne épaisse),
    asymptote (ligne pointillée) et tangente en $x = 1,5$ (ligne
    traitillée)}
  \label{fig:resolution:newtonraphson_3-1}
  \end{figure}

  On peut tenter de trouver numériquement la racine de la fonction
  $f(x)$ avec l'algorithme de Newton--Raphson en utilisant
  \begin{align*}
    f(x) &= \frac{4x - 7}{x - 2} \\
    \intertext{et}
    f^\prime(x) &= - \frac{1}{(x - 2)^2},
  \end{align*}
  ou encore directement par l'algorithme du point fixe avec
  \begin{align*}
    g(x)
    &= x - \frac{f(x)}{f^\prime(x)} \\
    &= 4x^2 - 14x + 14.
  \end{align*}
  Le graphique de la fonction $g(x)$ ci-dessus se trouve à la
  \autoref{fig:resolution:newtonraphson_3-2}. On notera toutefois que
  le point fixe en $x = 2$ n'est pas une solution acceptable dans le
  problème d'origine.

  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
f0 <- function(x) x
g <- function(x) 4*x^2 - 14*x + 14
lim <- c(1.5, 3)
curve(g, xlim = lim, ylim = lim, lwd = 2)
xx <- c(1.75, 2)
segments(xx, 0, xx, g(xx), lty = 2, col = "darkgray")
axis(1, at = 1.75)
curve(f0, add = TRUE)
@
    \caption{Fonction $g(x) = 4x^2 - 14x + 14$}
    \label{fig:resolution:newtonraphson_3-2}
  \end{figure}

  On constate également dans cette dernière figure que les hypothèses
  pour l'existence et l'unicité d'un point fixe --- et, donc, pour la
  convergence de la méthode de Newton--Raphson --- ne sont pas
  rencontrées. La valeur de départ utilisée aura donc un impact sur la
  réponse obtenue.

  \begin{gotoR}
    Compléter cet exemple en exécutant le code informatique
    correspondant à la \autoref{sec:resolution:code}.
  \end{gotoR}
  \qed
\end{exemple}

Le principal inconvénient de la méthode de Newton--Raphson demeure le
fait de devoir connaître la dérivée de la fonction $f$. Dans les cas
où celle-ci s'avère difficile ou inefficace à calculer, on peut
utiliser la \emph{méthode de la sécante}. Avec cette méthode, plutôt
que d'utiliser la tangente en un essai pour déterminer la valeur de
l'essai suivant, on a recours à la sécante entre les deux essais
précédents; voir la \autoref{fig:resolution:secante}. Les valeurs
des essais successifs sont alors données par:
\begin{equation*}
  x_n = x_{n - 1} - \frac{f(x_{n - 1})(x_{n - 1} - x_{n - 2})}{%
    f(x_{n - 1}) - f(x_{n - 2})},
\end{equation*}
avec $x_0$, $x_1$ des valeurs de départ.

\begin{prob-astuce}
  Nous revenons au problème de départ exprimé sous la forme
  $f(x) = H(x) - 9 = 0$. La fonction des heures d'ensoleillement $H$
  étant simple à dériver, la méthode de Newton--Raphson est simple à
  appliquer. En effet,
  \begin{align*}
    f(x)
    &= H(x) - 9 \\
    &= e^{0,001312 x + 2,778538}
      - e^{-0,001431 x + 2,016340} - 9,
  \end{align*}
  d'où
  \begin{equation*}
    \label{eq:resolution:nr-app}
    f^\prime(x) = 0,001312 e^{0,001312 x + 2,778538}
    + 0,001431 e^{-0,001431 x + 2,016340}.
  \end{equation*}
  Il ne reste qu'à appliquer l'\autoref{algo:resolution:newtonraphson}
  avec les fonctions $f(x)$ et $f^\prime(x)$ ainsi qu'une valeur de
  départ $x_0 \in \{1, 2, \dots, 31\}$.
\end{prob-astuce}

\begin{figure}
  \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) exp(2 * x) - 20
curve(f, xlim = c(0, 2), lwd = 2)
abline(h = 0)
x <- numeric(7)
x[1] <- 0
x[2] <- 2
for (i in 3:length(x))
    x[i] <- x[i - 1] - (f(x[i - 1]) * (x[i - 1] - x[i - 2]))/
    (f(x[i - 1]) - f(x[i - 2]))

segments(x[(1:2)], -21, x[(1:2)], f(x[(1:2)]), lty = 2, col = "darkgray")
segments(x[-c(1, 2)], 0, x[-c(1, 2)], f(x[-c(1, 2)]),
         lwd = 1, lty = "dashed", col = "darkgray")

for (i in 1:(length(x) - 2))
{
    xx <- x[i:(i + 2)]
    fxx <- f(xx)
    segments(xx[1], fxx[1], xx[3], 0, col = "blue")
    arrows(xx[2], fxx[2], xx[3], 0, col = "blue", length = 0.1)
}

points(x, f(x), pch = 21, bg = "red3")
@
  \caption{Illustration de la méthode de la sécante. Cette méthode
    requiert deux essais initiaux. Dans le graphique, il s'agit, dans
    l'ordre, du point à l'extrême gauche et celui à l'extrême droite.
    Les flèches illustrent comment est déterminé l'essai suivant. On
    trace la sécante entre deux points et le prochain essai est la
    valeur en abscisse où cette sécante croise l'axe.}
  \label{fig:resolution:secante}
\end{figure}



\section{Fonctions d'optimisation dans Excel et R}
\label{sec:resolution:fonctions}

Les méthodes de bissection, du point fixe, de Newton--Raphson et
autres permettent de résoudre des équations à une variable de la forme
$f(x) = 0$ ou $g(x) = x$. Il existe également des versions de ces
méthodes pour les systèmes à plusieurs variables comme
\begin{align*}
  f_1(x_1, x_2, x_3) &= 0 \\
  f_2(x_1, x_2, x_3) &= 0 \\
  f_3(x_1, x_2, x_3) &= 0.
\end{align*}

De tels systèmes d'équations surviennent plus souvent qu'autrement
lors de l'optimisation d'une fonction. Par exemple, en recherchant le
maximum ou le minimum d'une fonction $f(x, y)$, on souhaitera résoudre
le système d'équations
\begin{align*}
  \frac{\partial}{\partial x}\, f(x, y) &= 0 \\
  \frac{\partial}{\partial y}\, f(x, y) &= 0.
\end{align*}

La grande majorité des suites logicielles comportent des outils
d'optimisation de fonctions. Ce document passe en revue les fonctions
disponibles dans Excel et R.


\subsection{Solveur de Excel}

Le principal outil d'optimisation utilisé dans Excel est le Solveur.
La rubrique d'aide de cet outil est complète et on trouvera plusieurs
exemples dans le classeur \code{SOLVAMP.XLS} livré avec Excel.

Le reste de cette section est dévolu à des fonctions d'optimisation de
R.

\input{optimisation-fonctions}

\begin{gotoR}
  Des exemples d'utilisation des fonctions R ci-dessus sont fournis
  dans le code informatique de la \autoref{sec:resolution:code}.
\end{gotoR}

\begin{prob-astuce}
  La fonction \code{uniroot} permet de trouver la solution à l'équation
  $f(x) = 0$ dans un intervalle déterminé. Nous pourrons donc l'utiliser
  dans la solution en fin de chapitre pour confirmer les autres
  résultats.
\end{prob-astuce}

\section{Astuce Ripley}
\label{sec:resolution:astuce}

J'ai appris le truc suivant dans une publication de Brian Ripley --- un
important développeur de R --- dans les forums de discussion de
R. Il m'a été très utile à de nombreuses reprises, alors je le
dissémine.

Une application statistique fréquente de l'optimisation est la
maximisation numérique d'une fonction de vraisemblance ou, plus
communément, la minimisation de la log-vraisemblance négative
\begin{equation*}
  -l(\theta) = - \sum_{i = 1}^n \ln f(x_i; \theta).
\end{equation*}
Les fonctions d'optimisation sont d'ailleurs illustrées dans ce
contexte dans le code informatique de la
\autoref{sec:resolution:code}.

En actuariat, nous utilisons principalement des lois de probabilité
dont les paramètres sont strictement positifs. Or, en pratique, il
n'est pas rare que les fonctions d'optimisation s'égarent dans les
valeurs négatives des paramètres. La fonction de densité n'étant pas
définie, la log-vraisemblance vaut alors \code{NaN} et cela peut faire
complètement dérailler la procédure d'optimisation ou, à tout le
moins, susciter des doutes sur la validité de la réponse.

Afin de pallier à ce problème, l'Astuce Ripley{\texttrademark} propose
d'estimer non pas les paramètres de la loi eux-mêmes, mais plutôt
leurs logarithmes. Si l'on définit $\tilde{\theta} = \ln \theta$,
alors on peut écrire la fonction de log-vraisemblance ci-dessus sous
la forme
\begin{equation*}
  -l(\tilde{\theta}) = - \sum_{i = 1}^n \ln f(x_i; e^{\tilde{\theta}}).
\end{equation*}
Dès lors, $\tilde{\theta}$ (qui peut représenter un ou plusieurs
paramètres) demeure valide sur tout l'axe des réels, ce qui permet
d'éviter bien des soucis de nature numérique lors de la minimisation
de $-l(\tilde{\theta})$.

Évidemment, le résultat de l'optimisation est l'estimateur du maximum
de vraisemblance de $\tilde{\theta}$. Il faudra donc veiller à faire
la transformation inverse pour retrouver l'estimateur de $\theta$.

L'utilisation de l'Astuce est illustrée à la
\autoref{sec:resolution:code}.



\section{Outils additionnels}
\label{sec:resolution:plus}

Les packages disponible sur CRAN fournissent plusieurs autres outils
d'optimisation pour R. Pour un bon résumé des options disponibles,
consulter la \emph{CRAN Task View} consacrée à l'optimisation:
\begin{quote}
  \url{http://cran.r-project.org/web/views/Optimization.html}
\end{quote}


\begin{prob-solution}
  Nous résolvons avec R notre problème consistant à trouver la valeur
  de $x$ tel que $H(x) = 9$ avec les méthodes numériques étudiées dans
  ce chapitre. Les fonctions \code{bissection}, \code{pointfixe} et
  \code{nr} ci-dessous sont celles tirées du code informatique de la
  \autoref{sec:resolution:code}. \\

  Méthode de bissection: résolution de $H(x) - 9 = 0$.
<<echo=TRUE>>=
H <- function(x)
    exp(0.001312 * x + 2.778538) -
        exp(-0.001431 * x + 2.016340)
bissection(FUN = function(x) H(x) - 9,
           lower = 1, upper = 31)
@

  Méthode du point fixe: résolution de $g(x) = x$ avec la fonction $g$
  de l'encadré de la \autopageref{eq:resolution:pf-app}.
<<echo=TRUE>>=
g <- function(x)
    (log(9 + exp(-0.001431*x+2.016340)) - 2.778538) /
    0.001312
pointfixe(g, start = 15)
@

  Méthode de Newton--Raphson: résolution de $f(x) = H(x) - 9 = 0$ avec
  les fonctions $f$ et $f^\prime$ de l'encadré de la
  \autopageref{eq:resolution:nr-app}.
<<echo=TRUE>>=
f <- function(x) H(x) - 9
fp <- function(x)
    0.001312 * exp(0.001312 * x + 2.778538) +
        0.001431 * exp(-0.001431 * x + 2.016340)
nr(f, fp, start = 15)
@

  Vérification avec la fonction \code{uniroot}.
<<echo=TRUE>>=
uniroot(f, c(1, 31))$root
@
\end{prob-solution}

\newpage


\section{Code informatique}
\label{sec:resolution:code}

\lstinputlisting[firstline=3]{resolution_equations.R}

%\vfill
\medskip

\input{exercices-resolution_equations}

%%% Local Variables:
%%% engine: xetex
%%% TeX-master: "methodes_numeriques-partie_3"
%%% coding: utf-8
%%% End:
