%%% Copyright (C) 2018 Vincent Goulet
%%%
%%% Ce fichier fait partie du projet «Méthodes numériques en actuariat»
%%% http://github.com/vigou3/methodes-numeriques-en-actuariat
%%%
%%% Cette création est mise à disposition selon le contrat
%%% Attribution-Partage dans les mêmes conditions 4.0
%%% International de Creative Commons.
%%% http://creativecommons.org/licenses/by-sa/4.0/

\chapter{Résolution d'équations à une variable}
\label{chap:resolution}

<<echo=FALSE>>=
options(width = 52)
source("bissection.R")
source("pointfixe.R")
source("nr.R")
@

\begin{objectifs}
\item Résoudre une équation à une variable à l'aide des méthodes de la
  bissection, du point fixe et de Newton-Raphson.
\item Faire un choix parmi l'une des méthodes ci-dessus pour résoudre
  un problème donné.
\item Déterminer si une fonction admet un point fixe dans un
  intervalle donné.
\item Utiliser les fonctions de résolution d'équations et
  d'optimisation de Excel et R.
\end{objectifs}

\begin{prob-enonce}
  Les fonctions décrivant les heures de lever et de coucher du soleil
  à Québec pour le mois de janvier 2016 sont représentées par $L(x)$
  et $C(x)$, respectivement:
  \begin{align*}
    L(x) &= e^{-0.001431 x + 2,016340} \\
    C(x) &= e^{0,001312 x + 2,778538},
  \end{align*}
  où $x$ est le jour du mois (un entier). La fonction du nombre
  d'heures d'ensoleillement pour une journée est donc
  $H(x) = C(x) - L(x)$.

  Pendant quel jour du mois les Québécois bénéficient-ils de
  9~heures d'ensoleillement, à une minute près?
\end{prob-enonce}


\section{Mise en contexte}
\label{sec:resolution:contexte}

Ce chapitre passe en revue les méthodes les plus populaires pour
résoudre numériquement une équation à une variable. Ce problème,
simple seulement en apparence, survient dans une foule de domaines.
Débutons par deux exemples, tirés des mathématiques financières et de
l'inférence statistique.

\begin{exemple}
  Un investisseur est disposé à payer $k$~\$ aujourd'hui en retour
  d'une série de $n$ versements de $1$~\$, le premier dans un an. Pour
  déterminer le taux de rendement qu'il exige, on doit trouver la
  valeur de $i$ tel que $a_{\angl{n}\, i} = k$ ou, énoncé autrement,
  la valeur de $i$ tel que
  \begin{equation*}
    f(i) = \frac{1 - (1 + i)^{-n}}{i} -k = 0.
  \end{equation*}
  \qed
\end{exemple}

\begin{exemple}
  On a un échantillon aléatoire $X_1, \dots, X_n$ provenant d'une
  distribution binomiale négative avec fonction de masse de
  probabilité
  \begin{displaymath}
    \Pr[X = x] = \binom{x + r - 1}{r - 1} p^r (1 - p)^x, \quad x = 0,
    1, \dots,
  \end{displaymath}
  où $p$ est supposé connu. On souhaite trouver l'estimateur du
  maximum de vraisemblance du paramètre $r$.

  La fonction de vraisemblance est
  \begin{align*}
    L(r)
    &= \prod_{i = 1}^n \Pr[X = x_i] \\
    &= \prod_{i = 1}^n \binom{x_i + r - 1}{r - 1} p^r (1 - p)^{x_i}
  \end{align*}
  et la fonction de log-vraisemblance est
  \begin{align*}
    l(r)
    &= \sum_{i = 1}^n
    [\ln \Gamma(x_i + r) - \ln \Gamma(r) - \ln \Gamma(x_i + 1) \\
    &\quad\; + r \ln p + x_i \ln (1 - p)].
  \end{align*}
  Par conséquent, l'estimateur du maximum de vraisemblance $\hat{r}$
  est la solution de
  \begin{displaymath}
    f(r) = \frac{d}{dr}\, l(r) =
    \sum_{i = 1}^n (\Psi(x_i + r) - \Psi(r) + \ln p) = 0,
  \end{displaymath}
  où $\Psi(x) = \Gamma^\prime(x)/\Gamma(x)$ est la \emph{fonction
    digamma}. %
  \qed
\end{exemple}

Le problème sur lequel nous allons nous pencher consiste donc à
trouver la racine d'une fonction $f(x)$, c'est-à-dire la solution de
$f(x) = 0$.

\begin{prob-astuce}
  Nous cherchons à déterminer pour quelle valeur de
  $x \in \{1, 2, \dots, 31\}$ la fonction $H(x)$ vaut $9$ ou, de
  manière équivalente, la racine de l'équation $H(x) - 9 = 0$.

  Une technique d'essai-erreur intuitive suivrait probablement
  à peu près les étapes suivantes:
  \begin{enumerate}
  \item vérifier qu'il existe bel une racine dans l'intervalle
    $[1, 31]$ en évaluant le nombre d'heures d'ensoleillement aux
    bornes de l'intervalle, puis déterminer si la fonction est
    croissante ou décroissante sur l'intervalle (elle est croissante
    dans le cas présent);
  \item essayer une première valeur pour $x$ et calculer la valeur de
    $H(x)$;
  \item si le nombre d'heures d'ensoleillement est trop élevé,
    diminuer la valeur de $x$ et si, à l'inverse, le nombre d'heures
    d'ensoleillement est trop faible, augmenter la valeur de $x$;
  \item répéter les deux étapes précédentes jusqu'à trouver la bonne
    valeur de $x$ au un degré de précision désiré.
  \end{enumerate}

  Voici une mise en {\oe}uvre simple en R. Définissons d'abord une
  fonction pour calculer le nombre d'heures d'ensoleillement $H(x)$.
<<echo=TRUE>>=
H <- function(x)
{
    exp(0.001312 * x + 2.778538) -
        exp(-0.001431 * x + 2.016340)
}
@
  Calculons les valeurs au début et à la fin de l'intervalle
<<echo=TRUE>>=
H(1)
H(31)
@
  Selon les valeurs à $x = 1$ et $x = 31$, le jour où l'ensoleillement
  total vaut $9$ semble se situer environ à la mi-mois. Essayons donc
  $x = 15$.
<<echo=TRUE>>=
H(15)
@
  La valeur est supérieure à $9$. Le jour recherché se trouve donc
  entre $1$ et $15$. Essayons $x = 10$.
<<echo=TRUE>>=
H(10)
@
  La valeur est inférieure à $9$. Le jour recherché se trouve donc
  entre $10$ et $15$. Essayons $x = 13$.
<<echo=TRUE>>=
H(13)
@
  Nous avons trouvé la bonne valeur à une minute près.
\end{prob-astuce}


\section{Méthode de bissection}
\label{sec:resolution:bissection}

Toutes les méthodes numériques de résolution d'une équation qui seront
étudiées dans ce chapitre reposent sur une procédure systématique
d'essais et d'erreurs. La procédure --- ou algorithme --- utilisée
déterminera l'efficacité de la méthode. À ce chapitre, la méthode de
bissection est la plus simple et la plus intuitive méthode de
résolution, mais aussi la moins efficace.

Soit $f$ une fonction continue sur un intervalle $[a, b]$ choisi de
telle sorte que $f(a)$ et $f(b)$ sont de signes opposés. Par le
théorème de la valeur intermédiaire, il existe un point $x^*$ tel que
$f(x^*) = 0$. En d'autres mots, si une fonction continue est d'un côté
de l'axe des abscisses au début d'un intervalle et de l'autre coté à
l'autre extrémité de l'intervalle, alors elle a forcément croisé l'axe
quelque part dans l'intervalle.

L'idée de la méthode de bissection consiste à trouver la solution
$x^*$ par essais successifs en utilisant le point milieu d'intervalles
de plus en plus petits, mais que l'on sait toujours contenir le point
cherché. L'\autoref{algo:resolution:bissection} systématise
cette idée et la \autoref{fig:resolution:bissection} l'illustre
pour quelques itérations de l'algorithme.

\begin{algorithme}[Méthode de la bissection]
  \label{algo:resolution:bissection}
  Soit $f$ une fonction continue sur l'intervalle $[a, b]$ où $f(a)$
  et $f(b)$ sont de signes opposés. On cherche $x^*$ tel que $f(x^*) =
  0$ en un maximum de $N_{\mathrm{max}}$ itérations.
  \begin{enumerate}
  \item Poser $n = 1$.
  \item Répéter les étapes suivantes.
    \begin{enumerate}
      \pointedenum
    \item Poser $x_n = (a + b)/2$.
    \item \label{algo:resolution:bissection:signe} Si $f(a) f(x_n) >
      0$, poser $a = x_n$, sinon poser $b = x_n$.
    \item \label{algo:resolution:bissection:test} Si $|x_n - x_{n -
        1}|/|x_n| < \varepsilon$, poser $x^* = x_n$ et terminer.
    \item Si $n \geq N_{\mathrm{max}}$, terminer sans convergence.
    \item Poser $n = n + 1$.
    \end{enumerate}
  \end{enumerate}
\end{algorithme}

\begin{figure}[t]
  \centering
<<echo=FALSE, fig=TRUE>>=
par(mfrow = c(2, 2))
f <- function(x) x^3 + x

x <- c(-0.5, 0.75, 0.125)
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2,
      main = "Première itération")
abline(h = 0)
segments(x, -2.08, x, f(x), lty = c(1, 1, 2), col = "darkgray")
points(x, f(x), pch = c(19, 19, 21), bg = "red3")

x <- c(-0.5, 0.125, -0.1875)
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2,
      main = "Seconde itération")
abline(h = 0)
segments(x, -2.08, x, f(x), lty = c(1, 1, 2), col = "darkgray")
points(x, f(x), pch = c(19, 19, 21), bg = "red3")

x <- c(-0.1875, 0.125, -0.03125)
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2,
      main = "Troisième itération")
abline(h = 0)
segments(x, -2.08, x, f(x), lty = c(1, 1, 2), col = "darkgray")
points(x, f(x), pch = c(19, 19, 21), bg = "red3")

x <- c(-0.03125, 0.125, 0.046875)
curve(f(x), xlim = c(-1, 1), ylab = "f(x)", lwd = 2,
      main = "Quatrième itération")
abline(h = 0)
segments(x, -2.08, x, f(x), lty = c(1, 1, 2), col = "darkgray")
points(x, f(x), pch = c(19, 19, 21), bg = "red3")
@
  \caption{Illustration de la méthode de bissection. À chaque
    itération, les points noirs reliés par des segments verticaux en
    ligne pleine identifient les bornes de l'intervalle dans lequel on
    sait que se trouve la solution de l'équation $f(x) = 0$. Le point
    rouge relié par un segment en pointillé est l'essai de
    l'itération, c'est-à-dire le point milieu de l'intervalle. On
    remarquera comment ce point devient la borne inférieure ou
    supérieure de l'intervalle à l'itération suivante.}
  \label{fig:resolution:bissection}
\end{figure}

L'application de l'\autoref{algo:resolution:bissection} génère
une suite $\{x_n\}$, $n = 1, 2, \dots$ qui, si tout se passe bien,
converge vers la valeur $x^*$.

\begin{rems}
  \begin{enumerate}
  \item À l'étape~\ref*{algo:resolution:bissection:signe} de
    l'algorithme, le produit $f(a)
    f(x_n)$ permet de déterminer si l'on se trouve du même côté de
    l'axe des abscisses aux points $a$ et $x_n$ (produit de deux
    valeurs négatives ou de deux valeurs positives) ou de part et d'autre
    de l'axe (produit de valeurs de signes opposés).
  \item L'étape~\ref*{algo:resolution:bissection:test} permet de
    valider si l'algorithme a convergé vers une réponse. La valeur de
    $\varepsilon$ sera donc en général «petite».
  \item Nous avons utilisé l'erreur relative comme critère d'arrêt à
    l'étape~\ref*{algo:resolution:bissection:test}. Il s'agit en
    général du meilleur choix. En effet, un critère tel que $|f(x_n)|
    < \varepsilon$ peut être satisfait même si $x_n \gg x^*$ ou $x_n
    \ll x^*$ (voir la \autoref{fig:resolution:critere} pour deux
    exemples). Quant à l'erreur absolue $|x_n - x_{n - 1}| <
    \varepsilon$, l'inégalité peut être satisfaite même si la suite
    $\{x_n\}$ diverge.
  \end{enumerate}
\end{rems}

\begin{figure}
  \centering
<<echo=FALSE, fig=TRUE, height=4, width=8>>=
par(mfrow = c(1, 2))
f <- function(x) x^3 - x^2 - x - 10
curve(f(x), xlim = c(-10, 10), xlab = "x", ylab = "f(x)", lwd = 2)
points(Re(polyroot(c(-10, -1, -1, 1))[3]), 0, pch = 19)
abline(h = 0)

f <- function(x) x^3 - x^2 - x - 0.2
curve(f(x), xlim = c(-1, 2), xlab = "x", ylab = "f(x)", lwd = 2)
points(Re(polyroot(c(-0.2, -1, -1, 1))[3]), 0, pch = 19)
abline(h = 0)
@
  \caption{Deux exemples de fonctions pour lesquelles on pourrait
    avoir $|f(x_n)| < \varepsilon$ même si $x_n \gg x^*$ ou $x_n \ll
    x^*$. Le point identifie la véritable racine dans chaque
    graphique.}
  \label{fig:resolution:critere}
\end{figure}

\begin{exemple}
  \label{ex:resolution:bissection_1}
  On cherche la racine de $f(x) = x^3 + 4 x^2 - 10$ dans l'intervalle
  $[1, 2]$. On peut vérifier que la fonction $f$ n'a qu'une seule
  racine dans cet l'intervalle et que, de plus, $f(1) = -5$ et $f(2) =
  14$. Ainsi, $a = 1$ et $b = 2$ constituent des valeurs de départ
  adéquates.

  Le code R de la \autoref{sec:resolution:code} définit une
  fonction \code{bissection} dont les arguments sont:
  \begin{enumerate}
  \item la fonction $f(x)$;
  \item la valeur de $a$;
  \item la valeur de $b$;
  \item la valeur de $\varepsilon$ ($10^{-6}$ par défaut);
  \item le nombre maximal d'itérations $N_{\mathrm{max}}$ ($100$ par
    défaut);
  \item une valeur booléenne indiquant si les calculs intermédiaires
    doivent ou non être affichés à l'écran: si l'argument est
    \code{TRUE}, les valeurs de $a$, $b$, $x_n$ et $f(x_n)$ sont
    affichées à chaque itération.
  \end{enumerate}
  La fonction retourne une liste dont l'élément \code{\$root} contient
  la réponse et l'élément \code{\$nb.iter} le nombre d'itérations
  nécessaire pour obtenir cette réponse.

  \gotorbox{Exécuter le code informatique de la
    \autoref{sec:resolution:code} pour définir la fonction
    \code{bissection} puis résoudre cet exemple.}

<<echo=FALSE>>=
f <- function(x) x^3 + 4*x^2 - 10
res <- bissection(f, 1, 2, TOL=1E-5)
@

  Après \Sexpr{res$nb.iter} %$
  itérations de la fonction \code{bissection}, la réponse obtenue est,
  à neuf décimales, %
  $\nombre{\Sexpr{format(res$root, digits = 10, decimal.mark = ",")}}$. %$
  L'erreur d'approximation est au maximum de
  \begin{displaymath}
    |x^* - x_{17}| < |b_{18} - a_{18}| =
    |1,365234 - 1,365227| = 0,000007
  \end{displaymath}
  et, puisque $|a_{18}| < |x^*|$,
  \begin{displaymath}
    \frac{|x^* - x_{17}|}{|x^*|} < \frac{|b_{18} - a_{18}|}{|a_{18}|} =
    5,13 \times 10^{-6}.
  \end{displaymath}
  La réponse est donc exacte à au moins cinq décimales près. %
  \qed
\end{exemple}

\begin{exemple}
  \label{ex:resolution:bissection_2}
  La valeur présente d'une série de dix paiements de fin d'année est
  $8,2218$. Pour déterminer le taux d'intérêt (ou taux de rendement,
  selon le point de vue), on cherche $i$ tel que $f(i) =
  a_{\angl{10}\, i} - 8,2218 = 0$.

  \gotorbox{Exécuter le code informatique de la
    \autoref{sec:resolution:code} correspondant à cet exemple pour
    la solution.}%
  \qed
\end{exemple}


\begin{prob-astuce}
  La méthode de bissection est en fait une systématisation de la
  technique d'essai-erreur intuitive présentée précédemment.

  On utilise l'\autoref{algo:resolution:bissection} avec
  $f(x) = H(x) - 9$, $a = 1$ et $b = 31$.
\end{prob-astuce}


\section{Méthode du point fixe}
\label{sec:resolution:pointfixe}

La solution de l'équation
\begin{equation*}
  g(x) = x
\end{equation*}
est un \emph{point fixe} de la fonction $g$. Il s'agit du point où les
fonctions $g(x)$ et $y = x$ sont égales, c'est-à-dire là où la fonction
$g$ croise la droite à 45{\textdegree} dans le plan.

Tout problème de recherche de racine peut être exprimé comme un
problème de point fixe. Par exemple, en définissant
\begin{equation*}
  g(x) = x - f(x),
\end{equation*}
les problèmes de trouver $x$ tel que $g(x) = x$ ou tel que $f(x) = 0$ sont
équivalents.

La méthode du point fixe repose sur le théorème du même nom. Celui-ci
fournit les conditions garantissant, d'une part, l'existence d'un
point fixe pour une fonction $g$ dans un intervalle donné et, d'autre
part, l'unicité de ce point fixe. Un point fixe unique peut néanmoins
exister sans que ces conditions ne soient remplies.

\begin{thm}[Théorème du point fixe]
  \label{thm:resolution:pointfixe}
  Soit $g$ une fonction continue sur un intervalle $[a, b]$.
  \begin{enumerate}
  \item Si $g(x) \in [a, b]$ pour tout $x \in [a, b]$, alors $g$ a un
    point fixe dans $[a, b]$.
  \item Si, de plus, $g^\prime(x)$ existe sur $(a, b)$ et qu'il existe
    une constante $k$ tel que
    \begin{displaymath}
      |g^\prime(x)| \leq k < 1
    \end{displaymath}
    pour tout $x \in (a, b)$, alors $g$ a un point fixe \emph{unique}
    dans $[a, b]$.
  \end{enumerate}
\end{thm}

\begin{proof}
  Le théorème compte deux volets. Nous en faisons une démonstration
  simplifiée ne reposant que sur des arguments graphiques.

  \begin{enumerate}
  \item Le premier volet garantit l'existence d'un point fixe sur $[a,
    b]$ si l'image de la fonction $g$ se trouve aussi dans un
    intervalle $[a, b]$. Cette paire d'intervalles engendre le carré
    en pointillé que l'on retrouve dans les graphiques de la
    \autoref{fig:resolution:demo}.

    En définitive, le premier volet du théorème établit que si la
    fonction continue $g$ entre dans l'intervalle $[a, b]$ par la
    gauche du carré ($g(x) \in [a, b]$) et en ressort par la droite
    (idem), alors elle doit forcément croiser la droite $y = x$.
    Observons le graphique (a) de la \autoref{fig:resolution:demo}:
    \begin{itemize}
    \item $g(x) \in [a, b]$ pour tout $x \in [a, b]$, donc un point
      fixe existe nécessairement;
    \item $h(x) \notin [a, b]$ pour tout $x \in [a, b]$, donc la
      fonction n'a pas nécessairement de point fixe dans $[a, b]$;
    \item $k(x) \notin [a, b]$ pour tout $x \in [a, b]$, mais un point
      fixe demeure néanmoins possible.
    \end{itemize}
  \item Le second volet garantit l'unicité du point fixe si la pente
    de la fonction sur $(a, b)$ n'excède jamais $1$. Cette condition
    empêche la fonction de croiser la droite $y = x$ une première fois
    et de la croiser de nouveau suite à une forte augmentation.
    Comparons les deux fonctions du graphique (b) de la
    \autoref{fig:resolution:demo}:
    \begin{itemize}
    \item $g^\prime(x) < 1$ pour tout $x \in (a, b)$, donc $g(x)$
      croise $y = x$ en un seul point et le point fixe est unique;
    \item $h(x) \in [a, b]$ pour tout $x \in [a, b]$, mais
      $h^\prime(x) > 1$ pour $x \in (a, b)$, ce qui ouvre la porte à
      des points fixes multiples, tel qu'illustré.
    \end{itemize}
  \end{enumerate}

  \begin{figure}
    \setkeys{Gin}{width=\textwidth}
    \begin{minipage}{0.45\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
par(mar = c(2, 2, 1, 1))
f <- function(x) x
g <- function(x) x - (x^3 + 4 * x^2 - 10)/(3 * x^2 + 8 * x)
k <- function(x) g(x - 0.5) + 0.3
h <- function(x) -2 * x^2 + 7 * x - 4.75
curve(g, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, axes = FALSE, xlab = "", ylab = "")
curve(h, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, col = "red3", add = TRUE)
curve(k, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, col = "orange1", add = TRUE)
curve(f, add = TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1), lty = 2, border = "blue")
axis(1, at = c(1, 2), labels = c("a", "b"))
axis(2, at = c(1, 2), labels = c("a", "b"))
text(rep(2.2, 3), c(g(2.2), h(2.2), k(2.2)) + c(0.05, 0.09, 0.05),
     c("g", "h", "k"))
box()
@
      \subcaption{existence du point fixe}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
par(mar = c(2, 2, 1, 1))
f <- function(x) x
g <- function(x) x - (x^3 + 4 * x^2 - 10)/(3 * x^2 + 8 * x)

## Les points ci-dessous ont été obtenus avec la fonction drawPlot()
## du package Hmisc:
##
## drawPlot(Abline(0, 1), Abline(h = 1), Abline(h = 2),
##          Abline(v = 1), Abline(v = 2),
##          Curve('smooth', ask = TRUE),
##          xlim = c(0.75, 2.25), ylim = c(0.75, 2.25))
x <- c(
0.7840067, 0.8267755, 0.8668402, 0.9044605, 0.9402250, 0.9748105, 1.0088406,
1.0428095, 1.0770484, 1.1117217, 1.1468403, 1.1822866, 1.2178442, 1.2532294,
1.2881214, 1.3221886, 1.3551113, 1.3865996, 1.4164060, 1.4443339, 1.4702415,
1.4940425, 1.5157034, 1.5352392, 1.5527068, 1.5681983, 1.5818330, 1.5937504,
1.6041027, 1.6130488, 1.6207487, 1.6273589, 1.6330289, 1.6378987, 1.6420969,
1.6457396, 1.6489303, 1.6517600, 1.6543073, 1.6566399, 1.6588148, 1.6608796,
1.6628736, 1.6648288, 1.6667705, 1.6687184, 1.6706870, 1.6726867, 1.6747240,
1.6768025, 1.6789227, 1.6810837, 1.6832826, 1.6855164, 1.6877815, 1.6900755,
1.6923975, 1.6947488, 1.6971339, 1.6995611, 1.7020431, 1.7045971, 1.7072455,
1.7100156, 1.7129394, 1.7160532, 1.7193971, 1.7230142, 1.7269499, 1.7312507,
1.7359636, 1.7411355, 1.7468125, 1.7530396, 1.7598611, 1.7673205, 1.7754617,
1.7843296, 1.7939715, 1.8044381, 1.8157853, 1.8280743, 1.8413726, 1.8557528,
1.8712913, 1.8880650, 1.9061467, 1.9255983, 1.9464634, 1.9687572, 1.9924568,
2.0174906, 2.0437286, 2.0709745, 2.0989604, 2.1273455, 2.1557203, 2.1836199,
2.2105525, 2.2360593)
y <- c(
1.184281, 1.174952, 1.167810, 1.162311, 1.158103, 1.154966, 1.152779, 1.151487,
1.151073, 1.151545, 1.152918, 1.155205, 1.158409, 1.162524, 1.167523, 1.173368,
1.180005, 1.187368, 1.195383, 1.203970, 1.213046, 1.222532, 1.232351, 1.242432,
1.252714, 1.263146, 1.273686, 1.284303, 1.294978, 1.305699, 1.316463, 1.327275,
1.338145, 1.349088, 1.360123, 1.371268, 1.382545, 1.393974, 1.405574, 1.417363,
1.429356, 1.441564, 1.453996, 1.466657, 1.479547, 1.492662, 1.505995, 1.519534,
1.533262, 1.547157, 1.561196, 1.575350, 1.589585, 1.603868, 1.618160, 1.632420,
1.646607, 1.660678, 1.674589, 1.688297, 1.701760, 1.714935, 1.727783, 1.740267,
1.752351, 1.764005, 1.775200, 1.785911, 1.796119, 1.805806, 1.814961, 1.823575,
1.831645, 1.839169, 1.846153, 1.852601, 1.858524, 1.863933, 1.868844, 1.873273,
1.877238, 1.880758, 1.883856, 1.886556, 1.888882, 1.890862, 1.892529, 1.893916,
1.895063, 1.896012, 1.896807, 1.897496, 1.898117, 1.898702, 1.899259, 1.899759,
1.900124, 1.900207, 1.899779, 1.898530)

curve(g, xlim = c(0.75, 2.25), ylim = c(0.75, 2.25),
      lwd = 2, axes = FALSE, xlab = "", ylab = "")
lines(x, y, lwd = 2, col = "red3")
curve(f, add = TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1), lty = 2, border = "blue")
axis(1, at = c(1, 2), labels = c("a", "b"))
axis(2, at = c(1, 2), labels = c("a", "b"))
text(rep(2.2, 2), c(g(2.2), y[96]) + 0.05, c("g", "h"))
box()
@
      \subcaption{unicité du point fixe}
    \end{minipage}
    \caption{Exemples de graphiques permettant de faire la
      démonstration du théorème du point fixe}
    \label{fig:resolution:demo}
    \setkeys{Gin}{width=0.8\textwidth}
  \end{figure}
\end{proof}

Le théorème suivant, donné sans preuve, établit véritablement la
procédure qui sera utilisée par la méthode numérique pour trouver le
point fixe d'une fonction.

\begin{thm}
  \label{thm:resolution:pointfixe:2}
  Si les deux conditions du \autoref{thm:resolution:pointfixe}
  sont satisfaites, alors la série $\{x_n = g(x_{n - 1})\}$ converge
  vers un point fixe unique dans $[a, b]$.
\end{thm}

Tel que mentionné au début de la
\autoref{sec:resolution:bissection}, toutes les méthodes
numériques --- et la méthode du point fixe ne fait pas exception ---
procèdent par essais et erreurs, mais de manière systématique. Le
\autoref{thm:resolution:pointfixe:2} nous dit que pour trouver un
point fixe, le meilleur essai $x_n$ à faire est la valeur de la
fonction $g$ à l'essai précédent, $g(x_{n - 1})$. La
\autoref{fig:resolution:pointfixe} illustre comment la suite des
essais successifs peut converger vers le point fixe.

\begin{figure}
  \centering
  \setkeys{Gin}{width=\textwidth}
<<echo=FALSE, fig=TRUE, height=4, width=8>>=
par(mfrow = c(1, 2))
f <- function(x) x

## Fonction décroissante
g <- function(x) -0.035 * x^2 +  10

lim <- c(7, 8.5)
curve(g, xlim = lim, ylim = lim, lwd = 2)
curve(f, add = TRUE)

x <- numeric(6)
x[1] <- 7.1
for (i in 2:length(x)) x[i] <- g(x[i - 1])

segments(x[1], 6.95, x[1], x[2], lty = 2, col = "darkgray")
segments(x[-1], x[-1], x[-1], g(x[-1]), lty = 2, col = "darkgray")
arrows(head(x, -1), x[-1], x[-1], x[-1],
       col = "blue", length = 0.07)
points(x, g(x), pch = 21, bg = "red3")

## Fonction croissante
g <- function(x) -0.035 * (x - 15)^2 +  10
lim <- c(7.5, 8.8)
curve(g, xlim = lim, ylim = lim, lwd = 2)
curve(f, add = TRUE)
x <- numeric(5)
x[1] <- 7.7
for (i in 2:length(x)) x[i] <- g(x[i - 1])

segments(x[1], 6.95, x[1], x[2], lty = 2, col = "darkgray")
segments(x[-1], x[-1], x[-1], g(x[-1]), lty = 2, col = "darkgray")
arrows(head(x, -1), x[-1], x[-1], x[-1],
       col = "blue", length = 0.07)
points(x, g(x), pch = 21, bg = "red3")
@
  \caption{Illustrations de la méthode du point fixe pour une fonction
    décroissante et pour une fonction croissante. Les points rouges
    identifient les essais successifs, le premier étant, ici, le point
    le plus à gauche dans les graphiques. Les flèches illustrent
    comment est déterminé l'essai suivant. La relation $x_n = g(x_{n -
      1})$ implique que l'abscisse d'un essai correspond à la
    projection de l'ordonnée de l'essai précédent sur la droite $y =
    x$.}
  \label{fig:resolution:pointfixe}
  \setkeys{Gin}{width=0.8\textwidth}
\end{figure}

Nous pouvons dès lors composer un algorithme de résolution par la
méthode du point fixe.

\begin{algorithme}[Méthode du point fixe]
  \label{algo:resolution:pointfixe}
  Soit $g$ une fonction et $x_0$ une valeur de départ. On cherche
  $x^*$ tel que $g(x^*) = x^*$ en un maximum de $N_{\mathrm{max}}$
  itérations.
  \begin{enumerate}
  \item Poser $n = 1$.
  \item Répéter les étapes suivantes.
    \begin{enumerate}
    \item Poser $x_n = g(x_{n - 1})$.
    \item Si $|x_n - x_{n - 1}|/|x_n| < \varepsilon$, alors poser $x^*
      = x_n$ et terminer.
    \item Si $n \geq N_{\mathrm{max}}$, terminer sans convergence.
    \item Poser $n = n + 1$.
    \end{enumerate}
  \end{enumerate}
\end{algorithme}

\begin{rem}
  Comme on peut le déduire des illustrations de la
  \autoref{fig:resolution:pointfixe}, la rapidité de la convergence
  est fonction de $g^\prime(x)$: plus la pente est \emph{faible}, plus
  la convergence est \emph{rapide}, et vice versa.
\end{rem}

\begin{exemple}
  \label{ex:resolution:pointfixe_1}
  On répète l'\autoref{ex:resolution:bissection_2} à l'aide de la
  méthode du point fixe, soit trouver le taux d'intérêt $i$ tel que
  $a_{\angl{10}\,i} = 8,2218$. On a déjà déterminé à
  l'\autoref{ex:resolution:bissection_2} que le taux d'intérêt se
  trouve dans l'intervalle $[0,035, 0,040]$. On peut exprimer le
  problème sous forme de point fixe ainsi: trouver la valeur de $i$
  tel que
  \begin{displaymath}
    g(i) = \frac{1 - (1 + i)^{-10}}{8,2218} = i.
  \end{displaymath}

  Le code R de la \autoref{sec:resolution:code} définit une
  fonction \code{pointfixe} similaire à la fonction \code{bissection}
  présentée à la \autoref{sec:resolution:bissection}. Ses
  arguments sont d'ailleurs les mêmes, à l'exception que les points
  $a$ et $b$ sont remplacés par une valeur de départ $x_0$.

  \gotorbox{Exécuter le code informatique de la
    \autoref{sec:resolution:code} correspondant à ce bloc de matière
    pour définir la fonction \code{pointfixe} puis résoudre cet
    exemple.}

<<echo=FALSE>>=
g <- function(i) (1 - (1 + i)^(-10))/8.2218
res.pf <- pointfixe(g, start = 0.0375)
@
  Il faut \Sexpr{res.pf$nb.iter} %$
  itérations pour obtenir la convergence avec un critère identique à
  celui utilisé avec la bissection. Pour ce type de problème, la
  méthode du point fixe n'est pas la plus efficace.
  \qed
\end{exemple}

\begin{exemple}
  \label{ex:resolution:pointfixe_2}
  On répète l'\autoref{ex:resolution:bissection_1} à l'aide de la
  méthode du point fixe, à savoir: trouver la racine de $f(x) = x^3 +
  4 x^2 - 10 = 0$ dans l'intervalle $[1, 2]$.

  Il y a plusieurs façons d'exprimer le problème de recherche de
  racine en termes de point fixe. On examine cinq différentes
  fonctions toutes algébriquement équivalentes:
  \begin{align*}
    g_1(x) &= x - x^3 - 4 x^2 + 10  \\
    g_2(x) &= \left( \frac{10}{x} - 4x \right)^{1/2} \\
    g_3(x) &= \frac{1}{2} (10 - x^3)^{1/2} \\
    g_4(x) &= \left( \frac{10}{4 + x} \right)^{1/2} \\
    g_5(x) &= x - \frac{x^3 + 4 x^2 - 10}{3x^2 + 8x}.
  \end{align*}
  Il est laissé en exercice de vérifier que, dans chacun des cas, la
  racine de $f(x)$ est le point fixe de $g_i(x)$, $i = 1, \dots, 5$.

  Les graphiques des cinq fonctions ci-dessus se trouvent à la
  \autoref{fig:resolution:pointfixe_2}. L'examen de ces graphiques
  permet de déterminer, avant de faire tout calcul, pour quelles
  fonctions la procédure itérative du point fixe convergera ainsi que
  les taux de convergence relatif, le cas échéant.
  \begin{figure}
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
f <- function(x) x
lim <- c(0.95, 2.05)
g1 <- function(x) x - x^3 - 4 * x^2 + 10
curve(g1, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[1](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_1(x)$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
g2 <- function(x) sqrt(10/x - 4*x)
curve(g2, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[2](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_2(x)$}
    \end{minipage}
    \newline
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
g3 <- function(x) sqrt(10 - x^3)/2
curve(g3, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[3](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_3(x)$}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
g4 <- function(x) sqrt(10/(4 + x))
curve(g4, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[4](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_4(x)$}
    \end{minipage}
    \newline
    \centering
    \begin{minipage}{0.48\linewidth}
      \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
g5 <- function(x) x - (x^3 + 4*x^2 - 10)/(3*x^2 + 8*x)
curve(g5, xlim = lim, ylim = lim, lwd = 2, ylab = expression(g[5](x)))
curve(f, add=TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
      \subcaption{fonction $g_5(x)$}
    \end{minipage}
    \caption{Graphiques des cinq fonctions de
      l'\autoref{ex:resolution:pointfixe_2}}
    \label{fig:resolution:pointfixe_2}
  \end{figure}

  \gotorbox{Compléter cet exemple en exécutant le code informatique
    correspondant à la \autoref{sec:resolution:code}.}%
  \qed
\end{exemple}

\begin{prob-astuce}
  Pour utiliser l'algorithme du point fixe
  \ref{algo:resolution:pointfixe}, il faut exprimer notre problème de
  recherche du jour du mois où l'ensoleillement est de $9$ heures sous
  la forme $g(x) = x$.

  Nous pourrions simplement réécrire l'équation de départ $H(x) = 9$
  sous la forme $H(x) - 9 + x = x$. Seulement, la pente de cette
  fonction est très près de $1$ et la méthode du point fixe serait
  donc très lente.

  Isolons donc plutôt une valeur de $x$ dans l'équation de départ
  \begin{equation*}
    e^{0,001312 x + 2,778538} - e^{-0,001431 x + 2,016340} = 9.
  \end{equation*}
  En isolant le $x$ dans la première exponentielle, cette équation se
  réécrit
  \begin{equation*}
    x = \frac{\ln (9 + e^{-0,001431 x + 2,016340}) - 2,778538}{0,001312}.
  \end{equation*}
  Nous pourrions donc utiliser l'algorithme du point fixe avec la
  fonction
  \begin{equation*}
    \label{eq:resolution:pf-app}
    g(x) = \frac{\ln (9 + e^{-0,001431 x + 2,016340}) - 2,778538}{0,001312}.
  \end{equation*}
  On peut vérifier graphiquement que la pente de cette fonction est
  beaucoup plus faible que celle de $H(x) - 9 + x$.
\end{prob-astuce}


\section{Méthode de Newton--Raphson}
\label{sec:resolution:newtonraphson}

La méthode de Newton--Raphson est l'une des plus populaires et
puissantes méthodes numériques de résolution d'équations à une
variable. Les algorithmes plus élaborés qui existent aujourd'hui sont
d'ailleurs souvent basés sur cet algorithme.

L'étude de la méthode de Newton--Raphson nous ramène au problème de
recherche de la racine $x^*$ d'une fonction $f(x)$, c'est-à-dire la
solution de $f(x) = 0$. Il y a plusieurs manières d'introduire cette
méthode de résolution. Nous privilégierons une approche graphique.

Dans la méthode de Newton--Raphson, les essais successifs sont
déterminés en utilisant les points où la tangente de la fonction $f$ à
l'essai précédent croise l'axe des abscisses; voir la
\autoref{fig:resolution:newtonraphson} pour une illustration.

\begin{figure}[t]
  \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) (x - 0.2)^3 + x - 0.2
fp <- function(x) 3 * (x - 0.2)^2 + 1
tangente <- function(x, a) fp(a) * (x - a) + f(a)
curve(f(x), xlim = c(-0.8, 1.2), ylim = c(-0.5, 1.5), lwd = 2)
abline(h = 0)
x <- c(0.98, 0, 0)
for (i in 2:3)
    x[i] <- -(f(x[i - 1]) - x[i - 1] * fp(x[i - 1]))/fp(x[i - 1])

segments(x, c(-1.1, 0, 0), x, f(x), lty = 2, col = "darkgray")
arrows(1.2, tangente(1.2, x[1]), x[2], 0, col = "blue", length = 0.1)
arrows(0.95, tangente(0.95, x[2]), x[3], 0, col = "blue", length = 0.1)

points(x, f(x), pch = 21, bg = "red3")
@
  \caption{Illustration de la méthode de Newton--Raphson. Les points
    rouges identifient les essais successifs, le premier étant, ici,
    le point le plus à droite dans le graphique. Les flèches
    illustrent comment est déterminé l'essai suivant. On trace la
    tangente en un point; le prochain essai est la valeur en abscisse
    où cette tangente croise l'axe.}
  \label{fig:resolution:newtonraphson}
\end{figure}

Une première justification mathématique de la méthode va comme suit.
Soit $\tilde{x}$ un point «près» de la racine $x^*$ et tel que
$f(\tilde{x}) \neq 0$. Comme on peut le voir à la
\autoref{fig:resolution:newtonraphson}, la tangente de $f$ en
$\tilde{x}$ croise l'abscisse en un point $\hat{x}$ «près» de $x^*$.
Ainsi, le point $\hat{x}$ est tel que
\begin{displaymath}
  \frac{f(\tilde{x}) - 0}{\tilde{x} - \hat{x}} = f^\prime(\tilde{x}),
\end{displaymath}
d'où
\begin{align*}
  x^*
  &\simeq \hat{x} \\
  &= \tilde{x} - \frac{f(\tilde{x})}{f^\prime(\tilde{x})}.
\end{align*}

On peut également justifier la formule précédente à l'aide du
développement de Taylor de $f(x)$ autour de $\tilde{x}$:
\begin{equation*}
  f(x)
  = f(\tilde{x}) + (x - \tilde{x}) f^\prime(\tilde{x})
  + \frac{(x - \tilde{x})^2}{2} f^{\prime\prime}(\tilde{x}) + \dots
\end{equation*}
Toujours en supposant que $\tilde{x}$ est près de $x^*$, on a
\begin{equation*}
  f(x^*) = 0 = f(\tilde{x}) + (x^* - \tilde{x}) f^\prime(\tilde{x}) +
  \frac{(x^* - \tilde{x})^2}{2} f^{\prime\prime}(\tilde{x}) + \dots,
\end{equation*}
où l'on peut considérer les termes de puissance $2$ et plus dans le
développement comme négligeables. On obtient alors l'approximation
\begin{equation*}
  x^* \simeq \tilde{x} - \frac{f(\tilde{x})}{f^\prime(\tilde{x})}.
\end{equation*}

Tel qu'illustré à la \autoref{fig:resolution:newtonraphson}, on
peut répéter la procédure ci-dessus si le point $\hat{x}$ est trop
éloigné de la racine $x^*$. On utilise alors $\hat{x}$ comme nouveau
point où l'on calcule la tengente, et ainsi de suite jusqu'à
l'obtention d'une «bonne» approximation.

Formellement, soit $f$ une fonction différentiable sur $[a, b]$ et
$x^* \in [a, b]$. Alors $x^*$ peut être obtenu comme le point de
convergence de la série $\{x_n\}$ définie par
\begin{displaymath}
  x_n = x_{n - 1} - \frac{f(x_{n - 1})}{f^\prime(x_{n - 1})},
\end{displaymath}
avec $x_0$ une valeur de départ quelconque.
L'\autoref{algo:resolution:newtonraphson} systématise cette
procédure.

\begin{algorithme}[Méthode de Newton--Raphson]
  \label{algo:resolution:newtonraphson}
  Soit $f$ une fonction continue et différentiable sur l'intervalle
  $[a, b]$. On cherche $x^*$ tel que $f(x^*) = 0$ en un maximum de
  $N_{\mathrm{max}}$ itérations avec une valeur de départ $x_0$.
  \begin{enumerate}
  \item Poser $n = 1$.
  \item Répéter les étapes suivantes.
    \begin{enumerate}
    \item Poser $x_n = x_{n-1} - f(x_{n-1})/f^\prime(x_{n-1})$.
    \item Si $|x_n - x_{n - 1}|/|x_n| < \varepsilon$, alors poser $x^*
      = x_n$ et terminer.
    \item Si $n \geq N_{\mathrm{max}}$, terminer sans convergence.
    \item Poser $n = n + 1$.
    \end{enumerate}
  \end{enumerate}
\end{algorithme}

\begin{rems}
  \begin{enumerate}
  \item \label{algo:resolution:rem} L'examen attentif de la méthode de
    Newton--Raphson revèle qu'il s'agit en fait d'une procédure de
    point fixe avec
    \begin{displaymath}
      g(x) = x - \frac{f(x)}{f^\prime(x)}.
    \end{displaymath}
    La méthode de Newton--Raphson nous fournit donc la «bonne»
    fonction $g$ à utiliser dans la méthode du point fixe pour trouver
    la racine de la fonction $f$.
  \item On peut démontrer que si $f$ est doublement différentiable sur
    $[a, b]$ et que $x^* \in [a, b]$ est tel que $f(x^*) = 0$ et
    $f^\prime(x^*) \neq 0$, alors il existe un $\delta > 0$ tel que la
    série $\{x_n\}$ converge vers $x^*$ pour tout $x_0 \in [x^* -
    \delta, x^* + \delta]$. Autrement dit:
    \begin{itemize}
    \item les hypothèses du \autoref{thm:resolution:pointfixe}
      sont satisfaites;
    \item la méthode de Newton--Raphson fonctionne toujours avec un
      «bon» choix de valeur de départ $x_0$.
    \end{itemize}
  \end{enumerate}
\end{rems}

\begin{exemple}
  \label{ex:resolution:newtonraphson_1}
  On reprend l'\autoref{ex:resolution:pointfixe_1} de calcul d'un taux
  de rendement, cette fois à l'aide de la méthode de Newton--Raphson.
  Vous savez peut-être de votre cours de mathématiques financières que
  la méthode de Newton--Raphson est la plus efficace pour résoudre ce
  genre de problème. La \autoref{fig:resolution:newtonraphson_1}
  montre pourquoi elle est plus efficace que la méthode du point fixe:
  la fonction
  \begin{equation*}
    g(i) =  i - \frac{f(i)}{f^\prime(i)}
  \end{equation*}
  avec $f(i) = a_{\angl{n}\, i} - k$ est beaucoup plus plate que la
  fonction
  \begin{equation*}
    g(i) = \frac{1 - v^n}{k}
  \end{equation*}
  utilisée à l'\autoref{ex:resolution:pointfixe_1}.
  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) x
an <- function(i, n) (1 - (1 + i)^(-n))/i
anp <- function(i, n) (n * i * (1 + i)^(-n - 1) + (1 + i)^(-n) - 1)/i^2
g <- function(x) x - (an(x, 10) - 8.2218)/anp(x, 10)
lim <- c(0.0345, 0.0405)
curve(g, xlim = lim, ylim = lim,
      lwd = 2, xlab = "i", ylab = "g(i)")
curve(f, add = TRUE)
polygon(c(0.035, 0.035, 0.04, 0.04), c(0.035, 0.04, 0.04, 0.035),
        lty = "dashed", border = "blue")
@
    \caption{Fonction $g(i) = i - f(i)/f^\prime(i)$ où $f(i) = (1 - (1 +
      i)^{-10})/i - 8,2218$ pour $0,035 \leq i \leq 0,040$ (ligne épaisse)
      et la droite $y = i$ (ligne mince)}
    \label{fig:resolution:newtonraphson_1}
  \end{figure}

  On a défini en R une fonction \code{nr} similaire à la fonction
  \code{pointfixe} mentionnée à la \autoref{sec:resolution:pointfixe},
  sauf qu'on y a ajouté un argument pour la dérivée de la fonction
  $f(x)$.

  \gotorbox{Exécuter le code informatique de la \autoref{sec:resolution:code}
    correspondant à ce bloc de matière pour définir la fonction
    \code{nr} puis résoudre cet exemple. Prendre note comment l'on
    peut également utiliser la fonction \code{pointfixe} pour obtenir
    le taux de rendement.}%

<<echo=FALSE>>=
f <- function(i) (1 - (1 + i)^(-10))/i - 8.2218
fp <- function(i) (10 * i * (1 + i)^(-11) + (1 + i)^(-10) - 1)/i^2
res.nr <- nr(f, fp, 0.0375)
@
  La méthode de Newton--Raphson ne requiert donc que
  \Sexpr{res.nr$nb.iter} %$
  itérations pour obtenir un résultat équivalent à celui obtenu par la
  méthode du point fixe avec la fonction $g$ de
  l'\autoref{ex:resolution:pointfixe_1} en
  \Sexpr{res.pf$nb.iter} %$
  itérations. %
  \qed
\end{exemple}

\begin{exemple}
  \label{ex:resolution:newtonraphson_2}
  Revisitons l'\autoref{ex:resolution:bissection_1} où l'on
  cherche la racine de la fonction $f(x) = x^3 + 4 x^2 - 10$ dans
  l'intervalle $[1, 2]$. On a $f^\prime(x) = 3x^2 + 8 x$, d'où
  $f^\prime(x) \neq 0$ pour tout $x \in [1, 2]$. La méthode de
  Newton--Raphson dicte en définitive de rechercher le point fixe de
  la fonction
  \begin{align*}
    g(x) &= x - \frac{f(x)}{f^\prime(x)} \\
    &= x - \frac{x^3 + 4 x^2 - 10}{3 x^2 + 8 x}.
  \end{align*}
  Celle-ci est présentée à la
  \autoref{fig:resolution:newtonraphson_2}. On constate que la
  procédure itérative de Newton--Raphson convergera rapidement vers
  une racine unique dans l'intervalle $[1, 2]$. En effet:
<<echo=TRUE>>=
f <- function(x) x^3 + 4*x^ 2 - 10
fp <- function(x) 3*x^2 + 8 * x
nr(f, fp, start = 1.5)
@
  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
f0 <- function(x) x
lim <- c(0.95, 2.05)
f <- function(x) x^3 + 4*x^ 2 - 10
fp <- function(x) 3*x^2 + 8 * x
g <- function(x) x - f(x)/fp(x)
curve(g, xlim = lim, ylim = lim, lwd = 2)
curve(f0, add = TRUE)
polygon(c(1, 1, 2, 2), c(1, 2, 2, 1),
        lty = "dashed", border = "blue")
@
    \caption{Fonction $g(x) = x - f(x)/f^\prime(x)$, où $f(x) = x^3 +
      4 x^2 - 10$}
    \label{fig:resolution:newtonraphson_2}
  \end{figure}

  Le lecteur attentif aura remarqué que la fonction $g$ utilisée ici
  était la fonction $g_5$ dans
  l'\autoref{ex:resolution:pointfixe_2}, celle pour laquelle la
  convergence de la méthode du point fixe était la plus rapide. Mettre
  cette constatation en relation avec la première des remarques
  suivant l'\autoref{algo:resolution:newtonraphson}, à la
  \autopageref{algo:resolution:rem}. %
  \qed
\end{exemple}

\begin{exemple}
  \label{ex:resolution:newtonraphson_3}
  Cet exemple illustre l'importance d'utiliser, pour certaines
  fonctions, une valeur de départ près de la racine. La fonction $f(x)
  = (4x - 7)/(x - 2)$ a une racine en $x = 1,75$ et une asymptote en
  $x = 2$, ce qui cause quelques soucis. (Voir la
  \autoref{fig:resolution:newtonraphson_3-1} pour un graphique de
  cette fonction.)
  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) ifelse(x == 2, NA, (4 * x - 7)/(x - 2))
curve(f, xlim = c(0, 5), lwd = 2)
abline(8, -4, lty = "dashed", col = "blue")
abline(h = 0)
abline(v = 2, lwd = 2, lty = "dotted", col = "darkgray")
curve(f, xlim = c(0, 5), lwd = 2, add = TRUE)
@
  \caption{Fonction $f(x) = (4x - 7)/(x - 2)$ (ligne épaisse),
    asymptote (ligne pointillée) et tangente en $x = 1,5$ (ligne
    traitillée)}
  \label{fig:resolution:newtonraphson_3-1}
  \end{figure}

  On peut tenter de trouver numériquement la racine de la fonction
  $f(x)$ avec l'algorithme de Newton--Raphson en utilisant
  \begin{align*}
    f(x) &= \frac{4x - 7}{x - 2} \\
    \intertext{et}
    f^\prime(x) &= - \frac{1}{(x - 2)^2},
  \end{align*}
  ou encore directement par l'algorithme du point fixe avec
  \begin{align*}
    g(x)
    &= x - \frac{f(x)}{f^\prime(x)} \\
    &= 4x^2 - 14x + 14.
  \end{align*}
  Le graphique de la fonction $g(x)$ ci-dessus se trouve à la
  \autoref{fig:resolution:newtonraphson_3-2}. On notera toutefois que
  le point fixe en $x = 2$ n'est pas une solution acceptable dans le
  problème d'origine.

  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
f0 <- function(x) x
g <- function(x) 4*x^2 - 14*x + 14
lim <- c(1.5, 3)
curve(g, xlim = lim, ylim = lim, lwd = 2)
xx <- c(1.75, 2)
segments(xx, 0, xx, g(xx), lty = 2, col = "darkgray")
axis(1, at = 1.75)
curve(f0, add = TRUE)
@
    \caption{Fonction $g(x) = 4x^2 - 14x + 14$}
    \label{fig:resolution:newtonraphson_3-2}
  \end{figure}

  On constate également dans cette dernière figure que les hypothèses
  pour l'existence et l'unicité d'un point fixe --- et, donc, pour la
  convergence de la méthode de Newton--Raphson --- ne sont pas
  rencontrées. La valeur de départ utilisée aura donc un impact sur la
  réponse obtenue.

  \gotorbox{Compléter cet exemple en exécutant le code informatique
    correspondant à la \autoref{sec:resolution:code}.}%
  \qed
\end{exemple}

Le principal inconvénient de la méthode de Newton--Raphson demeure le
fait de devoir connaître la dérivée de la fonction $f$. Dans les cas
où celle-ci s'avère difficile ou inefficace à calculer, on peut
utiliser la \emph{méthode de la sécante}. Avec cette méthode, plutôt
que d'utiliser la tangente en un essai pour déterminer la valeur de
l'essai suivant, on a recours à la sécante entre les deux essais
précédents; voir la \autoref{fig:resolution:secante}. Les valeurs
des essais successifs sont alors données par:
\begin{equation*}
  x_n = x_{n - 1} - \frac{f(x_{n - 1})(x_{n - 1} - x_{n - 2})}{%
    f(x_{n - 1}) - f(x_{n - 2})},
\end{equation*}
avec $x_0$, $x_1$ des valeurs de départ.

\begin{prob-astuce}
  Nous revenons au problème de départ exprimé sous la forme
  $f(x) = H(x) - 9 = 0$. La fonction des heures d'ensoleillement $H$
  étant simple à dériver, la méthode de Newton--Raphson est simple à
  appliquer. En effet,
  \begin{align*}
    f(x)
    &= H(x) - 9 \\
    &= e^{0,001312 x + 2,778538}
      - e^{-0,001431 x + 2,016340} - 9,
  \end{align*}
  d'où
  \begin{equation*}
    \label{eq:resolution:nr-app}
    f^\prime(x) = 0,001312 e^{0,001312 x + 2,778538}
    + 0,001431 e^{-0,001431 x + 2,016340}.
  \end{equation*}
  Il ne reste qu'à appliquer l'\autoref{algo:resolution:newtonraphson}
  avec les fonctions $f(x)$ et $f^\prime(x)$ ainsi qu'une valeur de
  départ $x_0 \in \{1, 2, \dots, 31\}$.
\end{prob-astuce}

\begin{figure}
  \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) exp(2 * x) - 20
curve(f, xlim = c(0, 2), lwd = 2)
abline(h = 0)
x <- numeric(7)
x[1] <- 0
x[2] <- 2
for (i in 3:length(x))
    x[i] <- x[i - 1] - (f(x[i - 1]) * (x[i - 1] - x[i - 2]))/
    (f(x[i - 1]) - f(x[i - 2]))

segments(x[(1:2)], -21, x[(1:2)], f(x[(1:2)]), lty = 2, col = "darkgray")
segments(x[-c(1, 2)], 0, x[-c(1, 2)], f(x[-c(1, 2)]),
         lwd = 1, lty = "dashed", col = "darkgray")

for (i in 1:(length(x) - 2))
{
    xx <- x[i:(i + 2)]
    fxx <- f(xx)
    segments(xx[1], fxx[1], xx[3], 0, col = "blue")
    arrows(xx[2], fxx[2], xx[3], 0, col = "blue", length = 0.1)
}

points(x, f(x), pch = 21, bg = "red3")
@
  \caption{Illustration de la méthode de la sécante. Cette méthode
    requiert deux essais initiaux. Dans le graphique, il s'agit, dans
    l'ordre, du point à l'extrême gauche et celui à l'extrême droite.
    Les flèches illustrent comment est déterminé l'essai suivant. On
    trace la sécante entre deux points et le prochain essai est la
    valeur en abscisse où cette sécante croise l'axe.}
  \label{fig:resolution:secante}
\end{figure}



\section{Fonctions d'optimisation dans Excel et R}
\label{sec:resolution:fonctions}

Les méthodes de bissection, du point fixe, de Newton--Raphson et
autres permettent de résoudre des équations à une variable de la forme
$f(x) = 0$ ou $g(x) = x$. Il existe également des versions de ces
méthodes pour les systèmes à plusieurs variables comme
\begin{align*}
  f_1(x_1, x_2, x_3) &= 0 \\
  f_2(x_1, x_2, x_3) &= 0 \\
  f_3(x_1, x_2, x_3) &= 0.
\end{align*}

De tels systèmes d'équations surviennent plus souvent qu'autrement
lors de l'optimisation d'une fonction. Par exemple, en recherchant le
maximum ou le minimum d'une fonction $f(x, y)$, on souhaitera résoudre
le système d'équations
\begin{align*}
  \frac{\partial}{\partial x}\, f(x, y) &= 0 \\
  \frac{\partial}{\partial y}\, f(x, y) &= 0.
\end{align*}

La grande majorité des suites logicielles comportent des outils
d'optimisation de fonctions. Ce document passe en revue les fonctions
disponibles dans Excel et R.


\subsection{Solveur de Excel}

Le principal outil d'optimisation utilisé dans Excel est le Solveur.
La rubrique d'aide de cet outil est complète et on trouvera plusieurs
exemples dans le classeur \code{SOLVAMP.XLS} livré avec Excel.

Le reste de cette section est dévolu à des fonctions d'optimisation de
R.

\subsection{Fonction \code{uniroot}}
\label{optimisation:fonctions:uniroot}

La fonction \code{uniroot} recherche la racine\index{racine!d'une
  fonction}\index{fonction!racine} d'une fonction dans un intervalle.
C'est donc la fonction de base pour trouver la solution (unique) de
l'équation $f(x) = 0$ dans un intervalle déterminé.

\subsection{Fonction \code{optimize}}
\label{optimisation:fonctions:optimize}

La fonction \code{optimize} recherche le
minimum\index{minimum!local}\index{fonction!minimum local} local (par
défaut) ou le maximum\index{maximum!local}\index{fonction!maximum
  local} local d'une fonction dans un intervalle donné.

\subsection{Fonction \code{nlm}}
\label{optimisation:fonctions:nlm}

La fonction \code{nlm} minimise une fonction non
linéaire\index{minimum!fonction non linéaire}\index{fonction!minimum}
sur un nombre arbitraire de paramètres.

\subsection{Fonction \code{nlminb}}
\label{optimisation:fonctions:nlminb}

La fonction \code{nlminb} est similaire à \code{nlm}, sauf
qu'elle permet de spécifier des bornes inférieure ou supérieure
pour les paramètres. Attention, toutefois: les arguments de la
fonction ne sont ni les mêmes, ni dans le même ordre que ceux de
\code{nlm}.

\subsection{Fonction \code{optim}}
\label{optimisation:fonctions:optim}

La fonction \code{optim}\index{fonction!optimisation} est l'outil
d'optimisation tout usage de R. À ce titre, la fonction est souvent
utilisée par d'autres fonctions. Elle permet de choisir parmi
plusieurs algorithmes d'optimisation différents et, selon l'algorithme
choisi, de fixer des seuils minimum ou maximum aux paramètres à
optimiser.

\subsection{\code{polyroot}}
\label{optimisation:fonctions:polyroot}

En terminant, un mot sur \code{polyroot()}, qui n'est pas à proprement
parler une fonction d'optimisation, mais qui pourrait être utilisée
dans ce contexte. La fonction \code{polyroot} calcule toutes les
racines\index{racine!d'un polynôme} (complexes) du polynôme
$\sum_{i=0}^n a_i x^i$. Le premier argument est le vecteur des
coefficients $a_0, a_1, \dots, a_n$, dans cet ordre.

\gotorbox{Des exemples d'utilisation des fonctions R ci-dessus sont fournis
  dans le code informatique de la \autoref{sec:resolution:code}.}%

\begin{prob-astuce}
  La fonction \code{uniroot} permet de trouver la solution à l'équation
  $f(x) = 0$ dans un intervalle déterminé. Nous pourrons donc l'utiliser
  dans la solution en fin de chapitre pour confirmer les autres
  résultats.
\end{prob-astuce}

\section{Astuce Ripley}
\label{sec:resolution:astuce}

J'ai appris le truc suivant dans une publication de Brian Ripley --- un
important développeur de R --- dans les forums de discussion de
R. Il m'a été très utile à de nombreuses reprises, alors je le
dissémine.

Une application statistique fréquente de l'optimisation est la
maximisation numérique d'une fonction de vraisemblance ou, plus
communément, la minimisation de la log-vraisemblance négative
\begin{equation*}
  -l(\theta) = - \sum_{i = 1}^n \ln f(x_i; \theta).
\end{equation*}
Les fonctions d'optimisation sont d'ailleurs illustrées dans ce
contexte dans le code informatique de la
\autoref{sec:resolution:code}.

En actuariat, nous utilisons principalement des lois de probabilité
dont les paramètres sont strictement positifs. Or, en pratique, il
n'est pas rare que les fonctions d'optimisation s'égarent dans les
valeurs négatives des paramètres. La fonction de densité n'étant pas
définie, la log-vraisemblance vaut alors \code{NaN} et cela peut faire
complètement dérailler la procédure d'optimisation ou, à tout le
moins, susciter des doutes sur la validité de la réponse.

Afin de pallier à ce problème, l'Astuce Ripley{\texttrademark} propose
d'estimer non pas les paramètres de la loi eux-mêmes, mais plutôt
leurs logarithmes. Si l'on définit $\tilde{\theta} = \ln \theta$,
alors on peut écrire la fonction de log-vraisemblance ci-dessus sous
la forme
\begin{equation*}
  -l(\tilde{\theta}) = - \sum_{i = 1}^n \ln f(x_i; e^{\tilde{\theta}}).
\end{equation*}
Dès lors, $\tilde{\theta}$ (qui peut représenter un ou plusieurs
paramètres) demeure valide sur tout l'axe des réels, ce qui permet
d'éviter bien des soucis de nature numérique lors de la minimisation
de $-l(\tilde{\theta})$.

Évidemment, le résultat de l'optimisation est l'estimateur du maximum
de vraisemblance de $\tilde{\theta}$. Il faudra donc veiller à faire
la transformation inverse pour retrouver l'estimateur de $\theta$.

L'utilisation de l'Astuce est illustrée à la
\autoref{sec:resolution:code}.



\section{Outils additionnels}
\label{sec:resolution:plus}

Les paquetages disponible sur CRAN fournissent plusieurs autres outils
d'optimisation pour R. Pour un bon résumé des options disponibles,
consulter la
\link{http://cran.r-project.org/web/views/Optimization.html}{\emph{CRAN
    Task View}} consacrée à l'optimisation.

\begin{prob-solution}
  Nous résolvons avec R notre problème consistant à trouver la valeur
  de $x$ tel que $H(x) = 9$ avec les méthodes numériques étudiées dans
  ce chapitre. Les fonctions \code{bissection}, \code{pointfixe} et
  \code{nr} ci-dessous sont celles tirées du code informatique de la
  \autoref{sec:resolution:code}. \\

  Méthode de bissection: résolution de $H(x) - 9 = 0$.
<<echo=TRUE>>=
H <- function(x)
    exp(0.001312 * x + 2.778538) -
        exp(-0.001431 * x + 2.016340)
bissection(FUN = function(x) H(x) - 9,
           lower = 1, upper = 31)
@

  Méthode du point fixe: résolution de $g(x) = x$ avec la fonction $g$
  de l'encadré de la \autopageref{eq:resolution:pf-app}.
<<echo=TRUE>>=
g <- function(x)
    (log(9 + exp(-0.001431*x+2.016340)) - 2.778538) /
    0.001312
pointfixe(g, start = 15)
@

  Méthode de Newton--Raphson: résolution de $f(x) = H(x) - 9 = 0$ avec
  les fonctions $f$ et $f^\prime$ de l'encadré de la
  \autopageref{eq:resolution:nr-app}.
<<echo=TRUE>>=
f <- function(x) H(x) - 9
fp <- function(x)
    0.001312 * exp(0.001312 * x + 2.778538) +
        0.001431 * exp(-0.001431 * x + 2.016340)
nr(f, fp, start = 15)
@

  Vérification avec la fonction \code{uniroot}.
<<echo=TRUE>>=
uniroot(f, c(1, 31))$root
@
\end{prob-solution}

\newpage


\section{Code informatique}
\label{sec:resolution:code}

\def\scriptfilename{resolution\string_equations.R}

\scriptfile{\scriptfilename}
\lstinputlisting[firstline=13]{\scriptfilename}


\section{Exercices}
\label{sec:resolution:exercices}

\Opensolutionfile{reponses}[reponses-resolution_equations]
\Opensolutionfile{solutions}[solutions-resolution_equations]

\begin{Filesave}{reponses}
\bigskip
\section*{Réponses}

\end{Filesave}

\begin{Filesave}{solutions}
\section*{Chapitre \ref*{chap:resolution}}
\addcontentsline{toc}{section}{Chapitre \ref*{chap:resolution}}

\end{Filesave}

<<echo=FALSE>>=
options(width = 55, digits = 5)
@

\begin{exercice}[nosol]
  En vous basant sur les fonctions \code{bissection}, \code{pointfixe}
  et \code{nr} présentées dans le code de la
  \autoref{sec:resolution:code}, écrire une fonction R pour
  effectuer les calculs de l'algorithme de la sécante. Outre les
  arguments communs à toutes les fonctions que sont le niveau de
  tolérance $\varepsilon$, le nombre maximal d'itérations
  $N_{\mathrm{max}}$ et une valeur booléenne spécifiant si les valeurs
  successives des itérations doivent être affichées à l'écran, la
  fonction doit compter les arguments $f(x)$, $x_0$ et $x_1$.
\end{exercice}

\begin{exercice}
  \label{ex:resolution:toutes}
  Trouver la solution des équations suivantes par les méthodes de
  bissection, de Newton--Raphson et de la sécante.
  \begin{enumerate}
  \item $x^3 - 2 x^2 - 5 = 0$ pour $1 \leq x \leq 4$
  \item $x^3 + 3 x^2 - 1 = 0$ pour $-4 \leq x \leq 0$
  \item $x - 2^{-x} = 0$ pour $0 \leq x \leq 1$
  \item $e^x + 2^{-x} + 2 \cos x - 6 = 0$ pour $1 \leq x \leq 2$
  \item $e^x - x^2 + 3x - 2 = 0$ pour $0 \leq x \leq 1$
  \end{enumerate}
  \begin{sol}
    Les solutions suivantes utilisent nos fonctions de résolution
    d'équations à une variable. Les valeurs intermédiaires sont
    affichées pour montrer la convergence. La
    \autoref{fig:resolution:toutes} contient les graphiques des cinq
    fonctions pour les intervalles mentionnés dans l'énoncé.
    \begin{figure}
      \centering
      \begin{minipage}{0.45\linewidth}
        \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) x^3 - 2 * x^2 - 5
curve(f, xlim = c(1, 4), lwd = 2)
abline(h = 0)
@
        \subcaption{$f(x) = x^3 - 2 x^2 - 5$}
      \end{minipage}
      \hfill
      \begin{minipage}{0.45\linewidth}
        \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) x^3 + 3 * x^2 - 1
curve(f, xlim = c(-4, 0), lwd = 2)
abline(h = 0)
@
        \subcaption{$f(x) = x^3 + 3 x^2 - 1$}
      \end{minipage} \\
      \begin{minipage}{0.45\linewidth}
        \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) x - 2^(-x)
curve(f, xlim = c(0, 1), lwd = 2)
abline(h = 0)
@
        \subcaption{$f(x) = x - 2^{-x}$}
      \end{minipage}
      \hfill
      \begin{minipage}{0.45\linewidth}
        \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) exp(x) + 2^(-x) + 2 * cos(x) - 6
curve(f, xlim = c(1, 2), lwd = 2)
abline(h = 0)
@
        \subcaption{$f(x) = e^x + 2^{-x} + 2 \cos x - 6$}
      \end{minipage} \\
      \begin{minipage}{0.45\linewidth}
        \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) exp(x) - x^2 + 3 * x - 2
curve(f, xlim = c(0.2, 0.3), lwd = 2)
abline(h = 0)
@
        \subcaption{$f(x) = e^x - x^2 + 3x - 2$}
      \end{minipage}
      \caption{Fonctions de l'\autoref{ex:resolution:toutes}}
      \label{fig:resolution:toutes}
    \end{figure}
<<echo=FALSE>>=
source("bissection.R")
source("nr.R")
source("secante.R")
@
    \begin{enumerate}
    \item La fonction n'a qu'une seule racine dans $[1, 4]$.
<<echo=TRUE>>=
f1 <- function(x) x^3 - 2 * x^2 - 5
f1p <- function(x) 3 * x^2 - 4 * x
bissection(f1, lower = 1, upper = 4, echo = TRUE)
nr(f1, f1p, start = 2.5, echo = TRUE)
secante(f1, start0 = 1, start1 = 4, echo = TRUE)
@
    \item La fonction possède deux racines dans $[-4, 0]$. La
      convergence se fera vers l'une ou l'autre selon la position
      de la ou des valeurs de départ par rapport à l'extremum de la
      fonction dans l'intervalle. Ici, il s'agit d'un maximum $x =
      -2$. Ainsi, avec des valeurs de départ inférieures au maximum,
      on trouve la première racine:
<<echo=TRUE>>=
f2 <- function(x) x^3 + 3 * x^2 - 1
f2p <- function(x) 3 * x^2 + 6 * x
bissection(f2, lower = -3, upper = -2.8, TRUE)
nr(f2, f2p, start = -3, TRUE)
secante(f2, start0 = -3, start1 = -2, TRUE)
@
      Pour trouver la seconde racine, on utilise des valeurs de départ
      supérieures au maximum:
<<echo=TRUE>>=
bissection(f2, lower = -1, upper = 0.5, TRUE)
nr(f2, f2p, start = -1, TRUE)
secante(f2, start0 = -2, start1 = -1, TRUE)
@
      On remarquera que les deux valeurs de départ de la méthode de la
      sécante n'ont pas à se trouver de part et d'autre de la racine.
    \item La fonction n'a qu'une seule racine dans $[0, 1]$ et elle
      est légèrement supérieure à $0,6$.
<<echo=TRUE>>=
f3 <- function(x) x - 2^(-x)
f3p <- function(x) 1 + log(2) * 2^(-x)
bissection(f3, lower = 0.6, upper = 0.65, TRUE)
nr(f3, f3p, start = 0.6, TRUE)
secante(f3, start0 = 0.6, start1 = 0.65, TRUE)
@
    \item La fonction n'a qu'une seule racine dans $[1, 2]$ et elle
      est légèrement supérieure à $1,8$.
<<echo=TRUE>>=
f4 <- function(x)
    exp(x) + 2^(-x) + 2 * cos(x) - 6
f4p <- function(x)
    exp(x) - 2^(-x) * log(2) - 2 * sin(x)
bissection(f4, lower = 1.8, upper = 1.85, TRUE)
nr(f4, f4p, start = 1.8, TRUE)
secante(f4, start0 = 1.8, start1 = 1.85, TRUE)
@
    \item Encore ici, la fonction n'a qu'une seule racine dans
      l'intervalle mentionné et elle se situe autour de $0,25$.
<<echo=TRUE>>=
f5 <- function(x) exp(x) - x^2 + 3 * x - 2
f5p <- function(x) exp(x) - 2 * x + 3
bissection(f5, lower = 0.24, upper = 0.26, TRUE)
nr(f5, f5p, start = 0.26, TRUE)
secante(f5, start0 = 0.24, start1 = 0.26, TRUE)
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:resolution:sqrt(2)}
  Déterminer la valeur numérique de $\sqrt{2}$ à l'aide de la méthode
  de bissection dans l'intervalle $[0, 2] $ avec dix itérations.
  Comparer avec la vraie valeur.
  \begin{sol}
    On trouve la racine de $f(x) = x^2 - 2$ dans l'intervalle $[0, 2]$
    par la méthode de bissection avec un maximum de dix itérations. Le
    \autoref{tab:resolution:sqrt(2)} contient les valeurs
    successives de $a$, $b$, $x = (a + b)/2$ et $f(x)$.
    \begin{table}[t]
      \centering
      \caption{\normalfont Valeurs successives de la méthode de
        bissection pour l'\autoref{ex:resolution:sqrt(2)}}
      \label{tab:resolution:sqrt(2)}
      \begin{tabular}{>{$}r<{$}D{.}{,}{1.10}D{.}{,}{1.10}D{.}{,}{1.10}D{.}{,}{1.10}}
        \toprule
        \multicolumn{1}{c}{$n$} &
        \multicolumn{1}{c}{$a_n$} &
        \multicolumn{1}{c}{$b_n$} &
        \multicolumn{1}{c}{$x_n$} &
        \multicolumn{1}{c}{$f(x_n)$} \\
        \midrule
        1 & 0 & 2 & 1 & -1 \\
        2 & 1.00 & 2.00 & 1.50 & 0.25 \\
        3 & 1.0000 &  1.5000 &  1.2500 & -0.4375 \\
        4 & 1.250000 &  1.500000 &  1.375000 & -0.109375 \\
        5 & 1.37500000 & 1.50000000 & 1.43750000 & 0.06640625 \\
        6 & 1.37500000 &  1.43750000 &  1.40625000 & -0.02246094 \\
        7 & 1.40625000 & 1.43750000 & 1.42187500 & 0.02172852 \\
        8 & 1.4062500000 &  1.4218750000 &  1.4140625000 & -0.0004272461 \\
        9 & 1.41406250 & 1.42187500 & 1.41796875 & 0.01063538 \\
        10 & 1.41406250 & 1.41796875 & 1.41601562 & 0.00510025 \\
        \bottomrule
      \end{tabular}
    \end{table}
    On obtient donc une réponse de $1,41601562$, alors que la vraie
    réponse est le nombre irrationnel $\sqrt{2} = 1,414214$.
  \end{sol}
\end{exercice}

\begin{exercice}
  Soit $\{x_n\}$ une suite définie par
  \begin{displaymath}
    x_n = \sum_{k=1}^n \frac{1}{k}.
  \end{displaymath}
  Démontrer que $\lim_{n \rightarrow \infty} (x_n - x_{n-1}) = 0$,
  mais que la suite diverge néanmoins. Ceci illustre que l'erreur
  absolue peut être un mauvais critère d'arrêt dans les méthodes
  numériques.
  \begin{sol}
    On a que
    \begin{align*}
      x_n - x_{n - 1}
      &= \sum_{k=1}^n \frac{1}{k} - \sum_{k=1}^{n - 1} \frac{1}{k} \\
      &= \frac{1}{n},
    \end{align*}
    d'où $\lim_{n \rightarrow \infty} (x_n - x_{n-1}) = \lim_{n
      \rightarrow \infty} n^{-1} = 0$. Or, $\sum_{k=1}^n k^{-1}$ est
    la série harmonique qui est connue pour diverger. On peut, par
    exemple, justifier ceci par le fait que l'intégrale
    \begin{displaymath}
      \int_1^\infty \frac{1}{x}\, dx
    \end{displaymath}
    diverge elle-même. Cet exercice illustre donc que le critère $|x_n
    - x_{n - 1}| < \varepsilon$ peut être satisfait même pour une
    série divergente.
  \end{sol}
\end{exercice}

\begin{exercice}
  Soit la fonction $g(x) = 2^{-x}$ sur l'intervalle $[0, 1]$.
  \begin{enumerate}
  \item Vérifier si les hypothèses du
    \autoref{thm:resolution:pointfixe} quant à l'existence et
    l'unicité d'un point fixe dans $[0, 1]$ sont satisfaites.
  \item Déterminer graphiquement l'existence et l'unicité d'un point
    fixe de $g(x)$ dans $[0, 1]$ puis, le cas échéant, calculer ce
    point fixe.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item On considère la fonction $g(x) = 2^{-x}$ dans l'intervalle
      $[0, 1]$. En premier lieu, $1/2 \leq 2^{-x} \leq 1$ pour $0 \leq
      x \leq 1$, donc $g(x) \in [0, 1]$. De plus, $g^\prime(x) = -
      2^{-x} (\ln 2)$, d'où
      \begin{displaymath}
        |g^\prime(x)| = \frac{\ln 2}{2^{x}} \leq \ln 2 < 1, \quad
        0 \leq x \leq 1.
      \end{displaymath}
      Par le \autoref{thm:resolution:pointfixe}, la fonction $g$
      possède un point fixe unique dans l'intervalle $[0, 1]$.
    \item Le graphique de la fonction $g$ se trouve à la
      \autoref{fig:resolution:2^-x}. On constate que la fonction a
      effectivement un
      point fixe unique dans l'intervalle $[0, 1]$ et que celui-ci se
      trouve près de $x = 0,6$. On peut donc utiliser cette
      valeur comme point de départ de l'algorithme du point fixe:
<<echo=FALSE>>=
source("pointfixe.R")
@
<<echo=TRUE>>=
pointfixe(function(x) 2^(-x), start = 0.6)
@
      On remarque que la réponse est indépendante de la valeur de
      départ:
<<echo=TRUE>>=
pointfixe(function(x) 2^(-x), start = 0)
pointfixe(function(x) 2^(-x), start = 1)
pointfixe(function(x) 2^(-x), start = 2)
@
      \begin{figure}
        \centering
<<echo=FALSE, fig=TRUE>>=
f <- function(x) x
g <- function(x) 2^(-x)
curve(g, xlim = c(-0.05, 1.05), ylim = c(-0.05, 1.05), lwd = 2)
curve(f, add = TRUE)
polygon(c(0, 0, 1, 1), c(0, 1, 1, 0), lty = 2, border = "blue")
@
        \caption{Fonction $g(x) = 2^{-x}$ dans $[0, 1]$}
        \label{fig:resolution:2^-x}
      \end{figure}
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  Vérifier que les cinq fonctions $g_1, \dots, g_5$ de
  l'\autoref{ex:resolution:pointfixe_2} ont toutes un point fixe
  en $x^*$ lorsque $f(x^*) = 0$, où $f(x) = x^3 + 4x^2 - 10$.
  \begin{sol}
    Les cinq fonctions sont les suivantes:
    \begin{align*}
      g_1(x) &= x - x^3 - 4 x^2 + 10  \\
      g_2(x) &= \left( \frac{10}{x} - 4x \right)^{1/2} \displaybreak[0]\\
      g_3(x) &= \frac{1}{2} (10 - x^3)^{1/2}  \displaybreak[0]\\
      g_4(x) &= \left( \frac{10}{4 + x} \right)^{1/2} \\
      g_5(x) &= x - \frac{x^3 + 4 x^2 - 10}{3x^2 + 8x}.
    \end{align*}
    Soit $f(x) = x^3 + 4x^2 - 10$. On peut réécrire l'équation $f(x) =
    0$ de différentes façons:
    \begin{enumerate}
    \item $x = x - f(x)$;
    \item $x^3 = 10 - 4x^2 \Rightarrow x^2 = 10/x - 4x \Rightarrow x =
      (10/x - 4x)^{1/2}$;
    \item $4x^2 = 10 - x^3 \Rightarrow x^2 = (10 - x^3)/4 \Rightarrow
      x = \frac{1}{2}(10 - x^3)^{1/2}$;
    \item $4x^2 +  x^3 = 10 \Rightarrow x^2 = 10/(4 + x) \Rightarrow x
      = (10/(4 + x))^{1/2}$;
    \item $x = x - f(x)/f^\prime(x)$.
    \end{enumerate}
    Les fonctions $g_1$ à $g_5$ correspondent, dans l'ordre, au côté
    droit de chacune des équations ci-dessus. On remarquera que la
    fonction $g_5$ est celle préconisée par la méthode de
    Newton--Raphson --- et celle qui converge le plus rapidement.
  \end{sol}
\end{exercice}

\begin{exercice}
  Soit $g(x) = 4x^2 - 14x + 14$. Pour quels intervalles de valeurs de
  départ la procédure de point fixe converge-t-elle et diverge-t-elle?
  \begin{sol}
    La fonction $g(x) = 4x^2 - 14x + 14$ est une parabole ayant deux
    points fixes. On observe graphiquement que l'un se trouve en $x =
    2$ et que $g(1,5) = g(2)$. Or, pour toute valeur de départ $x_0 <
    1,5$ de l'algorithme du point fixe, on constate que les valeurs de
    $x_1, x_2, \dots$ se retrouveront de plus en plus loin sur la
    branche droite de la parabole. Il en va de même pour tout $x_0 >
    2$. La procédure diverge donc pour de telles valeurs de départ. En
    revanche, il est facile de vérifier graphiquement que la procédure
    converge pour toute valeur de départ dans l'intervalle $[1,5,\,
    2]$. Si $x_0 = 1,5$, on obtient le point fixe $x = 2$ après une
    seule itération.
  \end{sol}
  \begin{rep}
    Converge pour $x_0 \in [1,5, 2]$; diverge pour $x_0 \leq 1,5$ et
    $x_0 > 2$
  \end{rep}
\end{exercice}

\begin{exercice}
  \label{ex:resolution:racinecubique}
  Les trois fonctions ci-dessous sont toutes des candidates pour faire
  l'approximation, par la méthode du point fixe, de $\sqrt[3]{21}$:
  \begin{align*}
    g_1(x) &= \frac{20 x + 21x^{-2}}{21} \\
    g_2(x) &= x - \frac{x^3 - 21}{3 x^2} \\
    g_3(x) &= x - \frac{x^4 - 21 x}{x^2 - 21}.
  \end{align*}
  Classer ces fonctions en ordre décroissant de vitesse de convergence
  de l'algorithme du point fixe. \emph{Astuce}: comparer les valeurs
  des dérivées autour du point fixe.
  \begin{sol}
    En premier lieu, on remarque que les fonctions $g_1$, $g_2$ et
    $g_3$ sont développées à partir de l'équation $x^3 = 21$ pour
    calculer $\sqrt[3]{21}$ par la méthode du point fixe. La
    \autoref{fig:resolution:racinecubique} présente ces trois
    fonctions.
    \begin{figure}
      \centering
      \begin{minipage}[t]{0.32\linewidth}
        \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
f <- function(x) x
g <- function(x) (20 * x + 21 / x^2)/21
curve(g, xlim = c(2.45, 3.05), ylim = c(2.45, 3.05), lwd = 2)
curve(f, add = TRUE)
polygon(c(2.5, 2.5, 3, 3), c(2.5, 3, 3, 2.5), lty = 2, border = "blue")
@
        \subcaption{fonction $g_1(x)$}
      \end{minipage}
      \hfill
      \begin{minipage}[t]{0.32\linewidth}
        \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
f <- function(x) x
g <- function(x) x - (x^3 - 21)/(3 * x^2)
curve(g, xlim = c(2.45, 3.05), ylim = c(2.45, 3.05), lwd = 2)
curve(f, add = TRUE)
polygon(c(2.5, 2.5, 3, 3), c(2.5, 3, 3, 2.5), lty = 2, border = "blue")
@
        \subcaption{fonction $g_2(x)$}
      \end{minipage}
      \hfill
      \begin{minipage}[t]{0.32\linewidth}
        \centering
<<echo=FALSE, fig=TRUE, height=4, width=4>>=
f <- function(x) x
g <- function(x) x - (x^4 - 21 * x)/(x^2 - 21)
curve(g, xlim = c(2.45, 3.05), ylim = c(2.45, 3.05), lwd = 2)
curve(f, add = TRUE)
polygon(c(2.5, 2.5, 3, 3), c(2.5, 3, 3, 2.5), lty = 2, border = "blue")
@
        \subcaption{fonction $g_3(x)$}
      \end{minipage}
      \caption{Fonctions de l'\autoref{ex:resolution:racinecubique}}
      \label{fig:resolution:racinecubique}
    \end{figure}
    On a
    \begin{align*}
      g_1^\prime(x)
      &= \frac{20}{21} - \frac{2}{x^3} \\
      g_2^\prime(x)
      &= \frac{2}{3} - \frac{14}{x^3} \\
      g_3^\prime(x)
      &= 1 - \frac{2x^5 - 84 x^3 + 21 x^2 + 441}{(x^2 - 21)^2}.
    \end{align*}
    Considérons l'intervalle $[2,5,\, 3]$ autour du point fixe. On a
    que $|g_2^\prime(x)| < |g_1^\prime(x)|$ pour tout $x$ dans cet
    intervalle, donc la procédure du point fixe converge plus
    rapidement pour $g_2$ (la fonction de la méthode de
    Newton--Raphson). Cela se vérifie aisément sur les graphiques de
    la \autoref{fig:resolution:racinecubique}. Toujours à l'aide
    des graphiques, on voit que la procédure diverge avec la fonction
    $g_3$.
  \end{sol}
  \begin{rep}
    $g_2$, $g_1$; $g_3$ ne converge pas
  \end{rep}
\end{exercice}

\begin{exercice}
  Démontrer, à l'aide du théorème du point fixe, que la fonction $g(x)
  = 2^{-x}$ possède un point fixe unique dans l'intervalle
  $[\frac{1}{3}, 1]$. Calculer par la suite ce point fixe à l'aide de
  la fonction \code{pointfixe}.
  \begin{sol}
    On considère la fonction $g(x) = 2^{-x}$ dans l'intervalle
    $[\frac{1}{3}, 1]$. En premier lieu, on a
    $g(x) \in [\frac{1}{2}, 1/\sqrt[3]{2}] \subset [\frac{1}{3}, 1]$
    pour $x \in [\frac{1}{3}, 1]$. De plus, on a
    $g^\prime(x) = -2^{-x} (\ln 2)$. Puisque $\ln 2 < 1$, on a
    aussi que $|g^\prime(x)| = g(x) (\ln 2) \in [\frac{1}{3}, 1]$
    pour $x \in [\frac{1}{3}, 1]$.

    Par le théorème du point fixe, la fonction $g$ possède donc un
    point fixe unique dans l'intervalle $[\frac{1}{3}, 1]$. La valeur
    de ce point fixe est
<<echo=TRUE>>=
pointfixe(function(x) 2^(-x), start = 2/3)
@
  \end{sol}
\end{exercice}

\begin{exercice}
  Vérifier graphiquement que le \autoref{thm:resolution:pointfixe}
  demeure valide si la condition $|g^\prime(x)| \leq k < 1$ est
  remplacée par $g^\prime(x) \leq k < 1$.
  \begin{sol}
    La condition $|g^\prime(x)| \leq k < 1$ du
    \autoref{thm:resolution:pointfixe} assure l'unicité d'un
    point fixe. Cette condition est nécessaire pour que la fonction
    $g(x)$ ne puisse repasser au-dessus de la droite $y = x$ après
    l'avoir déjà croisée une première fois pour créer un point fixe.
    Or, il est seulement nécessaire de limiter la croissance de la
    fonction --- soit les valeurs positives de sa pente. Peu importe
    la vitesse de décroissance de la fonction dans l'intervalle $[a,
    b]$ (mais toujours sujet à ce que $g(x) \in [a, b]$), la fonction
    ne peut croiser la droite $y = x$ qu'une seule fois. La condition
    $g^\prime(x) \leq k < 1$ est donc suffisante pour assurer
    l'unicité du point fixe dans $[a, b]$.
  \end{sol}
\end{exercice}

\begin{exercice}
  Utiliser la méthode de Newton--Raphson pour trouver le point sur la
  courbe $y = x^2$ le plus près du point $(1, 0)$. \emph{Astuce}:
  minimiser la distance entre le point $(1, 0)$ et le point $(x,
  x^2)$.
  \begin{sol}
    La distance entre deux points $(x_1, y_1)$ et $(x_2, y_2)$ de
    $\mathbb{R}^2$ est
    \begin{displaymath}
      d = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}.
    \end{displaymath}
    Par conséquent, la distance entre le point $(x, x^2)$ et le point
    $(1, 0)$ est une fonction de $x$
    \begin{displaymath}
      d(x) = \sqrt{(x - 1)^2 + (x^2 - 0)^2} = \sqrt{x^4 + x^2 - 2x + 1}.
    \end{displaymath}
    On cherche la valeur de minimisant $d(x)$ ou, de manière
    équivalente, $d^2(x)$. On doit donc résoudre
    \begin{displaymath}
      \frac{d}{dx} d^2(x) = f(x) = 4x^3 + 2x - 2 = 0
    \end{displaymath}
    à l'aide de la méthode de Newton--Raphson. Cela requiert également
    \begin{displaymath}
      f^\prime(x) = 12 x^2 + 2.
    \end{displaymath}
    Le point sur la courbe $y = x^2$ le plus du point $(1, 0)$ est
    donc la limite de la suite
    \begin{displaymath}
      x_n = x_{n - 1} - \frac{4x_{n - 1}^3 + 2x_{n - 1} - 2}{12x_{n -
          1}^2 + 2}, \quad n = 1, 2, \dots,
    \end{displaymath}
    avec $x_0$ une valeur de départ «près» de la solution. On obtient
<<echo=TRUE>>=
nr(function(x) 4 * x^3 + 2 * x - 2,
   function(x) 12 * x^2 + 2, start = 0.6)
@

    On voit à la \autoref{fig:resolution:proche} que la solution, disons le
    point $(x^*, (x^*)^2)$, est la projection du point $(1, 0)$ sur la
    courbe $y = x^2$; autrement dit, la droite passant par $(x^*,
    (x^*)^2)$ et $(1, 0)$ est perpendiculaire à la tangente de $y =
    x^2$ en $x = x^*$.
    \begin{figure}
      \centering
<<echo=FALSE, fig=TRUE>>=
xp <- nr(function(x) 4 * x^3 + 2 * x - 2, function(x) 12 * x^2 + 2, start = 0.6)$root
curve(x^2, xlim = c(0, 1), lwd = 2)
segments(xp, xp^2, 1, 0)
points(c(1, xp), c(0, xp^2), pch = 19)
@
      \caption{Point de $y = x^2$ le plus près du point $(1, 0)$}
      \label{fig:resolution:proche}
    \end{figure}
  \end{sol}
  \begin{rep}
    $0,589755$
  \end{rep}
\end{exercice}

\begin{exercice}
  \label{ex:resolution:tri}
  Le taux de rendement interne d'une série de flux
  financiers $\{\mathit{CF}_t\}$ est le taux $i$ tel que
  \begin{displaymath}
    \sum_{t=0}^{n} \frac{\mathit{CF}_{t}}{(1 + i)^{t}} = 0.
  \end{displaymath}
  Écrire une fonction R permettant de calculer le taux de rendement
  interne d'une série de flux financiers quelconque à l'aide de la
  méthode de Newton--Raphson. Les arguments de la fonction sont un
  vecteur \code{CF} et un scalaire \code{erreur.max}. Au moins un
  élément de \code{CF} doit être négatif pour représenter une sortie
  de fonds. Dans tous les cas, utiliser $i = 0,05$ comme valeur de
  départ.
  \begin{sol}
    La fonction devra utiliser la méthode de Newton--Raphson pour
    trouver la racine de $f(i) = 0$, où
    \begin{align*}
      f(i)
      &= \sum_{t=0}^{n} \frac{\mathit{CF}_{t}}{(1 + i)^{t}} \\
      \intertext{et}
      f^\prime(i)
      &= - \sum_{t=0}^{n} \frac{t \mathit{CF}_{t}}{(1 + i)^{t + 1}}.
    \end{align*}
    La fonction \code{tri} de la \autoref{fig:resolution:tri} calcule le
    taux de rendement interne d'un vecteur de flux financiers en
    utilisant la fonction de Newton--Raphson \code{nr}.
    \begin{figure}
      \centering
      \begin{framed}
\begin{lstlisting}
tri <- function(CF, erreur.max = 1E-6)
{
    if (!any(CF < 0))
        stop("au moins un flux financier doit être
              négatif")

    t <- 0:(length(CF) - 1)

    f <- function(i) sum(CF/(1 + i)^t)
    fp <- function(i) sum((-CF * t)/((1 + i)^(t + 1)))

    nr(f, fp, start = 0.05, TOL = erreur.max)$root
}
\end{lstlisting}
      \end{framed} %$
      \caption{Fonction R de calcul du taux de rendement interne d'une
        série de flux financiers}
      \label{fig:resolution:tri}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  Refaire l'\autoref{ex:resolution:tri} en VBA en composant une
  fonction accessible dans une feuille Excel et comparer le résultat
  avec la fonction Excel \code{TRI()}.
  \begin{sol}
    La \autoref{fig:resolution:tri2} contient le code d'une fonction VBA
    \code{tri2} effectuant le calcul du taux de rendement interne
    d'un ensemble de flux financiers. Ceux-ci sont passés en argument
    à la fonction par le bais d'une plage horizontale ou verticale de
    montants périodiques consécutifs. La procédure de Newton--Raphson
    est codée à même cette fonction. On peut vérifier facilement que
    le résultat de cette fonction est identique à celui de la fonction
    Excel \code{TRI()}.
    \begin{figure}
      \centering
      \begin{framed}
\begin{verbatim}
Function tri2(flux As Range, Optional ErreurMax
              As Double = 0.000000001)
    Dim nrow As Integer, ncol As Integer, n As Integer
    Dim CF() As Double, f As Double, fp As Double,
        i As Double, it As Double

    nrow = flux.Rows.Count
    ncol = flux.Columns.Count
    n = IIf(nrow > 1, nrow, ncol) - 1
    ReDim CF(0 To n)

    For t = 0 To n
        CF(t) = flux.Cells(t + 1, 1)
    Next t

    If CF(0) > 0 Then
        tri2 = "Erreur"
        Exit Function
    End If

    i = 0.05
    Do
        f = 0
        fp = 0
        it = i
        For t = 0 To n
            f = f + CF(t) / (1 + i) ^ t
            fp = fp - t * CF(t) / (1 + i) ^ (t + 1)
        Next t
        i = i - f / fp
    Loop Until Abs(i - it) / i < ErreurMax
    tri2 = i
End Function
\end{verbatim}
      \end{framed}
      \caption{Fonction VBA de calcul du taux de rendement interne d'une
        série de flux financiers}
      \label{fig:resolution:tri2}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:resolution:gamma}
  \begin{enumerate}
  \item Composer une fonction R pour estimer par la méthode du maximum
    de vraisemblance le paramètre $\theta$ d'une loi gamma de
    paramètre de forme $\alpha = 3$ et de paramètre d'échelle $\theta
    = 1/\lambda$ --- de moyenne $3 \theta$, donc --- à partir d'un
    échantillon aléatoire $x_1, \dots, x_n$. \emph{Astuce}: maximiser
    la fonction de log-vraisemblance plutôt que la fonction de
    vraisemblance.
  \item Simuler 20 observations d'une loi gamma avec paramètre de
    forme $\alpha = 3$ et moyenne $\nombre{3000}$, puis estimer le
    paramètre d'échelle $\theta$ par le maximum de vraisemblance.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item On veut estimer par la méthode du maximum de vraisemblance
      le paramètre $\theta$ d'une loi Gamma$(3, 1/\theta)$, dont la
      fonction de densité de probabilité est
      \begin{displaymath}
        f(x; \theta) = \frac{1}{2 \theta^3}\, x^2 e^{-x/\theta}, \quad
        x > 0.
      \end{displaymath}
      La fonction de log-vraisemblance d'un échantillon aléatoire
      $x_1, \dots, x_n$ tiré de cette loi est
      \begin{align*}
        l(\theta)
        &= \sum_{i = 1}^n \ln f(x_i; \theta) \\
        &= \sum_{i = 1}^n
        \left(
          2 \ln x_i - \frac{x_i}{\theta} - \ln 2 - 3 \ln \theta
        \right) \\
        &= 2 \sum_{i = 1}^n \ln x_i - \frac{1}{\theta} \sum_{i = 1}^n
        x_i - n \ln 2 - 3n \ln \theta.
      \end{align*}
      On cherche le maximum de la fonction $l(\theta)$, soit la valeur
      de $\theta$ tel que
      \begin{displaymath}
        l^\prime(\theta) = \frac{1}{\theta^2} \sum_{i = 1}^n x_i -
        \frac{3n}{\theta} = 0.
      \end{displaymath}
      Résoudre cette équation à l'aide de la méthode de
      Newton--Raphson requiert également
      \begin{displaymath}
        l^{\prime\prime}(\theta) = - \frac{2}{\theta^3} \sum_{i =
          1}^n x_i + \frac{3n}{\theta^2}.
      \end{displaymath}
      La \autoref{fig:resolution:emv.gamma} présente une fonction R pour
      effectuer le calcul à l'aide de notre fonction de
      Newton--Raphson \code{nr}.  On remarquera que la somme des
      valeurs de l'échantillon --- qui ne change pas durant la
      procédure itérative --- est calculée une fois pour toute dès le
      début de la fonction.  De plus, on utilise comme valeur de
      départ l'estimateur des moments de $\theta$, $\bar{x}/3$.
      \begin{figure}
        \centering
        \begin{framed}
\begin{lstlisting}
emv.gamma <- function(x, erreur.max = 1E-6)
{
    n <- length(x)
    xsum <- sum(x)
    f <- function(theta) xsum/theta^2 -
         (3 * n)/theta
    fp <- function(theta) -2 * xsum / theta^3 +
          (3 * n)/theta^2
    nr(f, fp, xsum/n/3, TOL = erreur.max)$root
}
\end{lstlisting}
        \end{framed}
        \caption{Fonction R d'estimation du paramètre d'échelle d'une
          loi gamma par le maximum de vraisemblance}
        \label{fig:resolution:emv.gamma}
      \end{figure}
    \item On a, par exemple,
<<echo=FALSE>>=
emv.gamma <- function(x, erreur.max = 1E-6)
{
    n <- length(x)
    xsum <- sum(x)
    f <- function(theta) xsum/theta^2 -
         (3 * n)/theta
    fp <- function(theta) -2 * xsum / theta^3 +
          (3 * n)/theta^2
    nr(f, fp, mean(x)/3, TOL = erreur.max)$root
}
@
<<echo=TRUE>>=
x <- rgamma(20, shape = 3, scale = 1000)
emv.gamma(x)
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  Refaire l'\autoref{ex:resolution:gamma} à l'aide d'une routine VBA.
  Comparer votre réponse avec celle obtenue à l'aide du Solveur de
  Excel.
  \begin{sol}
    La \autoref{fig:resolution:emvGamma} présente le code VBA d'une fonction
    \code{emvGamma} très similaire à la fonction R de l'exercice
    précédent. Pour l'utiliser dans Excel, il suffit de lui passer en
    argument une plage (verticale) contenant un échantillon aléatoire
    d'une loi Gamma$(3, 1/\theta)$.
    \begin{figure}
      \centering
      \begin{framed}
\begin{verbatim}
Function emvGamma(Data As Range, Optional ErreurMax
                  As Double = 0.000000001)
    Dim n As Integer
    Dim sData As Double, f As Double,
        fp As Double, x As Double, xt As Double

    n = Data.Rows.Count
    sData = WorksheetFunction.Sum(Data)

    x = sData / n / 3
    Do
        f = sData / x ^ 2 - (3 * n) / x
        fp = -2 * sData / x ^ 3 + 3 * n / x ^ 2
        xt = x
        x = x - f / fp
    Loop Until Abs(x - xt) / x < ErreurMax
    emvGamma = x
End Function
\end{verbatim}
      \end{framed}
      \caption{Fonction VBA d'estimation du paramètre d'échelle d'une
        loi gamma par le maximum de vraisemblance}
      \label{fig:resolution:emvGamma}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  À l'aide de la méthode du point fixe, trouver le taux d'intérêt $i$
  tel que
  \begin{displaymath}
    a_{\angl{10}\,i}^{(12)} = \frac{1- (1 + i)^{-10}}{i^{(12)}} = 8,
  \end{displaymath}
  où
  \begin{displaymath}
    \left( 1 + \frac{i^{(12)}}{12} \right)^{12} = 1 + i.
  \end{displaymath}
  Comparer les résultats obtenus avec la méthode de Newton--Raphson.
  \begin{sol}
    On cherche à résoudre l'équation
    \begin{displaymath}
      a_{\angl{10}\,i}^{(12)} = \frac{1- (1 + i)^{-10}}{i^{(12)}} = 8
    \end{displaymath}
    ou, de manière équivalente,
    \begin{displaymath}
      f(i) = \frac{1 - (1 + i)^{-10}}{12 [(1 + i)^{1/12} - 1]} - 8 = 0.
    \end{displaymath}
    Pour résoudre le problème à l'aide de la méthode du point fixe, on
    peut considérer la fonction
    \begin{displaymath}
      g_1(i) = i - f(i),
    \end{displaymath}
    mais, comme le graphique de la \autoref{fig:resolution:a_angle:g1} le
    montre, la procédure itérative divergera. En posant
    \begin{displaymath}
      \frac{1 - (1 + i)^{-10}}{8} = 12[(1 + i)^{1/12} - 1],
    \end{displaymath}
    puis en isolant $i$ du côté droit de l'équation, on obtient une
    alternative
    \begin{displaymath}
      g_2(i) = \left( \frac{97 - (1 + i)^{-10}}{96} \right)^{12} - 1.
    \end{displaymath}
    Cette fonction satisfait les hypothèses pour l'existence et
    l'unicité d'un point fixe, mais sa pente est toutefois près de 1,
    donc la convergence sera lente; voir la
    \autoref{fig:resolution:a_angle:g2}. Enfin, on peut considérer la
    fonction
    \begin{equation*}
      g_3(i)
      = i - \frac{f(i)}{f^\prime(i)}
    \end{equation*}
    avec
    \begin{equation*}
    f^\prime(i) = \frac{120(1 + i)^{-11}[(1 + i)^{1/12} - 1] - [1 - (1 +
        i)^{-10}](1 + i)^{-11/12}}{144 [(1 + i)^{1/12} - 1]^2}.
    \end{equation*}
    On remarquera que cette dernière est la fonction utilisée dans la
    méthode de Newton--Raphson et sa pente est presque nulle, d'où une
    convergence très rapide; voir la \autoref{fig:resolution:a_angle:g3}.
    \begin{figure}
      \setkeys{Gin}{width=\textwidth}
      \begin{minipage}{0.32\linewidth}
        \centering
<<echo=FALSE, fig=TRUE, height=3, width=3>>=
f0 <- function(x) x
f <- function(i) (1 - (1 + i)^(-10))/(12 * ((1 + i)^(1/12) - 1)) - 8
par(mar = c(2, 2, 2, 2))
curve(x - f(x), xlim = c(-0.005, 0.105), ylim = c(-0.005, 0.105),
      xlab = "i", ylab = "g(i)", lwd = 2)
curve(f0, add = TRUE)
polygon(c(0, 0, 0.1, 0.1), c(0, 0.1, 0.1, 0), lty = 2, border = "blue")
@
        \subcaption{fonction $g_1(x)$ \label{fig:resolution:a_angle:g1}}
      \end{minipage}
      \hfill
      \begin{minipage}{0.32\linewidth}
        \centering
<<echo=FALSE, fig=TRUE, height=3, width=3>>=
g2 <- function(i) ((97 - (1 + i)^(-10))/96)^12 - 1
par(mar = c(2, 2, 2, 2))
curve(g2, xlim = c(-0.005, 0.105), ylim = c(-0.005, 0.105),
      xlab = "i", ylab = "g(i)", lwd = 2)
curve(f0, add = TRUE)
polygon(c(0, 0, 0.1, 0.1), c(0, 0.1, 0.1, 0), lty = 2, border = "blue")
@
        \subcaption{fonction $g_2(x)$ \label{fig:resolution:a_angle:g2}}
      \end{minipage}
      \hfill
      \begin{minipage}{0.32\linewidth}
        \centering
<<echo=FALSE, fig=TRUE, height=3, width=3>>=
fp <- function(i) (120 * (1 + i)^(-11) * ((1 + i)^(1/12) - 1) - (1 - (1 + i)^(-10)) * (1 + i)^(-11/12))/(144 * ((1 + i)^(1/12) - 1)^2)
g3 <- function(i) i - f(i)/fp(i)
par(mar = c(2, 2, 2, 2))
curve(g3, xlim = c(-0.005, 0.105), ylim = c(-0.005, 0.105),
      xlab = "i", ylab = "g(i)", lwd = 2)
curve(f0, add = TRUE)
polygon(c(0, 0, 0.1, 0.1), c(0, 0.1, 0.1, 0), lty = 2, border = "blue")
@
        \subcaption{fonction $g_3(x)$ \label{fig:resolution:a_angle:g3}}
      \end{minipage}
      \caption{Trois fonctions pour résoudre $a_{\angl{10}\, i}^{(12)}
        = 8$ par la méthode du point fixe}
      \label{fig:resolution:a_angle}
      \setkeys{Gin}{width=0.8\textwidth}
    \end{figure}
    On obtient les résultats suivants:
<<echo=TRUE>>=
f <- function(i)
    (1 - (1 + i)^(-10))/(12 * ((1 + i)^(1/12) - 1)) -
    8
fp <- function(i)
    (120 * (1 + i)^(-11) * ((1 + i)^(1/12) - 1) -
     (1 - (1 + i)^(-10)) * (1 + i)^(-11/12)) /
    (144 * ((1 + i)^(1/12) - 1)^2)
g2 <- function(i) ((97 - (1 + i)^(-10))/96)^12 - 1
g3 <- function(i) i - f(i)/fp(i)
pointfixe(g2, start = 0.05)
pointfixe(g3, start = 0.05)
@
  \end{sol}
  \begin{rep}
<<echo=FALSE>>=
xp <- pointfixe(g3, start = 0.05)$fixed.point
@
    $\Sexpr{format(xp, digits = 6, dec = ",")}$
  \end{rep}
\end{exercice}

\begin{exercice}
  Trouver la solution des équations suivantes à l'aide des fonctions R
  appropriées.
  \begin{enumerate}
  \item $x^3 - 2 x^2 - 5 = 0$ pour $1 \leq x \leq 4$
  \item $x^3 + 3 x^2 - 1 = 0$ pour $-4 \leq x \leq 0$
  \item $x - 2^{-x} = 0$ pour $0 \leq x \leq 1$
  \item $e^x + 2^{-x} + 2 \cos x - 6 = 0$ pour $1 \leq x \leq 2$
  \item $e^x - x^2 + 3x - 2 = 0$ pour $0 \leq x \leq 1$
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
\item
<<echo=TRUE,eval=FALSE>>=
f <- function(x) x^3 - 2 * x^2 - 5
uniroot(f, lower = 1, upper = 4)
@
\item Comme un simple graphique le démontre, il y a deux racines dans
  l'intervalle.
<<echo=TRUE,eval=FALSE>>=
f <- function(x) x^3 + 3 * x^2 - 1
curve(f, xlim = c(-4, 0))
uniroot(f, lower = -4, upper = -1)
uniroot(f, lower = -1, upper = 0)
@
\item
<<echo=TRUE,eval=FALSE>>=
f <- function(x) x - 2^(-x)
uniroot(f, lower = 0, upper = 1)
@
\item
<<echo=TRUE,eval=FALSE>>=
f <- function(x) exp(x) + 2^(-x) + 2 * cos(x) - 6
uniroot(f, lower = 1, upper = 2)
@
\item
<<echo=TRUE,eval=FALSE>>=
f <- function(x) exp(x) - x^2 + 3 * x - 2
uniroot(f, lower = 0, upper = 1)
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{exercice:optimisation:optim}
  La fonction de densité de probabilité et la fonction de répartition
  de la loi de Pareto de paramètres $\alpha$ et $\lambda$ sont,
  respectivement,
  \begin{align*}
    f(x)
    &= \frac{\alpha \lambda^\alpha}{(x + \lambda)^{\alpha + 1}} \\
    \intertext{et}
    F(x)
    &= 1 - \left( \frac{\lambda}{x + \lambda} \right)^\alpha.
  \end{align*}
  Calculer les estimateurs du maximum de vraisemblance des paramètres
  de la Pareto à partir d'un échantillon aléatoire obtenu par
  simulation avec la commande
<<echo=TRUE,eval=FALSE>>=
x <- lambda * (runif(100)^(-1/alpha) - 1)
@
  pour des valeurs de \code{alpha} et \code{lambda} choisies.
  \begin{sol}
    On a
<<echo=TRUE,eval=FALSE>>=
dpareto <- function(x, alpha, lambda)
    (alpha * lambda^alpha)/(x + lambda)^(alpha + 1)
f <- function(par, x)
    -sum(log(dpareto(x, par[1], par[2])))
optim(c(1, 1000), f, x = x)
@
    ou, en utilisant l'Astuce Ripley
    (\autoref{sec:resolution:astuce}) consistant à estimer le
    logarithme des paramètres pour éviter les soucis de convergence:
<<echo=TRUE,eval=FALSE>>=
dpareto <- function(x, logAlpha, logLambda)
{
    alpha <- exp(logAlpha)
    lambda <- exp(logLambda)
    (alpha * lambda^alpha)/(x + lambda)^(alpha+1)
}
optim(c(log(2), log(1000)), f, x = x)
exp(optim(c(log(2), log(1000)), f, x = x)$par)
@
  \end{sol}
\end{exercice}

\Closesolutionfile{reponses}
\Closesolutionfile{solutions}

\input{reponses-resolution_equations}

%%% Local Variables:
%%% engine: xetex
%%% TeX-master: "methodes-numeriques-en-actuariat_analyse-numerique"
%%% coding: utf-8
%%% End:
