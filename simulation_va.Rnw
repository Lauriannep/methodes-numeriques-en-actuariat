\chapter{Simulation de variables aléatoires}
\label{chap:simulation_va}

\begin{objectifs}
\item
\end{objectifs}

Habituellement, les applications de la simulation requièrent des
nombres aléatoires provenant non pas d'une distribution $U(0, 1)$,
mais plutôt d'une (ou plusieurs) distribution avec fonction de
répartition $F_X(x)$.

Il existe de très nombreux algorithmes pour générer des nombres
aléatoires de différentes distributions; voir
\cite{Devroye:random:1986}. Nous n'en étudierons que deux en détail:
\begin{enumerate}
\item méthode de l'inverse;
\item mélange de distributions.
\end{enumerate}
D'autres méthodes seront néanmoins mentionnées à la section
\ref{sec:simulation_va:melanges}.


\section{Méthode de l'inverse}
\label{sec:simulation_va:inverse}


\subsection{Distributions continues}
\label{sec:simulation_va:inverse:continues}

On peut transformer des nombres uniformes sur $(0, 1)$ en des nombres
provenant de la distribution avec fonction de répartition $F_X(x)$ en
utilisant le théorème suivant.

\begin{thm}
  Soit $X$ une variable aléatoire avec fonction de répartition
  $F_X(x)$. Alors
  \begin{displaymath}
    F_X(X) \sim U(0, 1).
  \end{displaymath}
\end{thm}
\begin{proof}
  Soit la transformation $U = F_X(X)$. Alors,
  \begin{align*}
    F_U(u)
    &= \Pr[U \leq u] \\
    &= \Pr[F_X(X) \leq u] \\
    &= \Pr[X \leq F_X^{-1}(u)] \\
    &= F_X(F_X^{-1}(u)) \\
    &= u,
  \end{align*}
  d'où $U \sim U(0, 1)$.
\end{proof}

Par conséquent, si $U \sim U(0, 1)$, alors
\begin{displaymath}
  F_X^{-1}(U) \sim X.
\end{displaymath}
Cette méthode fonctionne parce qu'il y aura plus de valeurs de $x$
simulées là où la pente de la fonction de répartition est la plus
grande. Graphiquement:
\begin{center}
  \SweaveOpts{width=6,height=3}
<<echo=FALSE,fig=TRUE>>=
par(mfrow = c(1, 2), mar = c(5, 4, 1, 1))

## Graphique de fonction de répartition
plot(NA, xlim = c(0, 14), ylim = c(0, 1),
     xlab = expression(x), ylab = expression(F[X](x)),
     xaxs="i", yaxs="i")
u <- c(0.3, 0.4, 0.8, 0.9)
x <- qgamma(u, 5, 1)
polygon(c(0, x[1], x[1], x[2], x[2], 0),
        c(u[1], u[1], 0, 0, u[2], u[2]), col="gray")
polygon(c(0, x[3], x[3], x[4], x[4], 0),
        c(u[3], u[3], 0, 0, u[4], u[4]), col="gray")
curve(pgamma(x, 5, 1), add=TRUE)

## Graphique de la densité
plot(NA, xlim = c(0, 14), ylim = c(0, 0.2),
     xlab = expression(x), ylab = expression(f[X](x)),
     xaxs = "i", yaxs = "i")
xx <- seq(from = x[1], to = x[2], length = 100)
polygon(c(xx[1], xx, xx[100]), c(0, dgamma(xx, 5, 1), 0), col = "gray")
xx <- seq(from = x[3], to = x[4], length = 100)
polygon(c(xx[1], xx, xx[100]), c(0, dgamma(xx, 5, 1), 0), col = "gray")
curve(dgamma(x, 5, 1), xlim = c(0, 14), add=TRUE)
@
\end{center}


\begin{rems}
  \begin{enumerate}
  \item La méthode de l'inverse en est une bonne si $F_X^{-1}(\cdot)$
    est facile à calculer.
  \item Problème: il y a en fait peu de lois de probabilité continues
    dont la fonction de répartition est simple à inverser
    (exponentielle, Pareto, Weibull, ...) Il faut parfois utiliser
    d'autres méthodes.
  \item Néanmoins, s'il n'y a pas de forme explicite pour
    $F_X^{-1}(\cdot)$, résoudre numériquement
    \begin{displaymath}
      F_X(x) - u = 0
    \end{displaymath}
    peut s'avérer aussi efficace que bien d'autres méthodes.
  \item Dans Excel (et VBA), on doit nécessairement utiliser la
    méthode de l'inverse. Plusieurs fonctions de quantiles sont
    disponibles (section \ref{sec:simulation_va:excel_et_al}).
  \end{enumerate}
\end{rems}

\begin{exemple}
  On veut obtenir un échantillon aléatoire d'une distribution
  exponentielle de paramètre $\lambda$ avec fonction de densité de
  probabilité
  \begin{align*}
    f(x)
    &= \lambda e^{-\lambda x}, \quad x > 0 \\
    \intertext{et fonction de répartition}
    F(x)
    &= 1 - e^{-\lambda x}, \quad x > 0.
  \end{align*}
  Or,
  \begin{displaymath}
    F^{-1}(u) = - \frac{1}{\lambda} \ln (1 - u),
  \end{displaymath}
  donc
  \begin{displaymath}
    X = - \frac{1}{\lambda} \ln (1 - U) \sim \text{Exponentielle}(\lambda),
  \end{displaymath}
  où $U \sim U(0, 1)$. En fait, puisque
  \begin{displaymath}
    U \sim U(0, 1) \quad \Leftrightarrow\quad 1 - U \sim U(0, 1),
  \end{displaymath}
  on peut se contenter de la relation
  \begin{displaymath}
    X \sim - \frac{1}{\lambda} \ln U \sim \text{Exponentielle}(\lambda).
  \end{displaymath}
  Par conséquent, l'algorithme pour simuler des nombres provenant
  d'une exponentielle de paramètre $\lambda$ est:
  \begin{enumerate}
  \item Obtenir un nombre $u$ d'une $U(0, 1)$;
  \item Poser $x = - \lambda^{-1} \ln u$.
  \end{enumerate}

  \normalfont
  \lstinputlisting{exemple_3.1.R}
  \qed
\end{exemple}


\subsection{Distributions discrètes}
\label{sec:simulation_va:inverse:discretes}

On peut aussi utiliser la méthode de l'inverse avec les distributions
discrètes. Cependant, puisque la fonction de répartition comporte des
sauts, son inverse n'existe pas formellement. Par conséquent, il
n'existe pas de solution de $u = F_X(x)$ pour certaines valeurs de
$u$, ou alors une infinité de solutions.

Supposons une distribution avec un saut en $x_0$:
\begin{center}
  \begin{minipage}[b]{0.35\linewidth}
    \begin{align*}
      F_X(x_0^-) &= a \\
      F_X(x_0) &= b > a.
    \end{align*}
  \end{minipage}
  \hfill
  \begin{minipage}{0.6\linewidth}
<<echo=FALSE,fig=TRUE, width=3.5, height=2.33>>=
par(mar = c(2, 2, 0, 0))
plot(NA, xlim = c(0, 5), ylim = c(0, 1.04),
     xlab = "", ylab = "",
     xaxs="i", yaxs="i", xaxt = "n", yaxt = "n")
x <- 0:4
for (i in x)
    points(c(i, i + 1), rep(pbinom(i, 4, 0.6), 2),
           type = "o", pch = c(19, 1))
segments(2, 0, 2, pbinom(2, 4, 0.6), lty = 2)
u <- runif(1, 0.3, 0.5)
arrows(0, u, 2, u, length = 0.125)
axis(1, at = 2:3, label = expression(x[0], x[1]))
axis(2, at = c(0, u, pbinom(1:2, 4, 0.6), 1), label = c(0, "u", "a", "b", 1))
@
  \end{minipage}
\end{center}

\begin{itemize}
\item si $a < u < b$, poser $x = x_0$
\item $x_0$ sera simulé dans une proportion $b - a$ du temps, ce qui
  correspond à $\Pr[X = x_0]$.
\end{itemize}

Que faire si $u = a$ ou $u = b$? On prend la plus grande valeur de
l'intervalle où $F_X(x)$ est constante:
\begin{align*}
  u = a  &\Rightarrow x = x_0 \\
  u = b  &\Rightarrow x = x_1.
\end{align*}
On procède ainsi parce que plusieurs générateurs produisent des
nombres uniformes sur $[0, 1)$.

\begin{exemple}
  Soit $X$ une variable aléatoire avec fonction de densité de probabilité
  \begin{center}
    \begin{minipage}[b]{0.45\linewidth}
      \begin{displaymath}
        f(x) =
        \begin{cases}
          0,5, & 0 \leq x < 1 \\
          0,   & 1 \leq x < 2 \\
          0,5, & 2 \leq x < 3.
        \end{cases}
      \end{displaymath}
    \end{minipage}
    \hfill
    \begin{minipage}[c]{0.45\linewidth}
<<echo=FALSE,fig=TRUE, width=6, height=4>>=
par(mar = c(5, 4, 1, 1))
plot(NA, xlim = c(0, 3), ylim = c(0, 1),
     xlab = expression(x), ylab = expression(f[X](x)),
     xaxt = "n", yaxt = "n")
points(c(0, 1), rep(0.5, 2), type = "o", pch = c(19, 1))
points(c(1, 2), rep(0, 2), type = "o", pch = c(19, 1))
points(c(2, 3), rep(0.5, 2), type = "o", pch = c(19, 1))
axis(1, at = 0:3)
axis(2, at = 0:2/2)
@
    \end{minipage}
  \end{center}

  On a une variable aléatoire \emph{mixte} (en partie continue et en
  partie continue) dont la fonction de répartition est
  \begin{center}
    \begin{minipage}[b]{0.45\linewidth}
      \begin{displaymath}
        F(x) =
        \begin{cases}
          0,5x, & 0 \leq x < 1 \\
          0,5   & 1 \leq x < 2 \\
          0,5x - 0,5, & 2 \leq x < 3.
        \end{cases}
      \end{displaymath}
    \end{minipage}
    \hfill
    \begin{minipage}[c]{0.45\linewidth}
<<echo=FALSE, fig=TRUE, width=6, height=4>>=
par(mar = c(5, 4, 1, 1))
plot(0:3, c(0, 0.5, 0.5, 1), type = "o", pch = 19,
     xlab = expression(x), ylab = expression(F[X](x)),
     xaxt = "n", yaxt = "n")
axis(1, at = 0:3)
axis(2, at = 0:2/2)
@
    \end{minipage}
  \end{center}
  Par conséquent, un algorithme pour simuler des nombres aléatoires de
  cette distribution est:
  \begin{enumerate}
  \item Obtenir un nombre $u$ d'une loi $U(0, 1)$.
  \item Poser
    \begin{displaymath}
      x =
      \begin{cases}
        2u,    & \text{si } 0 \leq u < 1 \\
        2,     & \text{si } u = 0,5 \\
        2u + 1 & \text{si } 0,5 < u < 1.
      \end{cases}
    \end{displaymath}
  \end{enumerate}
  \qed
\end{exemple}

\begin{exemple}
  On veut simuler des observations d'une distribution binomiale de
  paramètres $n$ et $\theta$.

  On pourrait, pour chaque $x$ simulé, faire $n$ expériences de
  Bernoulli et compter le nombre de succès. Par la méthode de
  l'inverse, on a un succès dans une expérience de Bernoulli si $u
  \leq \theta$. Par conséquent:
  \begin{enumerate}
  \item Simuler $n$ nombres uniformes indépendants $u_1, \dots, u_n$
    d'une loi $U(0, 1)$.
  \item Poser
    \begin{displaymath}
      x = \sum_{i = 1}^n I\{u_i \leq \theta\}.
    \end{displaymath}
  \end{enumerate}
  Cette technique requiert toutefois de simuler $n$ nombres uniformes
  pour chaque valeur de $x$.

  On peut aussi utiliser la méthode de l'inverse directement avec la
  distribution binomiale. Avec $n = 4$ et $\theta = 0,5$, on a
  \begin{align*}
    \Pr[X = x]
    &=
    \begin{cases}
      0,0625, & x = 0 \\
      0,25,   & x = 1 \\
      0,375,  & x = 2 \\
      0,25,   & x = 3 \\
      0,0625, & x = 4
    \end{cases} \\
    \intertext{et}
    \Pr[X \leq x]
    &=
    \begin{cases}
      0,      & x < 0 \\
      0,0625, & 0 \leq x < 1 \\
      0,3125, & 1 \leq x < 2 \\
      0,6875, & 2 \leq x < 3 \\
      0,9375, & 3 \leq x < 4 \\
      1,      & x \geq 4,
    \end{cases}
  \end{align*}
  d'où l'algorithme suivant:
  \begin{enumerate}
  \item Simuler un nombre $u$ d'une distribution $U(0, 1)$.
  \item Déterminer $x$ selon le tableau suivant:
    \begin{center}
      \begin{tabular}{lc}
        \toprule
        $u$ dans l'intervalle & Valeur de $x$ \\
        \midrule
        $[0, 0,0625)$         & $0$ \\
        $[0,0625, 0,3125)$    & $1$ \\
        $[0,3125, 0,6875)$    & $2$ \\
        $[0,6875, 0,9375)$    & $3$ \\
        $[0,9375, 1)$         & $4$ \\
        \bottomrule
      \end{tabular}
    \end{center}
  \end{enumerate}
  \qed
\end{exemple}

\begin{rem}
  La méthode de l'inverse pour les distributions discrètes à support
  fini est facile à mettre en oeuvre dans Excel avec la fonction
  \texttt{RECHERCHEV()}.
\end{rem}


\section{Méthode acceptation-rejet}

Supposons qu'il est compliqué de simuler des réalisations de la
variable aléatoire $X$ avec fonction de densité de probabilité
$f_X(x)$. Si on peut trouver une variable aléatoire $Y$ avec fonction
de densité de probabilité $g_Y(x)$ pour laquelle la simulation est
simple (uniforme, triangle, exponentielle, etc.) et que
\begin{displaymath}
  c g_Y(x) \geq f_X(x)
\end{displaymath}
pour tout $x$, alors on a l'algorithme d'acceptation-rejet suivant:
\begin{enumerate}
\item Générer une réalisation $y$ de la variable aléatoire $Y$ avec
  f.d.p.\ $g_Y(\cdot)$.
\item Générer un nombre $u$ d'une $U(0, 1)$.
\item Si
  \begin{displaymath}
    u \leq \frac{f_X(y)}{c g_Y(y)},
  \end{displaymath}
  poser $x = y$. Sinon, retourner à l'étape 1.
\end{enumerate}

L'idée consiste à accepter la «bonne proportion» des réalisations de
$Y$ comme provenant de $X$:
\begin{center}
<<echo=FALSE, fig=TRUE, height=4.5>>=
par(mar = c(3, 3, 1, 1))
plot(NA, xlim = c(0, 1), ylim = c(0, 2), xlab = "", ylab = "")
m <- dbeta(2/3, 3, 2)
x <- c(0.22, 0.58, 0.83)
segments(x, 0, x, dbeta(x, 3, 2), col = "green3", lwd = 3)
segments(x, dbeta(x, 3, 2), x, m, col = "red3", lwd = 3)
curve(dbeta(x, 3, 2), xlim = c(0, 1), add = TRUE, lwd = 2)
segments(0, 0, 0, m)
segments(1, 0, 1, m)
segments(0, m, 1, m, col = "blue3", lwd = 2)
text(0.2, m + 0.075, "c g(y)")
text(0.4, 1.5, "f(y)")
@
\end{center}

\begin{rems}
  \begin{enumerate}
  \item La principale difficulté avec cette méthode consiste à trouver
    la fonction enveloppante.
  \item Évidemment, plus $c g_Y(x)$ est près de $f_X(x)$, plus
    l'algorithme est performant.
  \end{enumerate}
\end{rems}

\begin{exemple}
  Soit $X \sim \text{Bêta}(3, 2)$. On a
  \begin{align*}
    f_X(x)
    &= \frac{\Gamma(5)}{\Gamma(3) \Gamma(2)}\,
    x^{3 - 1} (1 - x)^{2 - 1} \\
    &= 12 x^2 (1 - x), \quad 0 < x < 1.
  \end{align*}
  On peut inscrire la densité $f(x)$ dans un triangle aux
  caractéristiques suivantes (voir la figure
  \ref{fig:simulation_va:beta-triangle}):
  \begin{itemize}
  \item côté gauche
    \begin{enumerate}
    \item passe par $(0, 0) \Rightarrow y = mx$;
    \item $y = mx$ tangent à $f(x)$ $\Rightarrow$ $m$ tel que
      l'équation $mx = 12 x^2 (1 - x)$ a une seule racine autre que 0
      $\Rightarrow y = 3 x$;
    \end{enumerate}
  \item côté droit
    \begin{enumerate}
    \item passe par $(1, 0) \Rightarrow y = mx + b$ avec $m + b = 0$;
    \item pente égale à la pente de $f(x)$ en $x = 1$ $\Rightarrow y =
      12 - 12 x$.
    \end{enumerate}
  \end{itemize}
  \begin{figure}
    \centering
<<echo=FALSE, fig=TRUE, height=4>>=
par(mar = c(5, 4, 1, 1))
curve(dbeta(x, 3, 2), xlim = c(0, 1), ylim = c(0, 2.5), lwd = 2)
lines(c(0, 0.8, 1), c(0, 2.4, 0), lwd = 1)
segments(0.5, 0, 0.5, 1.5, lty = 2)
segments(0.8, 0, 0.8, 2.4, lty = 2)
axis(side = 1, at = 0.5)
@
    \caption{Fonction de densité de probabilité d'une loi Bêta$(3, 2)$
      enveloppée d'un triangle}
    \label{fig:simulation_va:beta-triangle}
  \end{figure}
  Par conséquent,
  \begin{displaymath}
    c g_Y(x) =
    \begin{cases}
      3x,       & 0 < x < 0,8 \\
      12 - 12 x, & 0,8 < x < 1.
    \end{cases}
  \end{displaymath}
  Or, l'aire du triangle est
  \begin{displaymath}
    \frac{(1) c g_Y(0,8)}{2} = \frac{(1)(2,4)}{2} = 1,2,
  \end{displaymath}
  d'où $c = 1,2$. Ainsi,
  \begin{align*}
    g_Y(x)
    &=
    \begin{cases}
      2,5 x,     & 0 < x < 0,8 \\
      10 - 10 x, & 0,8 < x < 1,
    \end{cases} \\
    G_Y(x)
    &=
    \begin{cases}
      1,25 x^2,          & 0 < x < 0,8 \\
      -5 x^2 + 10 x - 4, & 0,8 < x < 1,
    \end{cases} \\
    \intertext{d'où}
    G_Y^{-1}(y)
    &=
    \begin{cases}
      \sqrt{0,8 y},           & 0 < y < 0,8 \\
      1 - \sqrt{0,2 - 0,2 y}, & 0,8 < y < 1.
    \end{cases}
  \end{align*}
  On a donc l'algorithme suivant:
  \begin{enumerate}
  \item Simuler deux nombres $u_1$ et $u_2$ d'une $U(0, 1)$.
  \item Poser $y = G_Y^{-1}(u_1)$.
  \item Si
    \begin{displaymath}
      u_2 \leq \frac{f_X(y)}{1,2 g_Y(y)} \Leftrightarrow
      1,2 g_Y(y) u_2 \leq f_X(y),
    \end{displaymath}
    alors poser $x = y$. Sinon, retourner à l'étape 1.
  \end{enumerate}
  \qed
\end{exemple}


\section{Fonctions de simulation de variables aléatoires dans Excel,
  VBA et \textsf{R}}
\label{sec:simulation_va:excel_et_al}

Il est important de savoir simuler des valeurs d'une variable
aléatoire quelconque à partir de la méthode de l'inverse ou d'un autre
algorithme, surtout lorsque la distribution de la variable aléatoire
est peu usitée. Néanmoins, les différents outils statistiques à notre
disposition nous fournissent en général la majorité des fonctions de
simulation de variables aléatoires dont on peut avoir besoin pour un
usage quotidien.


\subsection{Excel et VBA}

Tel que mentionné à la section 3.1, il faut généralement utiliser la
méthode de l'inverse pour simuler des observations de lois de
probabilité dans Excel. Cette procédure est facilitée par le fait
qu'il existe des fonctions Excel pour calculer la fonction de
répartition inverse (ou fonction de quantile) des lois les plus
courantes.

Ainsi, on trouvera dans Excel la fonction de densité de probabilité
(lois continues) ou la fonction de masse de probabilité (lois
discrètes) et/ou la fonction de répartition et, dans certains cas
seulement, la fonction quantile des lois de probabilité présentées au
tableau \ref{tab:excel}. On remarquera que la logique s'était absentée
lorsque les traducteurs français ont fait leur travail.

\begin{table}
  \centering
  \begin{tabular}{p{18ex}p{36ex}p{18ex}}
    \toprule
    Loi de probabilité &
    Fonctions Excel (nom français) &
    Fonctions Excel \newline (nom anglais)  \\
    \midrule
    Bêta &
    \texttt{LOI.BETA()} \newline \texttt{BETA.INVERSE()} &
    \texttt{BETADIST()} \newline \texttt{BETAINV()} \\
    Binomiale &
    \texttt{LOI.BINOMALE()} \newline \texttt{CRITERE.LOI.BINOMIALE()} &
    \texttt{BINOMDIST()} \newline \texttt{CRITBINOM()}\\
    Binomiale négative &
    \texttt{LOI.BINOMIALE.NEG()} &
    \texttt{NEGBINOMDIST()}\\
    Exponentielle &
    \texttt{LOI.EXPONENTIELLE()} &
    \texttt{EXPONDIST()}\\
    \emph{F} (Fisher) &
    \texttt{LOI.F()} \newline \texttt{INVERSE.LOI.F()} &
    \texttt{FDIST()} \newline \texttt{FINV()}\\
    Gamma &
    \texttt{LOI.GAMMA()} \newline \texttt{LOI.GAMMA.INVERSE()} &
    \texttt{GAMMADIST()} \newline \texttt{GAMMAINV()}\\
    Hypergéométrique &
    \texttt{LOI.HYPERGEOMETRIQUE()} &
    \texttt{HYPERGEOMDIST()}\\
    Khi carré &
    \texttt{LOI.KHIDEUX()} \newline \texttt{KHIDEUX.INVERSE()} &
    \texttt{CHIDIST()} \newline \texttt{CHIINV()}\\
    Log-normale &
    \texttt{LOI.LOGNORMALE()} \newline \texttt{LOI.LOGNORMALE.INVERSE()}&
    \texttt{LOGNORMDIST()} \newline \texttt{LOGINV()}\\
    Normale &
    \texttt{LOI.NORMALE()} \newline
    \texttt{LOI.NORMALE.INVERSE()} \newline
    \texttt{LOI.NORMALE.STANDARD()} \newline
    \texttt{LOI.NORMALE.STANDARD.INVERSE()} &
    \texttt{NORMDIST()} \newline \texttt{NORMINV()} \newline
    \texttt{NORMSDIST()} \newline \texttt{NORMSINV()} \\
    Poisson &
    \texttt{POISSON()} &
    \texttt{POISSON()} \\
    \emph{t} (Student) &
    \texttt{LOI.STUDENT()} \newline \texttt{LOI.STUDENT.INVERSE()} &
    \texttt{TDIST()} \newline \texttt{TINV()}\\
    Weibull &
    \texttt{LOI.WEIBULL()} &
    \texttt{WEIBULL()}\\
    \bottomrule
  \end{tabular}
  \caption{Lois de probabilité pour lesquelles existent des fonctions
    dans Excel 2003.}
  \label{tab:excel}
\end{table}

Aucune fonction statistique n'existe dans VBA. On fera donc appel aux
fonctions de Excel en préfixant les noms de fonctions \emph{anglais}
du tableau \ref{tab:excel} de \texttt{WorksheetFunction}. En utilisant
une structure
\begin{verbatim}
With WorksheetFunction
    ...
End With
\end{verbatim}
dans une routine VBA, il est également possible accéder directement
aux fonctions Excel en les préfixant seulement d'un point.


\subsection{\textsf{R}}

Consulter le chapitre~8 de \cite{Goulet:introS:2007} pour une
description des fonctions de simulation de variables aléatoires dans
\textsf{R}.


% \section{Mélanges}
% \label{sec:simulation_va:melanges}

% \subsection{Mélanges continus}
% \label{sec:simulation_va:melanges:continus}

% Il est fréquent en analyse bayesienne de supposer que un (ou, plus
% rarement, plusieurs) paramètre d'une distribution $f$ est une
% réalisation d'une autre variable aléatoire. On a donc
% \begin{align*}
%   X|\Theta = \theta &\sim f(x|\theta) \\
%   \Theta &\sim u(\theta).
% \end{align*}
% La distribution marginale (non conditionnelle) de la variable
% aléatoire $X$ est un \emph{mélange}.

% Par la loi des probabilités totales,
% \begin{displaymath}
%   f(x) = \int_{-\infty}^\infty f(x|\theta) u(\theta)\, d\theta.
% \end{displaymath}

% Les mélanges sont utiles pour créer de nouvelles distributions ou pour
% simuler des distributions connues. L'algorithme pour obtenir une
% observation de la distribution non conditionnelle de $X$ est:
% \begin{enumerate}
% \item Simuler un nombre $\theta$ de la distribution de $\Theta$.
% \item Simuler une valeur $x$ de la distribution de $X|\Theta =
%   \theta$.
% \end{enumerate}

% \begin{exemple}
%   Soit
%   \begin{align*}
%     X|\Theta = \theta &\sim \text{Poisson}(\theta) \\
%     \Theta &\sim \text{Gamma}(\alpha, \lambda).
%   \end{align*}
%   On peut démontrer que
%   \begin{displaymath}
%     X \sim \text{Binomiale négative}
%     \left(
%       \alpha, \frac{\lambda}{\lambda + 1}
%     \right).
%   \end{displaymath}
%   On peut donc simuler des observations d'une binomiale négative de
%   paramètres $r = 5$ et $\theta = 0,8$ en répétant les étapes
%   suivantes autant de fois que nécessaire:
%   \begin{enumerate}
%   \item Simuler une observation $\theta$ d'une loi Gamma$(5, 4)$.
%   \item Simuler une observation $x$ d'une loi de Poisson$(\theta)$.
%   \end{enumerate}
%   \qed
% \end{exemple}


% \subsection{Mélanges discrets}
% \label{sec:simulation_va:melanges:discrets}

% Le cas limite d'un mélange continu est lorsque $\Theta \sim
% \text{Bernouilli}(p)$, c'est-à-dire
% \begin{displaymath}
%   u(\theta) =
%   \begin{cases}
%     p,     & \theta = 1 \\
%     1 - p, & \theta = 0.
%   \end{cases}
% \end{displaymath}
% Si on suppose que la densité de $X|\Theta = 1$ est $f_1(x)$ et que
% celle de $X|\Theta = 0$ est $f_2(x)$, on a alors
% \begin{align*}
%   f(x)
%   &= \int_{-\infty}^\infty f(x|\theta) u(\theta)\, d\theta \\
%   &= p f_1(x) + (1 - p) f_2(x).
% \end{align*}

% De tels mélanges discrets sont très souvent utilisés pour créer de
% nouvelles distributions aux caractéristiques particulières que l'on ne
% retrouve pas chez les distributions d'usage courant.

% Par exemple, la figure \ref{fig:simulation_va:ln.ln} montre qu'un
% mélange de deux distributions log-normales peut résulter en une
% fonction de densité de probabilité bimodale, mais ayant néanmoins une
% queue similaire à celle d'une log-normale.

% \begin{figure}
%   \centering
% <<echo=FALSE, fig=TRUE>>=
% par(mfrow=c(3, 1), lwd=1)
% titre1 <- expression(paste("Log-normale(", mu, " = 3,575, ", sigma, " = 0,637)"))
% titre2 <- expression(paste("Log-normale(", mu, " = 4,555, ", sigma, " = 0,265)"))
% titre3 <- expression(paste("Mélange"))
% curve(dlnorm(x, 3.575, 0.637), xlim = c(0, 250),
%       main = titre1, ylab = "f(x)")
% curve(dlnorm(x, 4.555, 0.265), xlim = c(0, 250),
%       main = titre2, ylab = "f(x)")
% curve(0.554 * dlnorm(x, 3.575, 0.637) + 0.446 * dlnorm(x, 4.555, 0.265), xlim = c(0, 250),
%       main = titre3, ylab = "f(x)")
% @
%   \caption{Fonctions de densité de probabilité de deux log-normales et
%     de leur mélange}
%   \label{fig:simulation_va:ln.ln}
% \end{figure}

% À la figure \ref{fig:simulation_va:pois.nbinom}, on a créé une distribution en
% mélangeant une loi de Poisson avec une distribution binomiale négative
% avec un paramètre $r < 1$. Il en résulte une distribution similaire à
% la Poisson, mais avec une queue sensiblement plus lourde: le maximum
% effectif (le 99,999\ieme{} quantile pour être plus précis) de la
% distribution est ainsi basé de 10 dans le cas de la Poisson pure, à
% près de 58 dans le mélange.

% \begin{figure}
%   \centering
% <<echo=FALSE, eval=FALSE, fig=TRUE>>=
% par(mfrow = c(3, 1), lwd = 1)
% x <- 0:20
% titre1 <- expression(paste("Poisson(2)"))
% titre2 <- expression(paste("Binomiale négative(0,3, 0,035)"))
% titre3 <- expression(paste("Mélange"))
% plot(x, dpois(x, 2), type="h", main=titre1, ylab="f(x)")
% plot(x, dnbinom(x, 0.3, prob = 0.035), type = "h", main = titre2, ylab = "f(x)")
% plot(x, 0.8 * dpois(x, 2) + 0.2 * dnbinom(x, 0.3, prob=0.035), type = "h",
%      main = titre3, ylab = "f(x)")
% @
%   \caption{Fonctions de probabilité d'une Poisson, d'une binomiale
%     négative et de leur mélange}
%   \label{fig:simulation_va:pois.nbinom}
% \end{figure}

% La procédure pour simuler un nombre d'un mélange discret est simple:
% dans $100p$~\% des cas le nombre doit provenir de la distribution
% $f_1(x)$ et dans $100(1 - p)$~\% de la distribution $f_2(x)$.
% L'algorithme est donc:
% \begin{enumerate}
% \item Simuler un nombre $u$ uniforme sur $(0, 1)$;
% \item Si $u \leq p$, simuler un nombre de $f_1(x)$, sinon simuler de
%   $f_2(x)$.
% \end{enumerate}

% \begin{rem}
%   Il est important de faire la différence entre un mélange discret et
%   la variable aléatoire
%   \begin{displaymath}
%     X = p X_1 + (1 - p) X_2,
%   \end{displaymath}
%   où $X_1$ et $X_2$ sont des variables aléatoires avec fonction de
%   densité de probabilité $f_1(x)$ et $f_2(x)$, respectivement. Cette
%   définition signifie que la valeur de la variable aléatoire $X$ est
%   formée à $100p$~\% de celle de $X_1$ et à $100(1 - p)$~\% de celle
%   de $X_2$. On simulerait donc un nombre de $X$ en simulant un nombre
%   $x_1$ de $X_1$ et un nombre $x_2$ de $X_2$, puis en posant $x = p
%   x_1 + (1 - p) x_2$.
% \end{rem}


% % \subsection{Convolution}
% % \label{sec:simulation_va:autres:convolution}

% % Soit $X$ et $Y$ deux variables aléatoires indépendantes et
% % \begin{displaymath}
% %   Z = X + Y.
% % \end{displaymath}
% % Alors $Z$ est appelée la \emph{convolution} de $X$ et $Y$. On démontre
% % facilement que
% % \begin{displaymath}
% %   f_Z(x) = \int_{-\infty}^\infty f_X(x - y) g_Y(y)\, dy.
% % \end{displaymath}

% % De manière générale, une convolution est \emph{très} compliquée à
% % évaluer, même numériquement. Certaines convolutions sont toutefois
% % bien connues:
% % \begin{center}
% %   \begin{tabular}{ll}
% %     \toprule
% %     Somme de & donne \\
% %     \midrule
% %     $n$ Bernoulli$(p)$ & binomiale$(n, p)$ \\
% %     $r$ géométrique$(\theta)$ & binomiale négative$(r, \theta)$ \\
% %     $\alpha$ exponentielle$(\lambda)$ & gamma$(\alpha, \lambda)$ \\
% %     $n$ Poisson$(\lambda_i)$ & Poisson$(\sum_{i = 1}^n \lambda_i)$ \\
% %     $n$ normale$(\mu_i, \sigma_i^2)$ & normale$(\sum_{i = 1}^n \mu_i,
% %     \sum_{i = 1}^n \sigma_i^2)$ \\
% %     \bottomrule
% %   \end{tabular}
% % \end{center}

% % Ces résultats peuvent être utilisés pour générer des observations de
% % certaines distributions.

% % \begin{exemple}
% %   Pour simuler des observations d'une distribution Gamma$(\alpha,
% %   \lambda)$ avec $\alpha$ entier, on peut simplement sommer $\alpha$
% %   observations d'une exponentielle$(\lambda)$:
% %   \begin{enumerate}
% %   \item Simuler $\alpha$ nombres uniformes indépendants $u_1, \dots,
% %     u_\alpha$ d'une $U(0, 1)$.
% %   \item Poser
% %     \begin{displaymath}
% %       x = - \frac{1}{\lambda} \sum_{i = 1}^\alpha \ln u_i.
% %     \end{displaymath}
% %   \end{enumerate}
% %   \qed
% % \end{exemple}

% % La simulation peut aussi servir à estimer des caractéristiques de la
% % distribution d'une convolution difficiles à calculer explicitement.

% % \begin{exemple}
% %   Soit $X \sim \text{Gamma}(\alpha_1, \lambda_1)$ et $Y \sim
% %   \text{Gamma}(\alpha_2, \lambda_2)$. On souhaite calculer le
% %   95{\ieme} centile de $X + Y$.

% %   Si $\lambda_1 \neq \lambda_2$, trouver la distribution de $X + Y$
% %   est compliqué (pas de solution explicite).

% %   On va donc \emph{estimer} le 95{\ieme} centile théorique par le
% %   95{\ieme} centile empirique d'un grand échantillon simulé.

% %   \begin{enumerate}
% %   \item Simuler $n$ nombres $x_1, \dots, x_n$ d'une Gamma$(\alpha_1,
% %     \lambda_1)$.
% %   \item Simuler $n$ nombres $y_1, \dots, y_n$ d'une Gamma$(\alpha_1,
% %     \lambda_1)$.
% %   \item Poser $z_i = x_i + y_i$, $i = 1, \dots, n$.
% %   \item Trouver le 95{\ieme} centile empirique de l'échantillon
% %     $\{z_1, \dots, z_n\}$, c'est-à-dire le point $z^*$ tel que
% %     \begin{displaymath}
% %       \frac{\# z_i \leq z^*}{n} = 0,95.
% %     \end{displaymath}
% %   \end{enumerate}

% %   \begin{commentaire}
% %     Compléter l'exemple en \textsf{R} (code ci-dessous) ainsi qu'en
% %     Excel (fichier \verb|exemple_3.7.xls|).
% %   \end{commentaire}
% % <<echo=TRUE>>=
% % x <- rgamma(10000, 3, 4)
% % y <- rgamma(10000, 5, 2)
% % quantile(x + y, 0.95)
% % @
% %   \qed
% % \end{exemple}


\section{Intégration Monte Carlo}
\label{sec:simulation_va:montecarlo}

On appelle simulation Monte Carlo (ou méthode de Monte Carlo) toute
méthode consistant à résoudre une expression mathématique à l'aide de
nombres aléatoires. Par extension, l'appellation est souvent utilisée
pour référer à toute utilisation de la simulation.

L'une des utilisations de la simulation Monte Carlo la plus répandue
est le calcul d'intégrales, principalement pour des dimensions
supérieures à un. On ne présente ici que l'idée générale.

Supposons que l'on souhaite calculer l'intégrale
\begin{displaymath}
  \theta = \int_a^b h(x)\, dx,
\end{displaymath}
mais que celle-ci est trop compliquée pour être évaluée explicitement.
On pourrait l'estimer numériquement par la moyenne de deux sommes de
Riemann:
\begin{center}
  \begin{minipage}{0.45\linewidth}
    \begin{displaymath}
      R_n^- = \sum_{k = 0}^{n - 1} h(a + k \Delta x) \Delta x,
    \end{displaymath}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
<<echo=FALSE,fig=TRUE,height=4>>=
par(mar = c(1, 0, 1, 0))
curve(dgamma(x, 3, 2), xlim = c(0, 2), lwd = 2,
      xaxt = "n", yaxt = "n")
xx <- seq(0, 2, by = 0.2)
lines(xx, dgamma(xx, 3, 2), type = "s")
segments(xx, 0, xx, dgamma(xx, 3, 2))
@
  \end{minipage}
  \newline
  \begin{minipage}{0.45\linewidth}
    \begin{displaymath}
      R_n^+ = \sum_{k = 1}^n h(a + k \Delta x) \Delta x,
    \end{displaymath}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\linewidth}
<<echo=FALSE,fig=TRUE,height=4>>=
par(mar = c(1, 0, 1, 0))
curve(dgamma(x, 3, 2), xlim = c(0, 2), lwd = 2,
      xaxt = "n", yaxt = "n")
xx <- seq(0, 2, by = 0.2)
lines(xx, dgamma(xx, 3, 2), type = "S")
segments(xx, 0, xx, dgamma(xx, 3, 2))
@
  \end{minipage}
\end{center}
(où $\Delta x = (b - a)/n$ et $n$ est grand), puis
\begin{displaymath}
  \hat{\theta}_n = \frac{R_n^- + R_n^+}{2}.
\end{displaymath}
Cette procédure devient toutefois rapidement compliquée pour les
intégrales multiples à plusieurs dimensions. Il y a éventuellement
beaucoup trop de points à évaluer.

L'idée de l'intégration Monte Carlo consiste donc à évaluer la
fonction en des points choisis aléatoirement, puis à s'en remettre à
la loi des grands nombres pour estimer l'intégrale. On exprime tout
d'abord la fonction $h(x)$ sous la forme
\begin{displaymath}
  h(x) = g(x) f(x),
\end{displaymath}
où $f(x)$ est une densité sur $(a, b)$. Ainsi,
\begin{align*}
  \theta
  &= \int_a^b g(x) f(x)\, dx \\
  &= \esp{g(X)},
\end{align*}
où $X$ est la variable aléatoire avec fonction de densité de
probabilité $f(x)$. Si $x_1, \dots, x_n$ sont des observations
simulées de la densité $f(x)$, alors
\begin{displaymath}
  \hat{\theta}_n = \frac{1}{n} \sum_{i = 1}^n g(x_i)
\end{displaymath}
constitue une estimation de l'intégrale $\theta$.  Par la loi des
grands nombres $\hat{\theta}_n \stackrel{n \rightarrow
  \infty}{\longrightarrow} \theta$.

Par souci de simplicité et parce qu'il est facile d'obtenir un
échantillon aléatoire d'une loi uniforme, on pose en général $X \sim
U(a, b)$, soit
\begin{displaymath}
  f(x) = \frac{1}{b - a}, \quad a < x < b.
\end{displaymath}
Dans ce cas, on réécrit l'intégrale sous la forme
\begin{align*}
  \theta
  &= (b - a) \int_a^b g(x)\, \frac{1}{b - a}\, dx \\
  &= (b - a) \esp{g(X)},
\end{align*}
et
\begin{displaymath}
  \hat{\theta}_n = \frac{b - a}{n} \sum_{i = 1}^n g(x_i),
\end{displaymath}
où $x_1, \dots, x_n$ est un échantillon aléatoire d'une loi $U(a, b)$,
constitue une estimation de l'intégrale.

\begin{rem}
  Il est équivalent de faire le changement de variable
  \begin{displaymath}
    \begin{split}
      u  &= \frac{x - a}{b - a} \\
      du &= \frac{dx}{b - a}
    \end{split}
    \quad \Leftrightarrow \quad
    \begin{split}
      x  &= a + (b - a) u \\
      dx &= (b - a)\, du
    \end{split}
  \end{displaymath}
  dans l'intégrale
  \begin{displaymath}
    \theta = \int_a^b g(x) f(x)\, dx.
  \end{displaymath}
  On obtient alors
  \begin{align*}
    \theta
    &= (b - a) \int_0^1 g(a + (b - a)u) f(a + (b - a)u)\, du \\
    &= (b - a) \esp{g(a + (b - a)U)},
  \end{align*}
  où $U \sim U(0, 1)$. Une estimation de l'intégrale est donc
  \begin{displaymath}
    \hat{\theta}_n = \frac{b - a}{n} \sum_{i = 1}^n g(a + (b - a) u_i),
  \end{displaymath}
  où $u_1, \dots, u_n$ est un échantillon aléatoire d'une loi $U(0,
  1)$. On doit utiliser la technique du changement de variable lorsque
  le domaine est infini.
\end{rem}

\begin{exemple}
  \label{ex:simulation_va:montecarlo1}
  Soit l'intégrale
  \begin{displaymath}
    \theta = \int_2^5 x^{11/5} e^{-x/10}\, dx.
  \end{displaymath}
  Parce que l'exposant de $x$ n'est pas un entier, on ne peut évaluer
  cette intégrale par parties. Cependant, on remarque que la fonction
  à intégrer est, à une constante près, la densité d'une loi gamma:
  \begin{align*}
    \theta
    &= \int_2^5 x^{11/5} e^{-x/10}\, dx \\
    &= \frac{\Gamma(\frac{16}{5})}{(\frac{1}{10})^{16/5}} \int_2^5
    \frac{(\frac{1}{10})^{16/5}}{\Gamma(\frac{16}{5})}\,
    x^{16/5 - 1} e^{-x/10}\, dx \\
    &= \frac{\Gamma(\frac{16}{5})}{(\frac{1}{10})^{16/5}}
    \left[
      G \left(5; \frac{16}{5}, \frac{1}{10} \right) -
      G \left(2; \frac{16}{5}, \frac{1}{10} \right)
    \right],
  \end{align*}
  où $G(x; \alpha, \lambda)$ est la fonction de répartition de la loi
  Gamma$(\alpha, \lambda)$. Avec \textsf{R}, on obtient
<<echo=TRUE>>=
gamma(3.2) * diff(pgamma(c(2, 5), 3.2, 0.1)) / 0.1^3.2
@

  Pour utiliser la méthode Monte Carlo, on pose
  \begin{displaymath}
    \theta = 3 \int_2^5 x^{11/5} e^{-x/10}
    \left( \frac{1}{3} \right)\, dx.
  \end{displaymath}
  Si $\{x_1, \dots, x_n\}$ est un échantillon aléatoire d'une loi
  $U(2, 5)$, alors
  \begin{displaymath}
    \hat{\theta}_n = \frac{3}{n} \sum_{i = 1}^n
    x_i^{11/5} e^{-x_i/10}
  \end{displaymath}
  est une estimation de $\theta$. On a obtenu les résultats suivants
  avec \textsf{R} (voir aussi la figure
  \ref{fig:simulation_va:montecarlo1}):
<<echo=TRUE>>=
f <- function(x) x^2.2 * exp(-x/10)
x <- runif(1e2, 2, 5)
3 * mean(f(x))
x <- runif(1e3, 2, 5)
3 * mean(f(x))
x <- runif(1e4, 2, 5)
3 * mean(f(x))
x <- runif(1e5, 2, 5)
3 * mean(f(x))
x <- runif(1e6, 2, 5)
3 * mean(f(x))
@
  \qed
  \begin{figure}[t]
    \centering
<<echo=FALSE, fig=TRUE>>=
par(mfrow = c(2, 2))
f <- function(x) x^2.2 * exp(-x/10)
curve(f(x), xlim = c(2, 5), lwd = 3, main = "Vraie fonction")

x <- runif(1e2, 2, 5)
plot(x, f(x), main = "n = 100", pch = 21,
     col = "gray", bg = "black")
x <- runif(1e3, 2, 5)
plot(x, f(x), main = "n = 1000", pch = 21,
     col = "gray", bg = "black")
x <- runif(1e4, 2, 5)
plot(x, f(x), main = "n = 10 000", pch = 21,
     col = "gray", bg = "black")
@
    \caption{Fonction $h(x)$ de l'exemple
      \ref{ex:simulation_va:montecarlo1} et points choisis aléatoirement
      où la fonction est évaluée pour l'intégration Monte Carlo}
    \label{fig:simulation_va:montecarlo1}
  \end{figure}
\end{exemple}

\begin{exemple}
  \label{ex:simulation_va:montecarlo2}
  Soit l'intégrale
  \begin{displaymath}
    \theta = \int_0^{5/4} \int_0^{5/4} \sqrt{4 - x^2 - y^2}\, dy\, dx.
  \end{displaymath}
  La procédure à suivre avec les intégrales multiples est la même
  qu'avec les intégrales simples, sauf que l'on tire des points
  uniformément dans autant de dimensions que nécessaire. Ainsi, dans
  le cas présent, on pose
  \begin{align*}
    \theta
    &= \int_0^{5/4} \int_0^{5/4} \sqrt{4 - x^2 - y^2}\, dy\, dx \\
    &= \frac{25}{16} \int_0^{5/4} \int_0^{5/4} \sqrt{4 - x^2 - y^2}
    \frac{1}{(\frac{5}{4})(\frac{5}{4})}\, dy\, dx \\
    &= \frac{25}{16}\, \Esp{\sqrt{4 - X^2 - Y^2}},
  \end{align*}
  où $X$ et $Y$ sont des variables aléatoires indépendantes
  distribuées uniformément sur l'intervalle $(0, \frac{5}{4})$.
  Autrement dit, la densité conjointe de $X$ et $Y$ est uniforme sur
  $(0, \frac{5}{4}) \times (0, \frac{5}{4})$. Par conséquent, une
  estimation de $\theta$ calculée à partir d'un échantillon $\{(x_1,
  y_1), \dots, (x_n, y_n)\}$ tiré de cette loi conjointe est
  \begin{displaymath}
    \hat{\theta}_n = \frac{25}{16 n} \sum_{i = 1}^n \sqrt{4 - x_i^2 - y_i^2}.
  \end{displaymath}
  On a obtenu les résultats suivants avec \textsf{R} (voir aussi la
  figure \ref{fig:simulation_va:montecarlo2}):
<<echo=TRUE>>=
u <- runif(1e2, 0, 1.25)
v <- runif(1e2, 0, 1.25)
mean(sqrt(4 - u^2 - v^2)) * 1.25^2
u <- runif(1e3, 0, 1.25)
v <- runif(1e3, 0, 1.25)
mean(sqrt(4 - u^2 - v^2)) * 1.25^2
u <- runif(1e4, 0, 1.25)
v <- runif(1e4, 0, 1.25)
mean(sqrt(4 - u^2 - v^2)) * 1.25^2
@
  \qed
  \begin{figure}[t]
    \centering
<<echo=FALSE,fig=TRUE>>=
par(mfrow = c(2, 2), mar = c(1, 1, 2, 1))
f <- function(x, y) sqrt(4 - x^2 - y^2)
x <- seq(0, 1.25, length = 25)
y <- seq(0, 1.25, length = 25)
persp(x, y, outer(x, y, f), main = "Vraie fonction",
      zlim = c(0, 2), theta = 120, phi = 30, col = "gray",
      zlab = "z", ticktype = "detailed")
u <- runif(1e2, 0, 1.25)
v <- runif(1e2, 0, 1.25)
res <- persp(x, y, matrix(NA, length(x), length(y)), main = "n = 100",
             zlim = c(0, 2), theta = 120, phi = 30,
             zlab = "z", ticktype = "detailed")
points(trans3d(u, v, f(u, v), pm = res), pch = 21,
       col = "gray", bg = "black")

u <- runif(1e3, 0, 1.25)
v <- runif(1e3, 0, 1.25)
res <- persp(x, y, matrix(NA, length(x), length(y)), main = "n = 1000",
             zlim = c(0, 2), theta = 120, phi = 30,
             zlab = "z", ticktype = "detailed")
points(trans3d(u, v, f(u, v), pm = res), pch = 21,
       col = "gray", bg = "black")

u <- runif(1e4, 0, 1.25)
v <- runif(1e4, 0, 1.25)
res <- persp(x, y, matrix(NA, length(x), length(y)), main = "n = 10 000",
             zlim = c(0, 2), theta = 120, phi = 30,
             zlab = "z", ticktype = "detailed")
points(trans3d(u, v, f(u, v), pm = res), pch = 21,
       col = "gray", bg = "black")
@
    \caption{Fonction $h(x)$ de l'exemple
      \ref{ex:simulation_va:montecarlo2} et points choisis
      aléatoirement où la fonction est évaluée pour l'intégration
      Monte Carlo}
    \label{fig:simulation_va:montecarlo2}
  \end{figure}
\end{exemple}

\begin{rem}
  Le premier graphique de la figure
  \ref{fig:simulation_va:montecarlo2} a été réalisé en \textsf{R} avec
  les commandes suivantes:
<<echo=TRUE,eval=FALSE>>=
f <- function(x, y) sqrt(4 - x^2 - y^2)
x <- seq(0, 1.25, length = 25)
y <- seq(0, 1.25, length = 25)
persp(x, y, outer(x, y, f), main = "Vraie fonction",
      zlim = c(0, 2), theta = 120, phi = 30, col = "gray",
      zlab = "z", ticktype = "detailed")
@
  Pour ajouter des points dans un graphique en trois dimensions,
  utiliser les fonction \texttt{points} et \texttt{trans3d}.
\end{rem}

\input{exercices-simulation_va}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "methodes_numeriques-partie_2"
%%% coding: utf-8
%%% End:
